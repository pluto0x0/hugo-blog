[{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 menu: main: - identifier: categories name: categories url: /categories/ weight: 10 - identifier: tags name: tags url: /tags/ weight: 20 - identifier: example name: example.org url: https://example.org weight: 30 Diffusion Model 加噪过程 定义一个马尔可夫链，从数据 $x_{0} \\sim q(x)$ 开始，每一步加一点噪声：\n$$q\\left( x_{t}~|~x_{t - 1} \\right) = \\mathcal{N}(x_{t};\\sqrt{1 - \\beta_{t}}x_{t - 1},\\beta_{t}I)$$使用重参数化，等价于\n$$x_{t} = \\sqrt{1 - \\beta_{t}}x_{t - 1} + \\sqrt{\\beta_{t}}\\varepsilon_{t},\\quad\\varepsilon_{t} \\sim N(0,I),$$其中 $\\beta$ 是一系列预定义的参数.\n对于两个高斯分布 $x_{1} \\sim \\mathcal{N}(\\mu_{1},\\sigma_{1}^{2})$ 和 $x_{2} \\sim \\mathcal{N}(\\mu_{2},\\sigma_{2}^{2})$，我们有：\n$$x_{1} + x_{2} \\sim \\mathcal{N}(\\mu_{1} + \\mu_{2},\\sigma_{1}^{2} + \\sigma_{2}^{2})$$于是定义 $\\alpha_{t} = 1 - \\beta_{t}$，则\n$$\\begin{aligned} x_{t} \u0026 = \\sqrt{\\alpha_{t}}x_{t - 1} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{\\alpha_{t}\\left( 1 - \\alpha_{t - 1} \\right)}\\varepsilon_{t} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}}\\varepsilon \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}x_{t - 3} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}\\varepsilon \\\\ \u0026 = \\ldots \\end{aligned}$$定义 ${\\overline{\\alpha}}_{t} = \\prod_{s = 1}^{t}\\alpha_{s}$, 得到 $x_{t}$ 的封闭形式\n$$x_{t} = \\sqrt{{\\overline{\\alpha}}_{t}}x_{0} + \\sqrt{1 - {\\overline{\\alpha}}_{t}}\\varepsilon,\\quad\\varepsilon \\sim N(0,I).$$即\n$$q\\left( x_{t}~|~x_{0} \\right) = \\mathcal{N}(x_{t};\\sqrt{{\\overline{\\alpha}}_{t}}x_{0},\\left( 1 - {\\overline{\\alpha}}_{t} \\right)I)$$因为 $\\alpha_{t} \u003c 1$, 因此 ${\\overline{\\alpha}}_{\\infty} \\rightarrow 0$，此时 $q\\left( x_{t}~|~x_{0} \\right) \\rightarrow \\mathcal{N}(0,I)$. 即随着 $t$ 增大，$x_{t}$ 趋近于纯噪声.\n去噪过程 我们的目标是找到加噪过程 $q\\left( x_{t}~|~x_{t - 1} \\right)$ 的逆过程，即逐步去噪的条件高斯分布\n$$q\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{t}\\left( x_{t} \\right),\\Sigma_{t}\\left( x_{t} \\right))$$$q\\left( x_{t - 1}~|~x_{t} \\right)$不可解，因此使用一个模型 $\\theta$ 近似，以 $x_{t}$ 和 $t$ 作为输入，输出分布参数\n$$p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{\\theta}\\left( x_{t},t \\right),\\Sigma_{\\theta}\\left( x_{t},t \\right))$$最大似然估计 MLE 目标是最小化去噪模型 $p_{\\theta}$ 对初始数据 $x_{0}$ 的负对数似然：\n$$\\mathcal{L}(\\theta) = - \\log p_{\\theta}\\left( x_{0} \\right)$$同样地，使用变分下界 ELBO 优化，其中 $x_{0}$ 是已知变量，$x_{1:T}$ 是隐变量：\n$$\\begin{array}{r} \\mathcal{F}(q,\\theta) = {\\mathbb{E}}_{q\\left( x_{1:T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0:T} \\right) - \\log q\\left( x_{1:T}|x_{0} \\right) \\right\\rbrack \\\\ \\mathcal{L}(\\theta) \\leq - \\mathcal{F}(q,\\theta) \\end{array}$$根据马尔可夫性质，\n$$\\begin{array}{r} q\\left( x_{1:T}|x_{0} \\right) = q\\left( x_{T}~|~x_{0} \\right)\\prod_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\\\ p_{\\theta}\\left( x_{0:T} \\right) = p_{\\theta}\\left( x_{T} \\right)\\prod_{t = 1}^{T}p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\end{array}$$代入得到 $\\mathcal{F}(q,\\theta)$\n$$\\begin{aligned} = \u0026 {\\mathbb{E}}_{q\\left( x_{1}:x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) + \\sum_{t = 1}^{T}\\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) - \\sum_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t},x_{t - 1}|x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}{\\mathbb{E}}_{q\\left( x_{t - 1}|x_{t},x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right) \\\\ \u0026 - \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right) \\end{aligned}$$分别记作\n$$\\mathcal{L} ≔ - \\mathcal{F}(q,\\theta) = \\mathcal{L}_{0} + \\sum_{t = 2}^{T}\\mathcal{L}_{t - 1} + \\mathcal{L}_{T}.$$其中\n初始项 $\\mathcal{L}_{0} = - {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack$\n最小化最后一步 $x_{1}$ 到 $x_{0}$ 的重建误差\n当 $p_{\\theta}$ 取高斯分布时，相当于最小化均方误差 MSE: ${\\mathbb{E}}\\left\\lbrack \\left\\| {x_{1} - x_{0}} \\right\\|^{2} \\right\\rbrack$\n中间项 $\\mathcal{L}_{t - 1} = {\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right)$\n让模型 $p_{\\theta}$ 学习去噪过程，缩小和真实后验 $q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)$ 的差距。\n$$q\\left( x_{t - 1}|x_{t},x_{0} \\right) = \\frac{q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)}{q\\left( x_{t}|x_{0} \\right)} \\propto q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)$$ 终端项 $\\mathcal{L}_{T} = \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right)$\n让模型 $p_{\\theta}$ 的先验分布接近 $q\\left( x_{T}~|~x_{0} \\right)$\n对于足够大的 $T$，$q\\left( x_{T}~|~x_{0} \\right) \\approx \\mathcal{N}(0,I)$，而先验 $p_{\\theta}\\left( x_{T} \\right)$ 被定义为 $\\mathcal{N}(0,I)$\n因此该项可以忽略不计.\nScore-based Diffusion Model \u0026amp; Langevin dynamics Langevin dynamics Boltzmann distribution 统计力学的玻尔兹曼分布（Boltzmann distribution）指出一个系统的状态分布为\n$$p_{i} \\propto \\exp( - \\frac{\\varepsilon_{i}}{kT})$$ []{#eq:boltzmann}\n其中 $\\varepsilon_{i}$ 是状态 $i$ 的能量，$k$ 是玻尔兹曼常数，$T$ 是温度.\nLangevin equation 而 Langevin equation 描述的是粒子在（一维）势能场中的布朗运动，\n$$dx_{t} = - \\frac{1}{\\gamma}\\nabla_{x}U\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t}$$ []{#eq:langevin}\n其中\n$x$ 是粒子位置\n$U(x)$ 是势能函数\n$\\gamma$ 是阻尼系数\n$W_{t}$ 是标准 Wiener 过程：$W_{t + \\Delta} = W_{t} + \\mathcal{N}(0,\\Delta)$\n根据 Boltzmann distribution\n$$U(x) = - kT\\log p(x) + \\text{ constant},$$代入得\n$$\\begin{aligned} dx_{t} \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\\\ \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\end{aligned}$$方程在离散时间 $x_{k} ≔ x(k\\tau)$ 下的形式为\n$$\\begin{array}{rlr} x_{k + 1} - x_{k} \u0026 = - \\frac{kT}{\\gamma}\\tau\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{\\frac{2kT}{\\gamma}\\tau}\\xi\\quad \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\\\ \u0026 = - \\eta\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{2\\eta}\\xi \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\end{array}$$其中 $\\eta = \\frac{kT}{\\gamma}\\tau$ 是步长. 回忆 $x_{t}$ 描述的是粒子的随机位置，因此\n$$x_{k} \\sim p(x)$$即已知对数梯度 $\\nabla\\log p(x)$ 时，Langevin dynamics 迭代的过程可以对分布 $p(x)$ 采样，而不需要显式地知道 $p(x)$ 的形式。\n观察迭代形式，这实际上是一个带随机扰动的对数梯度上升过程，梯度项使得粒子趋向于高概率区域，而随机扰动则保证了采样的多样性.\nSimulated Annealing 实际上，如果令玻尔兹曼分布 ([@eq]:boltzmann) 中势能不变，$T$ 逐渐收敛至 $0$, 则分布收敛到单点分布 $p(x) = \\delta(x - x^{\\ast})$，其中 $x^{\\ast} = \\arg\\min\\limits_{x}U(x)$ 是势能的最小值点, 此时 Langevin equation ([@eq]:langevin) 中的随机扰动项收敛至 $0$，Langevin dynamics 退化为势能的对数梯度下降. 而温度 $T$ 的收敛速度控制了采样过程的随机性，快速的降温会导致探索不足，陷入局部势能极小值，反之则有更大概率达到势能全局最小值。这种模拟降温过程的方法即为模拟退火 Simulated Annealing.\nScore-based Diffusion Model 定义 score 函数，即数据分布的对数梯度：\n$$\\text{ score}(x) = \\nabla_{x}\\log p(x)$$根据 Langevin dynamics ([@eq]:langevin)，只要能估计出数据分布的 score 函数，即可通过迭代采样得到数据分布的样本.\n学习 score 在 Score-based Diffusion Model 中，唯一需要学习的就是一个 noise-conditioned score network:\n$$s_{\\theta}\\left( x_{t},t \\right) \\approx \\nabla_{x_{t}}\\log p\\left( x_{t} \\right)$$采取 DSM（Denoising Score Matching）损失：\n$$\\mathcal{L} = {\\mathbb{E}}_{x,z,t}\\left\\lbrack \\lambda(t)\\left\\| {s_{\\theta}\\left( x + \\sigma_{t}z,t \\right) + \\frac{z}{\\sigma_{t}}} \\right\\|^{2} \\right\\rbrack$$即 $s_{\\theta}\\left( x + \\sigma_{t}z,t \\right)$ 的真实值为\n$$\\nabla\\log\\mathcal{N}(u;x,\\sigma_{t}^{2}) = \\nabla\\frac{{- (u - x)}^{2}}{2\\sigma_{t}^{2}} = - \\frac{u - x}{\\sigma_{t}^{2}} = - \\frac{z}{\\sigma_{t}}$$而 $\\lambda(t)$ 是一个权重函数，用于平衡不同噪声水平下的损失贡献. 常见的选择是\n$$\\lambda(t) = \\sigma_{t}^{2}$$采样/去噪 条件 Diffusion Model 给定条件 $c$, 需要\n$$\\nabla_{x}\\log p\\left( x|c \\right)$$Bayes 公式：\n$$\\nabla_{x}\\log p\\left( x|c \\right) = \\nabla_{x}\\log p(x) + \\nabla_{x}\\log p\\left( c|x \\right)$$如何得到 $\\nabla_{x}\\log p\\left( c|x \\right)$:\nclassifier guidance：基于 $x_{t}$ 的分类器，通过反向传播获取梯度。 通过给 $\\nabla_{x}\\log p\\left( c|x \\right)$ 乘以一个系数 $s \u003e 1$，可以增强条件信息的影响，得到更符合条件的样本生成结果.\nClassifier-Free Diffusion Guidance (CFG) 不使用分类器，而是定义两种去噪模型的score：\n条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma,c \\right) - x_{0} \\right)$\n无条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right)$\n其中 $D_{\\theta}$ 是去噪器, 使用一个 null 条件（如全零向量）来表示无条件模型. 则上式的等价形式\n$$\\begin{aligned} \\nabla_{x}\\log p\\left( x|c \\right) \u0026 = \\nabla_{x}\\log p(x) + S\\nabla_{x}\\log p\\left( c|x \\right) \\\\ \u0026 = \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) + S\\left( \\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) - \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\right) \\\\ \u0026 = S\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) + (1 - S)\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\\\ \u0026 = \\frac{1}{\\sigma^{2}}\\left( SD_{\\theta}\\left( x_{t},\\sigma,c \\right) + (1 - S)D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right) \\end{aligned}$$即用二者的凸组合来进行去噪采样.\n","permalink":"http://localhost:1313/posts/2025-12-26-diffusion/","summary":"\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nt\"\u003emenu\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"nt\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/categories/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e10\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/tags/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e20\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ehttps://example.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e30\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch1 id=\"diffusion-model\"\u003eDiffusion Model\u003c/h1\u003e\n\u003ch2 id=\"加噪过程\"\u003e加噪过程\u003c/h2\u003e\n\u003cp\u003e定义一个\u003cstrong\u003e马尔可夫链\u003c/strong\u003e，从数据 $x_{0} \\sim q(x)$\n开始，每一步加一点噪声：\u003c/p\u003e","title":"diffusion"},{"content":"证据下界 ELBO 在最大似然估计（Maximum Likelihood Estimation, MLE）中，目标是最大化观测数据 $x$ 的对数似然.\n参数 $\\theta$ 的对数似然（log likelihood）的定义为\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布 $q(z)$，有\n$$ \\begin{aligned} \\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\ \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\end{aligned} $$由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\n$$ \\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack. $$取等条件 Jensen 不等式能够取等，当且仅当对于所有 $z$, $\\frac{p_{\\theta}(x,z)}{q(z)}$ 为常数 $c$. 因此\n$$ \\begin{aligned} p_{\\theta}(x) \u0026= \\sum_{z}p_{\\theta}(x,z) = c\\sum_{z}q(z) = c \\\\ q(z) \u0026= \\frac{p_{\\theta}(x,z)}{p_{\\theta}(x)} = p_{\\theta}\\left( z|x \\right). \\end{aligned} $$这里的 $q(z)$ 可以是任意分布，但使用中常用 $q(z) = q_{\\varphi}\\left( z|x \\right)$，即 $z$ 的近似后验分布，而近似后验分布越接近真实后验分布 $p_{\\theta}\\left( z|x \\right)$，ELBO 越接近对数似然.\nKL散度 任意分布 $p(x)$ 的信息熵定义为\n$$H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log p(x) \\right\\rbrack$$即对随机事件编码长度的期望值. 如果认为 $x$ 服从另一分布 $q(x)$，在\u0026quot;真实\u0026quot;分布 $p(x)$ 下的编码长度期望值定义为交叉熵：\n$$H(p,q) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log q(x) \\right\\rbrack.$$KL散度即定义为“额外的”编码长度\n$$\\text{ KL}\\left( p\\|q \\right) = H(p,q) - H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack.$$ KL散度描述了两个分布的差异程度，但是不是距离度量，因为不满足对称性和三角不等式.\nKL 散度的非负性 对于任意分布 $p(x)$ 和 $q(x)$，有 $\\text{KL}(p \\|q) \\ge 0$，因为\n$$ \\begin{aligned} \\text{ KL}\\left( p\\|q \\right) \u0026 = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack \\\\ \u0026 = - {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log\\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \\left( \\text{Jensen} \\right) \u0026 \\geq - \\log{\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \u0026 = - \\log\\int_{x}p(x)\\left( \\frac{q(x)}{p(x)} \\right)dx \\\\ \u0026 = - \\log\\int_{x}q(x)dx \\\\ \u0026 = - \\log 1 \\\\ \u0026 = 0. \\end{aligned} $$易知当且仅当 $p = q$ 时，$\\text{KL}\\left( p\\|q \\right) = 0$.\nELBO 等价形式 回到 ELBO，ELBO 和真实对数似然的差距为\n$$ \\begin{aligned} \\ell(\\theta) - \\mathcal{F}(q,\\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x) - \\log p_{\\theta}(x,z) + \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack - \\log p_{\\theta}\\left( z|x \\right) + \\log q(z) \\right\\rbrack \\\\ \u0026= \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right) \\geq 0. \\end{aligned} $$因此，ELBO 等价于\n$$\\mathcal{F}(q,\\theta) = \\ell(\\theta) - \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right)$$显然，取等条件同样为 $q(z) = p_{\\theta}\\left( z|x \\right)$. 而一般的问题中，通常采用以下形式：\n$$ \\begin{aligned} \\mathcal{F}(q, \\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{p_{\\theta}(z)} \\right\\rbrack - \\left( {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(z) \\right\\rbrack \\right) \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q(z)\\|p_{\\theta}(z) \\right) \\end{aligned} $$EM EM 算法的目标是最大化参数 $\\theta$ 对数似然：\n$$\\ell(\\theta) = \\log p\\left( x|\\theta \\right)$$第 $i$ 步的参数和隐变量分布分别记为 $\\theta^{(i)}$ 和 $q^{(i)}(z)$.\nE 步 最大化 $\\ell(\\theta^{(i)})$ 的 ELBO，即取等条件\n$$q^{(i + 1)}(z) = p_{\\theta^{(i)}}\\left( z|x \\right)$$M 步 更新参数 $\\theta^{(i)}$ 以最大化 ELBO， $$\\theta^{(i + 1)} = \\arg\\max\\limits_{\\theta}\\mathcal{F}(q^{(i + 1)},\\theta)$$收敛性 $$\\ell(\\theta^{(i + 1)})\\underset{\\text{ELBO}}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i + 1)})\\underset{\\arg\\max}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i)})\\underset{\\text{满足取等条件}}{=}\\ell(\\theta^{(i)})$$因此对数似然单调不减.\n例子：高斯混合模型 GMM 假设观测数据 $x$ 来自 $K$ 个高斯分布的混合：\n$$p_{\\theta}(x) = \\sum_{k = 1}^{K}\\pi_{k}\\mathcal{N}(x|\\mu_{k},\\Sigma_{k})$$其中 $\\theta = \\left\\{ \\pi_{k},\\mu_{k},\\Sigma_{k} \\right\\}_{k=1}^K$ 是模型参数，$\\pi_{k}$ 是混合系数，满足 $\\sum_{k = 1}^{K}\\pi_{k} = 1$. 数据样本为 $\\left\\{ x^{i} \\right\\}_{i = 1}^{N}$，引入隐变量 $z$ 表示样本属于哪个高斯分布, $z^{i} = k$ 表示样本 $x^{i}$ 来自第 $k$ 个高斯分布.\nE 步 计算后验概率（责任度）：\n$$ \\begin{aligned} \\gamma_{z^{i} = k} \u0026 \\leftarrow p_{\\theta}\\left( z^{i} = k|x^{i} \\right) \\\\ \u0026 = \\frac{\\pi_{k}\\mathcal{N}(x^{i}|\\mu_{k},\\Sigma_{k})}{\\sum_{j = 1}^{K}\\pi_{j}\\mathcal{N}(x^{i}|\\mu_{j},\\Sigma_{j})} \\end{aligned} $$M 步 更新参数：\n$$\\theta = \\arg\\max\\limits_{\\theta}\\mathcal{F}(\\gamma,\\theta)$$即在已知责任度 $\\gamma_{z^{i} = k}$ 下，最大化似然的参数. 定义 $\\begin{aligned} N_{k} \u0026 = \\sum_{i = 1}^{N}\\gamma_{z^{i} = k} \\end{aligned}$,\n则更新步骤为\n$$ \\begin{aligned} \\pi_{k} \u0026 \\leftarrow \\frac{N_{k}}{N} \\\\ \\mu_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}x^{i} \\\\ \\Sigma_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}\\left( x^{i} - \\mu_{k} \\right)\\left( x^{i} - \\mu_{k} \\right)^{\\top} \\end{aligned} $$VAE 普通的自编码器（Autoencoder）就是编码\u0026ndash;解码：\n编码器把输入数据 $x$ 映射到一个隐空间向量 $z$；\n解码器把 $z$ 还原回数据空间，得到重构 $\\hat{x}$.\n但是，普通自编码器学习到的 $z$ 没有概率解释，不能直接采样用于生成.\nVAE 的关键思想是：\n给隐变量 $z$ 加一个概率分布的解释，并用变分推断来学习这个分布.\n编码器不再输出一个确定向量，而是输出一个 分布参数（均值 $\\mu(x)$、方差 $\\sigma^{2}(x)$）\n从这个分布中采样 $z \\sim q_{\\varphi(z|x)}$，再送给解码器生成 $\\hat{x}$.\n这样隐空间就被正则化成一个连续、平滑的概率空间，可以用来插值、采样、生成新样本.\n先验分布 $p(z)$ 隐变量 $z$ 的先验分布 $p(z)$ 通常取标准正态分布 $\\mathcal{N}(0,I)$.\n解码器（生成分布） $p_{\\theta}\\left( x|z \\right)$ 网络参数 $\\theta$ 输入隐变量 $z$，输出数据 $x$ 的分布参数，即高斯分布的均值 $\\mu(z)$ 和方差 $\\Sigma(z)$.\n编码器（近似后验分布）$q_{\\varphi}\\left( z|x \\right)$ 使用 $q_{\\varphi}\\left( z|x \\right)$ 拟合\u0026quot;真实\u0026quot;后验分布 $p_{\\theta}\\left( z|x \\right)$.同样使用神经网络参数 $\\varphi$，输入数据 $x$，输出隐变量 $z$ 的分布参数.\n\u0026ldquo;近似\u0026quot;后验 和 \u0026ldquo;真实\u0026quot;后验 \u0026ldquo;真实\u0026quot;的后验分布由贝叶斯公式得出\n$$ \\begin{aligned} p_{\\theta}\\left( x|z \\right) \u0026= \\frac{p_{\\theta}\\left( x|z \\right)p(z)}{p_{\\theta}(x)} \\\\ p_{\\theta}(x) \u0026= \\int p_{\\theta}\\left( x|z \\right)p(z)dz \\end{aligned} $$因此真实的后验不可解，使用近似后验 $q_{\\varphi}\\left( z|x \\right)$ 来代替.\nELBO 和损失函数 使用 ELBO 替代对数似然：\n$$\\log p_{\\theta}(x) \\geq {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$其中\n${\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack$ 是重构误差，衡量解码器重构 $\\hat{x}$ 与输入 $x$ 的差异；\n$\\text{KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$ 是正则化项，使近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 尽量接近先验分布 $p(z)$（标准正态分布）.\n训练和重参数化 目前我们有\n编码器 $q_{\\varphi}\\left( z|x \\right)$，输入 $x$，输出隐变量 $z$ 的高斯分布参数 $\\mu(x),\\sigma^{2}(x)$；\n解码器 $p_{\\theta}\\left( x|z \\right)$，输入隐变量 $z$，输出重构 $\\hat{x}$ 的分布；\n先验分布 $p(z)$，通常取标准正态分布 $\\mathcal{N}(0,I)$.\n损失函数 ELBO $$\\mathcal{L} = - {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack + \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$ 训练时，期望项（重构误差）没有解析解，使用 $z$ 的采样来近似. 为了保证采样 $z \\sim \\mathcal{N}(\\mu(x),\\sigma^{2}(x))$ 可导，使用重参数化技巧：\n$$ \\begin{array}{r} z = \\mu(x) + \\sigma(x) \\odot \\varepsilon, \\\\ \\end{array} $$其中 $\\varepsilon \\sim \\mathcal{N}(0,I)$ 是独立噪声.\n展开 KL 散度 记 $q_{\\text{agg }}(z) = {\\mathbb{E}}_{x \\sim P(x)}q\\left( z|x \\right)$,\n$$ \\begin{aligned} \\text{ELBO} \u0026= \\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right] - \\mathrm{KL}\\!\\left(q_{\\text{agg}}(z)\\|p(z)\\right) \\\\ \u0026= \\underbrace{\\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right]}_{\\text{重构项}} - \\underbrace{H\\!\\left(q_{\\text{agg}}(z),p(z)\\right)}_{\\text{交叉熵}} + \\underbrace{H\\!\\left(p(z)\\right)}_{\\text{熵}}. \\end{aligned} $$ 重构项：鼓励隐变量分布远离先验分布 $p(z)$，提高重构质量 交叉熵：把隐变量分布拉向先验分布 $p(z)$ 中心，会同时减小均值和方差 熵：鼓励隐变量分布增大方差，分布更扁平 VAE 的问题 Prior Hole VAE 的隐空间分布 $q_{\\text{agg }}(z)$ 往往只占据先验分布 $p(z)$ 的一小部分，导致从先验分布采样的 $z$ 很可能落在\u0026quot;空洞\u0026quot;区域，解码器无法生成有效样本.\nPosterior Collapse 如果解码器足够强大，例如 autoregressive 模型，可以不依赖 $z$, 或者仅从 $z$ 的一部分维度中重构输入 $x$. 即 $z$ 的某些维度对重构没有贡献，导致这些维度的近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 退化为先验分布 $p(z)$，从而无法学习到有效的隐表示.\n$$\\exists i\\ s.t.\\ \\forall x,q_{\\varphi}\\left( z_{i}|x \\right) = p\\left( z_{i} \\right)$$Vector Quantized VAE(VQ VAE) 让隐变量 $z$ 取离散值，而不是连续值. 定义一个有限的码本（codebook），编码器输出一个向量 $e_{i}$，然后将 $e_{i}$ 映射到码本中距离最近的离散向量 $e_{k}$.\n解决了 Prior Hole 和 Posterior Collapse 问题，但训练时需要使用特殊的技巧（如直通估计器）来处理离散变量的不可导问题.\n","permalink":"http://localhost:1313/posts/elbo-em-vae/","summary":"\u003ch1 id=\"证据下界-elbo\"\u003e证据下界 ELBO\u003c/h1\u003e\n\u003cp\u003e在最大似然估计（Maximum Likelihood Estimation,\nMLE）中，目标是最大化观测数据 $x$ 的对数似然.\u003c/p\u003e\n\u003cp\u003e参数 $\\theta$ 的对数似然（log likelihood）的定义为\u003c/p\u003e\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$\u003cp\u003e其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布\n$q(z)$，有\u003c/p\u003e\n$$\n\\begin{aligned}\n\\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\\n \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack\n\\end{aligned}\n$$\u003cp\u003e由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\u003c/p\u003e\n$$\n\\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack.\n$$\u003ch2 id=\"取等条件\"\u003e取等条件\u003c/h2\u003e\n\u003cp\u003eJensen 不等式能够取等，当且仅当对于所有 $z$,\n$\\frac{p_{\\theta}(x,z)}{q(z)}$\n为常数 $c$.\n因此\u003c/p\u003e","title":"ELBO，EM和VAE"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 menu: main: - identifier: categories name: categories url: /categories/ weight: 10 - identifier: tags name: tags url: /tags/ weight: 20 - identifier: example name: example.org url: https://example.org weight: 30 Diffusion Model 加噪过程 定义一个马尔可夫链，从数据 $x_{0} \\sim q(x)$ 开始，每一步加一点噪声：\n$$q\\left( x_{t}~|~x_{t - 1} \\right) = \\mathcal{N}(x_{t};\\sqrt{1 - \\beta_{t}}x_{t - 1},\\beta_{t}I)$$使用重参数化，等价于\n$$x_{t} = \\sqrt{1 - \\beta_{t}}x_{t - 1} + \\sqrt{\\beta_{t}}\\varepsilon_{t},\\quad\\varepsilon_{t} \\sim N(0,I),$$其中 $\\beta$ 是一系列预定义的参数.\n对于两个高斯分布 $x_{1} \\sim \\mathcal{N}(\\mu_{1},\\sigma_{1}^{2})$ 和 $x_{2} \\sim \\mathcal{N}(\\mu_{2},\\sigma_{2}^{2})$，我们有：\n$$x_{1} + x_{2} \\sim \\mathcal{N}(\\mu_{1} + \\mu_{2},\\sigma_{1}^{2} + \\sigma_{2}^{2})$$于是定义 $\\alpha_{t} = 1 - \\beta_{t}$，则\n$$\\begin{aligned} x_{t} \u0026 = \\sqrt{\\alpha_{t}}x_{t - 1} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{\\alpha_{t}\\left( 1 - \\alpha_{t - 1} \\right)}\\varepsilon_{t} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}}\\varepsilon \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}x_{t - 3} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}\\varepsilon \\\\ \u0026 = \\ldots \\end{aligned}$$定义 ${\\overline{\\alpha}}_{t} = \\prod_{s = 1}^{t}\\alpha_{s}$, 得到 $x_{t}$ 的封闭形式\n$$x_{t} = \\sqrt{{\\overline{\\alpha}}_{t}}x_{0} + \\sqrt{1 - {\\overline{\\alpha}}_{t}}\\varepsilon,\\quad\\varepsilon \\sim N(0,I).$$即\n$$q\\left( x_{t}~|~x_{0} \\right) = \\mathcal{N}(x_{t};\\sqrt{{\\overline{\\alpha}}_{t}}x_{0},\\left( 1 - {\\overline{\\alpha}}_{t} \\right)I)$$因为 $\\alpha_{t} \u003c 1$, 因此 ${\\overline{\\alpha}}_{\\infty} \\rightarrow 0$，此时 $q\\left( x_{t}~|~x_{0} \\right) \\rightarrow \\mathcal{N}(0,I)$. 即随着 $t$ 增大，$x_{t}$ 趋近于纯噪声.\n去噪过程 我们的目标是找到加噪过程 $q\\left( x_{t}~|~x_{t - 1} \\right)$ 的逆过程，即逐步去噪的条件高斯分布\n$$q\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{t}\\left( x_{t} \\right),\\Sigma_{t}\\left( x_{t} \\right))$$$q\\left( x_{t - 1}~|~x_{t} \\right)$不可解，因此使用一个模型 $\\theta$ 近似，以 $x_{t}$ 和 $t$ 作为输入，输出分布参数\n$$p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{\\theta}\\left( x_{t},t \\right),\\Sigma_{\\theta}\\left( x_{t},t \\right))$$最大似然估计 MLE 目标是最小化去噪模型 $p_{\\theta}$ 对初始数据 $x_{0}$ 的负对数似然：\n$$\\mathcal{L}(\\theta) = - \\log p_{\\theta}\\left( x_{0} \\right)$$同样地，使用变分下界 ELBO 优化，其中 $x_{0}$ 是已知变量，$x_{1:T}$ 是隐变量：\n$$\\begin{array}{r} \\mathcal{F}(q,\\theta) = {\\mathbb{E}}_{q\\left( x_{1:T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0:T} \\right) - \\log q\\left( x_{1:T}|x_{0} \\right) \\right\\rbrack \\\\ \\mathcal{L}(\\theta) \\leq - \\mathcal{F}(q,\\theta) \\end{array}$$根据马尔可夫性质，\n$$\\begin{array}{r} q\\left( x_{1:T}|x_{0} \\right) = q\\left( x_{T}~|~x_{0} \\right)\\prod_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\\\ p_{\\theta}\\left( x_{0:T} \\right) = p_{\\theta}\\left( x_{T} \\right)\\prod_{t = 1}^{T}p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\end{array}$$代入得到 $\\mathcal{F}(q,\\theta)$\n$$\\begin{aligned} = \u0026 {\\mathbb{E}}_{q\\left( x_{1}:x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) + \\sum_{t = 1}^{T}\\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) - \\sum_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t},x_{t - 1}|x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}{\\mathbb{E}}_{q\\left( x_{t - 1}|x_{t},x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right) \\\\ \u0026 - \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right) \\end{aligned}$$分别记作\n$$\\mathcal{L} ≔ - \\mathcal{F}(q,\\theta) = \\mathcal{L}_{0} + \\sum_{t = 2}^{T}\\mathcal{L}_{t - 1} + \\mathcal{L}_{T}.$$其中\n初始项 $\\mathcal{L}_{0} = - {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack$\n最小化最后一步 $x_{1}$ 到 $x_{0}$ 的重建误差\n当 $p_{\\theta}$ 取高斯分布时，相当于最小化均方误差 MSE: ${\\mathbb{E}}\\left\\lbrack \\left\\| {x_{1} - x_{0}} \\right\\|^{2} \\right\\rbrack$\n中间项 $\\mathcal{L}_{t - 1} = {\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right)$\n让模型 $p_{\\theta}$ 学习去噪过程，缩小和真实后验 $q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)$ 的差距。\n$$q\\left( x_{t - 1}|x_{t},x_{0} \\right) = \\frac{q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)}{q\\left( x_{t}|x_{0} \\right)} \\propto q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)$$ 终端项 $\\mathcal{L}_{T} = \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right)$\n让模型 $p_{\\theta}$ 的先验分布接近 $q\\left( x_{T}~|~x_{0} \\right)$\n对于足够大的 $T$，$q\\left( x_{T}~|~x_{0} \\right) \\approx \\mathcal{N}(0,I)$，而先验 $p_{\\theta}\\left( x_{T} \\right)$ 被定义为 $\\mathcal{N}(0,I)$\n因此该项可以忽略不计.\nScore-based Diffusion Model \u0026amp; Langevin dynamics Langevin dynamics Boltzmann distribution 统计力学的玻尔兹曼分布（Boltzmann distribution）指出一个系统的状态分布为\n$$p_{i} \\propto \\exp( - \\frac{\\varepsilon_{i}}{kT})$$ []{#eq:boltzmann}\n其中 $\\varepsilon_{i}$ 是状态 $i$ 的能量，$k$ 是玻尔兹曼常数，$T$ 是温度.\nLangevin equation 而 Langevin equation 描述的是粒子在（一维）势能场中的布朗运动，\n$$dx_{t} = - \\frac{1}{\\gamma}\\nabla_{x}U\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t}$$ []{#eq:langevin}\n其中\n$x$ 是粒子位置\n$U(x)$ 是势能函数\n$\\gamma$ 是阻尼系数\n$W_{t}$ 是标准 Wiener 过程：$W_{t + \\Delta} = W_{t} + \\mathcal{N}(0,\\Delta)$\n根据 Boltzmann distribution\n$$U(x) = - kT\\log p(x) + \\text{ constant},$$代入得\n$$\\begin{aligned} dx_{t} \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\\\ \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\end{aligned}$$方程在离散时间 $x_{k} ≔ x(k\\tau)$ 下的形式为\n$$\\begin{array}{rlr} x_{k + 1} - x_{k} \u0026 = - \\frac{kT}{\\gamma}\\tau\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{\\frac{2kT}{\\gamma}\\tau}\\xi\\quad \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\\\ \u0026 = - \\eta\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{2\\eta}\\xi \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\end{array}$$其中 $\\eta = \\frac{kT}{\\gamma}\\tau$ 是步长. 回忆 $x_{t}$ 描述的是粒子的随机位置，因此\n$$x_{k} \\sim p(x)$$即已知对数梯度 $\\nabla\\log p(x)$ 时，Langevin dynamics 迭代的过程可以对分布 $p(x)$ 采样，而不需要显式地知道 $p(x)$ 的形式。\n观察迭代形式，这实际上是一个带随机扰动的对数梯度上升过程，梯度项使得粒子趋向于高概率区域，而随机扰动则保证了采样的多样性.\nSimulated Annealing 实际上，如果令玻尔兹曼分布 ([@eq]:boltzmann) 中势能不变，$T$ 逐渐收敛至 $0$, 则分布收敛到单点分布 $p(x) = \\delta(x - x^{\\ast})$，其中 $x^{\\ast} = \\arg\\min\\limits_{x}U(x)$ 是势能的最小值点, 此时 Langevin equation ([@eq]:langevin) 中的随机扰动项收敛至 $0$，Langevin dynamics 退化为势能的对数梯度下降. 而温度 $T$ 的收敛速度控制了采样过程的随机性，快速的降温会导致探索不足，陷入局部势能极小值，反之则有更大概率达到势能全局最小值。这种模拟降温过程的方法即为模拟退火 Simulated Annealing.\nScore-based Diffusion Model 定义 score 函数，即数据分布的对数梯度：\n$$\\text{ score}(x) = \\nabla_{x}\\log p(x)$$根据 Langevin dynamics ([@eq]:langevin)，只要能估计出数据分布的 score 函数，即可通过迭代采样得到数据分布的样本.\n学习 score 在 Score-based Diffusion Model 中，唯一需要学习的就是一个 noise-conditioned score network:\n$$s_{\\theta}\\left( x_{t},t \\right) \\approx \\nabla_{x_{t}}\\log p\\left( x_{t} \\right)$$采取 DSM（Denoising Score Matching）损失：\n$$\\mathcal{L} = {\\mathbb{E}}_{x,z,t}\\left\\lbrack \\lambda(t)\\left\\| {s_{\\theta}\\left( x + \\sigma_{t}z,t \\right) + \\frac{z}{\\sigma_{t}}} \\right\\|^{2} \\right\\rbrack$$即 $s_{\\theta}\\left( x + \\sigma_{t}z,t \\right)$ 的真实值为\n$$\\nabla\\log\\mathcal{N}(u;x,\\sigma_{t}^{2}) = \\nabla\\frac{{- (u - x)}^{2}}{2\\sigma_{t}^{2}} = - \\frac{u - x}{\\sigma_{t}^{2}} = - \\frac{z}{\\sigma_{t}}$$而 $\\lambda(t)$ 是一个权重函数，用于平衡不同噪声水平下的损失贡献. 常见的选择是\n$$\\lambda(t) = \\sigma_{t}^{2}$$采样/去噪 条件 Diffusion Model 给定条件 $c$, 需要\n$$\\nabla_{x}\\log p\\left( x|c \\right)$$Bayes 公式：\n$$\\nabla_{x}\\log p\\left( x|c \\right) = \\nabla_{x}\\log p(x) + \\nabla_{x}\\log p\\left( c|x \\right)$$如何得到 $\\nabla_{x}\\log p\\left( c|x \\right)$:\nclassifier guidance：基于 $x_{t}$ 的分类器，通过反向传播获取梯度。 通过给 $\\nabla_{x}\\log p\\left( c|x \\right)$ 乘以一个系数 $s \u003e 1$，可以增强条件信息的影响，得到更符合条件的样本生成结果.\nClassifier-Free Diffusion Guidance (CFG) 不使用分类器，而是定义两种去噪模型的score：\n条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma,c \\right) - x_{0} \\right)$\n无条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right)$\n其中 $D_{\\theta}$ 是去噪器, 使用一个 null 条件（如全零向量）来表示无条件模型. 则上式的等价形式\n$$\\begin{aligned} \\nabla_{x}\\log p\\left( x|c \\right) \u0026 = \\nabla_{x}\\log p(x) + S\\nabla_{x}\\log p\\left( c|x \\right) \\\\ \u0026 = \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) + S\\left( \\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) - \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\right) \\\\ \u0026 = S\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) + (1 - S)\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\\\ \u0026 = \\frac{1}{\\sigma^{2}}\\left( SD_{\\theta}\\left( x_{t},\\sigma,c \\right) + (1 - S)D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right) \\end{aligned}$$即用二者的凸组合来进行去噪采样.\n","permalink":"http://localhost:1313/posts/2025-12-26-diffusion/","summary":"\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nt\"\u003emenu\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"nt\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/categories/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e10\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/tags/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e20\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ehttps://example.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e30\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch1 id=\"diffusion-model\"\u003eDiffusion Model\u003c/h1\u003e\n\u003ch2 id=\"加噪过程\"\u003e加噪过程\u003c/h2\u003e\n\u003cp\u003e定义一个\u003cstrong\u003e马尔可夫链\u003c/strong\u003e，从数据 $x_{0} \\sim q(x)$\n开始，每一步加一点噪声：\u003c/p\u003e","title":"D"},{"content":"证据下界 ELBO 在最大似然估计（Maximum Likelihood Estimation, MLE）中，目标是最大化观测数据 $x$ 的对数似然.\n参数 $\\theta$ 的对数似然（log likelihood）的定义为\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布 $q(z)$，有\n$$ \\begin{aligned} \\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\ \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\end{aligned} $$由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\n$$ \\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack. $$取等条件 Jensen 不等式能够取等，当且仅当对于所有 $z$, $\\frac{p_{\\theta}(x,z)}{q(z)}$ 为常数 $c$. 因此\n$$ \\begin{aligned} p_{\\theta}(x) \u0026= \\sum_{z}p_{\\theta}(x,z) = c\\sum_{z}q(z) = c \\\\ q(z) \u0026= \\frac{p_{\\theta}(x,z)}{p_{\\theta}(x)} = p_{\\theta}\\left( z|x \\right). \\end{aligned} $$这里的 $q(z)$ 可以是任意分布，但使用中常用 $q(z) = q_{\\varphi}\\left( z|x \\right)$，即 $z$ 的近似后验分布，而近似后验分布越接近真实后验分布 $p_{\\theta}\\left( z|x \\right)$，ELBO 越接近对数似然.\nKL散度 任意分布 $p(x)$ 的信息熵定义为\n$$H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log p(x) \\right\\rbrack$$即对随机事件编码长度的期望值. 如果认为 $x$ 服从另一分布 $q(x)$，在\u0026quot;真实\u0026quot;分布 $p(x)$ 下的编码长度期望值定义为交叉熵：\n$$H(p,q) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log q(x) \\right\\rbrack.$$KL散度即定义为“额外的”编码长度\n$$\\text{ KL}\\left( p\\|q \\right) = H(p,q) - H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack.$$ KL散度描述了两个分布的差异程度，但是不是距离度量，因为不满足对称性和三角不等式.\nKL 散度的非负性 对于任意分布 $p(x)$ 和 $q(x)$，有 $\\text{KL}(p \\|q) \\ge 0$，因为\n$$ \\begin{aligned} \\text{ KL}\\left( p\\|q \\right) \u0026 = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack \\\\ \u0026 = - {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log\\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \\left( \\text{Jensen} \\right) \u0026 \\geq - \\log{\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \u0026 = - \\log\\int_{x}p(x)\\left( \\frac{q(x)}{p(x)} \\right)dx \\\\ \u0026 = - \\log\\int_{x}q(x)dx \\\\ \u0026 = - \\log 1 \\\\ \u0026 = 0. \\end{aligned} $$易知当且仅当 $p = q$ 时，$\\text{KL}\\left( p\\|q \\right) = 0$.\nELBO 等价形式 回到 ELBO，ELBO 和真实对数似然的差距为\n$$ \\begin{aligned} \\ell(\\theta) - \\mathcal{F}(q,\\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x) - \\log p_{\\theta}(x,z) + \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack - \\log p_{\\theta}\\left( z|x \\right) + \\log q(z) \\right\\rbrack \\\\ \u0026= \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right) \\geq 0. \\end{aligned} $$因此，ELBO 等价于\n$$\\mathcal{F}(q,\\theta) = \\ell(\\theta) - \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right)$$显然，取等条件同样为 $q(z) = p_{\\theta}\\left( z|x \\right)$. 而一般的问题中，通常采用以下形式：\n$$ \\begin{aligned} \\mathcal{F}(q, \\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{p_{\\theta}(z)} \\right\\rbrack - \\left( {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(z) \\right\\rbrack \\right) \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q(z)\\|p_{\\theta}(z) \\right) \\end{aligned} $$EM EM 算法的目标是最大化参数 $\\theta$ 对数似然：\n$$\\ell(\\theta) = \\log p\\left( x|\\theta \\right)$$第 $i$ 步的参数和隐变量分布分别记为 $\\theta^{(i)}$ 和 $q^{(i)}(z)$.\nE 步 最大化 $\\ell(\\theta^{(i)})$ 的 ELBO，即取等条件\n$$q^{(i + 1)}(z) = p_{\\theta^{(i)}}\\left( z|x \\right)$$M 步 更新参数 $\\theta^{(i)}$ 以最大化 ELBO， $$\\theta^{(i + 1)} = \\arg\\max\\limits_{\\theta}\\mathcal{F}(q^{(i + 1)},\\theta)$$收敛性 $$\\ell(\\theta^{(i + 1)})\\underset{\\text{ELBO}}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i + 1)})\\underset{\\arg\\max}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i)})\\underset{\\text{满足取等条件}}{=}\\ell(\\theta^{(i)})$$因此对数似然单调不减.\n例子：高斯混合模型 GMM 假设观测数据 $x$ 来自 $K$ 个高斯分布的混合：\n$$p_{\\theta}(x) = \\sum_{k = 1}^{K}\\pi_{k}\\mathcal{N}(x|\\mu_{k},\\Sigma_{k})$$其中 $\\theta = \\left\\{ \\pi_{k},\\mu_{k},\\Sigma_{k} \\right\\}_{k=1}^K$ 是模型参数，$\\pi_{k}$ 是混合系数，满足 $\\sum_{k = 1}^{K}\\pi_{k} = 1$. 数据样本为 $\\left\\{ x^{i} \\right\\}_{i = 1}^{N}$，引入隐变量 $z$ 表示样本属于哪个高斯分布, $z^{i} = k$ 表示样本 $x^{i}$ 来自第 $k$ 个高斯分布.\nE 步 计算后验概率（责任度）：\n$$ \\begin{aligned} \\gamma_{z^{i} = k} \u0026 \\leftarrow p_{\\theta}\\left( z^{i} = k|x^{i} \\right) \\\\ \u0026 = \\frac{\\pi_{k}\\mathcal{N}(x^{i}|\\mu_{k},\\Sigma_{k})}{\\sum_{j = 1}^{K}\\pi_{j}\\mathcal{N}(x^{i}|\\mu_{j},\\Sigma_{j})} \\end{aligned} $$M 步 更新参数：\n$$\\theta = \\arg\\max\\limits_{\\theta}\\mathcal{F}(\\gamma,\\theta)$$即在已知责任度 $\\gamma_{z^{i} = k}$ 下，最大化似然的参数. 定义 $\\begin{aligned} N_{k} \u0026 = \\sum_{i = 1}^{N}\\gamma_{z^{i} = k} \\end{aligned}$,\n则更新步骤为\n$$ \\begin{aligned} \\pi_{k} \u0026 \\leftarrow \\frac{N_{k}}{N} \\\\ \\mu_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}x^{i} \\\\ \\Sigma_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}\\left( x^{i} - \\mu_{k} \\right)\\left( x^{i} - \\mu_{k} \\right)^{\\top} \\end{aligned} $$VAE 普通的自编码器（Autoencoder）就是编码\u0026ndash;解码：\n编码器把输入数据 $x$ 映射到一个隐空间向量 $z$；\n解码器把 $z$ 还原回数据空间，得到重构 $\\hat{x}$.\n但是，普通自编码器学习到的 $z$ 没有概率解释，不能直接采样用于生成.\nVAE 的关键思想是：\n给隐变量 $z$ 加一个概率分布的解释，并用变分推断来学习这个分布.\n编码器不再输出一个确定向量，而是输出一个 分布参数（均值 $\\mu(x)$、方差 $\\sigma^{2}(x)$）\n从这个分布中采样 $z \\sim q_{\\varphi(z|x)}$，再送给解码器生成 $\\hat{x}$.\n这样隐空间就被正则化成一个连续、平滑的概率空间，可以用来插值、采样、生成新样本.\n先验分布 $p(z)$ 隐变量 $z$ 的先验分布 $p(z)$ 通常取标准正态分布 $\\mathcal{N}(0,I)$.\n解码器（生成分布） $p_{\\theta}\\left( x|z \\right)$ 网络参数 $\\theta$ 输入隐变量 $z$，输出数据 $x$ 的分布参数，即高斯分布的均值 $\\mu(z)$ 和方差 $\\Sigma(z)$.\n编码器（近似后验分布）$q_{\\varphi}\\left( z|x \\right)$ 使用 $q_{\\varphi}\\left( z|x \\right)$ 拟合\u0026quot;真实\u0026quot;后验分布 $p_{\\theta}\\left( z|x \\right)$.同样使用神经网络参数 $\\varphi$，输入数据 $x$，输出隐变量 $z$ 的分布参数.\n\u0026ldquo;近似\u0026quot;后验 和 \u0026ldquo;真实\u0026quot;后验 \u0026ldquo;真实\u0026quot;的后验分布由贝叶斯公式得出\n$$ \\begin{aligned} p_{\\theta}\\left( x|z \\right) \u0026= \\frac{p_{\\theta}\\left( x|z \\right)p(z)}{p_{\\theta}(x)} \\\\ p_{\\theta}(x) \u0026= \\int p_{\\theta}\\left( x|z \\right)p(z)dz \\end{aligned} $$因此真实的后验不可解，使用近似后验 $q_{\\varphi}\\left( z|x \\right)$ 来代替.\nELBO 和损失函数 使用 ELBO 替代对数似然：\n$$\\log p_{\\theta}(x) \\geq {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$其中\n${\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack$ 是重构误差，衡量解码器重构 $\\hat{x}$ 与输入 $x$ 的差异；\n$\\text{KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$ 是正则化项，使近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 尽量接近先验分布 $p(z)$（标准正态分布）.\n训练和重参数化 目前我们有\n编码器 $q_{\\varphi}\\left( z|x \\right)$，输入 $x$，输出隐变量 $z$ 的高斯分布参数 $\\mu(x),\\sigma^{2}(x)$；\n解码器 $p_{\\theta}\\left( x|z \\right)$，输入隐变量 $z$，输出重构 $\\hat{x}$ 的分布；\n先验分布 $p(z)$，通常取标准正态分布 $\\mathcal{N}(0,I)$.\n损失函数 ELBO $$\\mathcal{L} = - {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack + \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$ 训练时，期望项（重构误差）没有解析解，使用 $z$ 的采样来近似. 为了保证采样 $z \\sim \\mathcal{N}(\\mu(x),\\sigma^{2}(x))$ 可导，使用重参数化技巧：\n$$ \\begin{array}{r} z = \\mu(x) + \\sigma(x) \\odot \\varepsilon, \\\\ \\end{array} $$其中 $\\varepsilon \\sim \\mathcal{N}(0,I)$ 是独立噪声.\n展开 KL 散度 记 $q_{\\text{agg }}(z) = {\\mathbb{E}}_{x \\sim P(x)}q\\left( z|x \\right)$,\n$$ \\begin{aligned} \\text{ELBO} \u0026= \\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right] - \\mathrm{KL}\\!\\left(q_{\\text{agg}}(z)\\|p(z)\\right) \\\\ \u0026= \\underbrace{\\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right]}_{\\text{重构项}} - \\underbrace{H\\!\\left(q_{\\text{agg}}(z),p(z)\\right)}_{\\text{交叉熵}} + \\underbrace{H\\!\\left(p(z)\\right)}_{\\text{熵}}. \\end{aligned} $$ 重构项：鼓励隐变量分布远离先验分布 $p(z)$，提高重构质量 交叉熵：把隐变量分布拉向先验分布 $p(z)$ 中心，会同时减小均值和方差 熵：鼓励隐变量分布增大方差，分布更扁平 VAE 的问题 Prior Hole VAE 的隐空间分布 $q_{\\text{agg }}(z)$ 往往只占据先验分布 $p(z)$ 的一小部分，导致从先验分布采样的 $z$ 很可能落在\u0026quot;空洞\u0026quot;区域，解码器无法生成有效样本.\nPosterior Collapse 如果解码器足够强大，例如 autoregressive 模型，可以不依赖 $z$, 或者仅从 $z$ 的一部分维度中重构输入 $x$. 即 $z$ 的某些维度对重构没有贡献，导致这些维度的近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 退化为先验分布 $p(z)$，从而无法学习到有效的隐表示.\n$$\\exists i\\ s.t.\\ \\forall x,q_{\\varphi}\\left( z_{i}|x \\right) = p\\left( z_{i} \\right)$$Vector Quantized VAE(VQ VAE) 让隐变量 $z$ 取离散值，而不是连续值. 定义一个有限的码本（codebook），编码器输出一个向量 $e_{i}$，然后将 $e_{i}$ 映射到码本中距离最近的离散向量 $e_{k}$.\n解决了 Prior Hole 和 Posterior Collapse 问题，但训练时需要使用特殊的技巧（如直通估计器）来处理离散变量的不可导问题.\n","permalink":"http://localhost:1313/posts/elbo-em-vae/","summary":"\u003ch1 id=\"证据下界-elbo\"\u003e证据下界 ELBO\u003c/h1\u003e\n\u003cp\u003e在最大似然估计（Maximum Likelihood Estimation,\nMLE）中，目标是最大化观测数据 $x$ 的对数似然.\u003c/p\u003e\n\u003cp\u003e参数 $\\theta$ 的对数似然（log likelihood）的定义为\u003c/p\u003e\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$\u003cp\u003e其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布\n$q(z)$，有\u003c/p\u003e\n$$\n\\begin{aligned}\n\\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\\n \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack\n\\end{aligned}\n$$\u003cp\u003e由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\u003c/p\u003e\n$$\n\\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack.\n$$\u003ch2 id=\"取等条件\"\u003e取等条件\u003c/h2\u003e\n\u003cp\u003eJensen 不等式能够取等，当且仅当对于所有 $z$,\n$\\frac{p_{\\theta}(x,z)}{q(z)}$\n为常数 $c$.\n因此\u003c/p\u003e","title":"ELBO，EM和VAE"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 menu: main: - identifier: categories name: categories url: /categories/ weight: 10 - identifier: tags name: tags url: /tags/ weight: 20 - identifier: example name: example.org url: https://example.org weight: 30 Diffusion Model 加噪过程 定义一个马尔可夫链，从数据 $x_{0} \\sim q(x)$ 开始，每一步加一点噪声：\n$$q\\left( x_{t}~|~x_{t - 1} \\right) = \\mathcal{N}(x_{t};\\sqrt{1 - \\beta_{t}}x_{t - 1},\\beta_{t}I)$$使用重参数化，等价于\n$$x_{t} = \\sqrt{1 - \\beta_{t}}x_{t - 1} + \\sqrt{\\beta_{t}}\\varepsilon_{t},\\quad\\varepsilon_{t} \\sim N(0,I),$$其中 $\\beta$ 是一系列预定义的参数.\n对于两个高斯分布 $x_{1} \\sim \\mathcal{N}(\\mu_{1},\\sigma_{1}^{2})$ 和 $x_{2} \\sim \\mathcal{N}(\\mu_{2},\\sigma_{2}^{2})$，我们有：\n$$x_{1} + x_{2} \\sim \\mathcal{N}(\\mu_{1} + \\mu_{2},\\sigma_{1}^{2} + \\sigma_{2}^{2})$$于是定义 $\\alpha_{t} = 1 - \\beta_{t}$，则\n$$\\begin{aligned} x_{t} \u0026 = \\sqrt{\\alpha_{t}}x_{t - 1} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{\\alpha_{t}\\left( 1 - \\alpha_{t - 1} \\right)}\\varepsilon_{t} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}}\\varepsilon \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}x_{t - 3} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}\\varepsilon \\\\ \u0026 = \\ldots \\end{aligned}$$定义 ${\\overline{\\alpha}}_{t} = \\prod_{s = 1}^{t}\\alpha_{s}$, 得到 $x_{t}$ 的封闭形式\n$$x_{t} = \\sqrt{{\\overline{\\alpha}}_{t}}x_{0} + \\sqrt{1 - {\\overline{\\alpha}}_{t}}\\varepsilon,\\quad\\varepsilon \\sim N(0,I).$$即\n$$q\\left( x_{t}~|~x_{0} \\right) = \\mathcal{N}(x_{t};\\sqrt{{\\overline{\\alpha}}_{t}}x_{0},\\left( 1 - {\\overline{\\alpha}}_{t} \\right)I)$$因为 $\\alpha_{t} \u003c 1$, 因此 ${\\overline{\\alpha}}_{\\infty} \\rightarrow 0$，此时 $q\\left( x_{t}~|~x_{0} \\right) \\rightarrow \\mathcal{N}(0,I)$. 即随着 $t$ 增大，$x_{t}$ 趋近于纯噪声.\n去噪过程 我们的目标是找到加噪过程 $q\\left( x_{t}~|~x_{t - 1} \\right)$ 的逆过程，即逐步去噪的条件高斯分布\n$$q\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{t}\\left( x_{t} \\right),\\Sigma_{t}\\left( x_{t} \\right))$$$q\\left( x_{t - 1}~|~x_{t} \\right)$不可解，因此使用一个模型 $\\theta$ 近似，以 $x_{t}$ 和 $t$ 作为输入，输出分布参数\n$$p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{\\theta}\\left( x_{t},t \\right),\\Sigma_{\\theta}\\left( x_{t},t \\right))$$最大似然估计 MLE 目标是最小化去噪模型 $p_{\\theta}$ 对初始数据 $x_{0}$ 的负对数似然：\n$$\\mathcal{L}(\\theta) = - \\log p_{\\theta}\\left( x_{0} \\right)$$同样地，使用变分下界 ELBO 优化，其中 $x_{0}$ 是已知变量，$x_{1:T}$ 是隐变量：\n$$\\begin{array}{r} \\mathcal{F}(q,\\theta) = {\\mathbb{E}}_{q\\left( x_{1:T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0:T} \\right) - \\log q\\left( x_{1:T}|x_{0} \\right) \\right\\rbrack \\\\ \\mathcal{L}(\\theta) \\leq - \\mathcal{F}(q,\\theta) \\end{array}$$根据马尔可夫性质，\n$$\\begin{array}{r} q\\left( x_{1:T}|x_{0} \\right) = q\\left( x_{T}~|~x_{0} \\right)\\prod_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\\\ p_{\\theta}\\left( x_{0:T} \\right) = p_{\\theta}\\left( x_{T} \\right)\\prod_{t = 1}^{T}p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\end{array}$$代入得到 $\\mathcal{F}(q,\\theta)$\n$$\\begin{aligned} = \u0026 {\\mathbb{E}}_{q\\left( x_{1}:x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) + \\sum_{t = 1}^{T}\\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) - \\sum_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t},x_{t - 1}|x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}{\\mathbb{E}}_{q\\left( x_{t - 1}|x_{t},x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right) \\\\ \u0026 - \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right) \\end{aligned}$$分别记作\n$$\\mathcal{L} ≔ - \\mathcal{F}(q,\\theta) = \\mathcal{L}_{0} + \\sum_{t = 2}^{T}\\mathcal{L}_{t - 1} + \\mathcal{L}_{T}.$$其中\n初始项 $\\mathcal{L}_{0} = - {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack$\n最小化最后一步 $x_{1}$ 到 $x_{0}$ 的重建误差\n当 $p_{\\theta}$ 取高斯分布时，相当于最小化均方误差 MSE: ${\\mathbb{E}}\\left\\lbrack \\left\\| {x_{1} - x_{0}} \\right\\|^{2} \\right\\rbrack$\n中间项 $\\mathcal{L}_{t - 1} = {\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right)$\n让模型 $p_{\\theta}$ 学习去噪过程，缩小和真实后验 $q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)$ 的差距。\n$$q\\left( x_{t - 1}|x_{t},x_{0} \\right) = \\frac{q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)}{q\\left( x_{t}|x_{0} \\right)} \\propto q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)$$ 终端项 $\\mathcal{L}_{T} = \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right)$\n让模型 $p_{\\theta}$ 的先验分布接近 $q\\left( x_{T}~|~x_{0} \\right)$\n对于足够大的 $T$，$q\\left( x_{T}~|~x_{0} \\right) \\approx \\mathcal{N}(0,I)$，而先验 $p_{\\theta}\\left( x_{T} \\right)$ 被定义为 $\\mathcal{N}(0,I)$\n因此该项可以忽略不计.\nScore-based Diffusion Model \u0026amp; Langevin dynamics Langevin dynamics Boltzmann distribution 统计力学的玻尔兹曼分布（Boltzmann distribution）指出一个系统的状态分布为\n$$p_{i} \\propto \\exp( - \\frac{\\varepsilon_{i}}{kT})$$ []{#eq:boltzmann}\n其中 $\\varepsilon_{i}$ 是状态 $i$ 的能量，$k$ 是玻尔兹曼常数，$T$ 是温度.\nLangevin equation 而 Langevin equation 描述的是粒子在（一维）势能场中的布朗运动，\n$$dx_{t} = - \\frac{1}{\\gamma}\\nabla_{x}U\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t}$$ []{#eq:langevin}\n其中\n$x$ 是粒子位置\n$U(x)$ 是势能函数\n$\\gamma$ 是阻尼系数\n$W_{t}$ 是标准 Wiener 过程：$W_{t + \\Delta} = W_{t} + \\mathcal{N}(0,\\Delta)$\n根据 Boltzmann distribution\n$$U(x) = - kT\\log p(x) + \\text{ constant},$$代入得\n$$\\begin{aligned} dx_{t} \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\\\ \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\end{aligned}$$方程在离散时间 $x_{k} ≔ x(k\\tau)$ 下的形式为\n$$\\begin{array}{rlr} x_{k + 1} - x_{k} \u0026 = - \\frac{kT}{\\gamma}\\tau\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{\\frac{2kT}{\\gamma}\\tau}\\xi\\quad \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\\\ \u0026 = - \\eta\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{2\\eta}\\xi \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\end{array}$$其中 $\\eta = \\frac{kT}{\\gamma}\\tau$ 是步长. 回忆 $x_{t}$ 描述的是粒子的随机位置，因此\n$$x_{k} \\sim p(x)$$即已知对数梯度 $\\nabla\\log p(x)$ 时，Langevin dynamics 迭代的过程可以对分布 $p(x)$ 采样，而不需要显式地知道 $p(x)$ 的形式。\n观察迭代形式，这实际上是一个带随机扰动的对数梯度上升过程，梯度项使得粒子趋向于高概率区域，而随机扰动则保证了采样的多样性.\nSimulated Annealing 实际上，如果令玻尔兹曼分布 ([@eq]:boltzmann) 中势能不变，$T$ 逐渐收敛至 $0$, 则分布收敛到单点分布 $p(x) = \\delta(x - x^{\\ast})$，其中 $x^{\\ast} = \\arg\\min\\limits_{x}U(x)$ 是势能的最小值点, 此时 Langevin equation ([@eq]:langevin) 中的随机扰动项收敛至 $0$，Langevin dynamics 退化为势能的对数梯度下降. 而温度 $T$ 的收敛速度控制了采样过程的随机性，快速的降温会导致探索不足，陷入局部势能极小值，反之则有更大概率达到势能全局最小值。这种模拟降温过程的方法即为模拟退火 Simulated Annealing.\nScore-based Diffusion Model 定义 score 函数，即数据分布的对数梯度：\n$$\\text{ score}(x) = \\nabla_{x}\\log p(x)$$根据 Langevin dynamics ([@eq]:langevin)，只要能估计出数据分布的 score 函数，即可通过迭代采样得到数据分布的样本.\n学习 score 在 Score-based Diffusion Model 中，唯一需要学习的就是一个 noise-conditioned score network:\n$$s_{\\theta}\\left( x_{t},t \\right) \\approx \\nabla_{x_{t}}\\log p\\left( x_{t} \\right)$$采取 DSM（Denoising Score Matching）损失：\n$$\\mathcal{L} = {\\mathbb{E}}_{x,z,t}\\left\\lbrack \\lambda(t)\\left\\| {s_{\\theta}\\left( x + \\sigma_{t}z,t \\right) + \\frac{z}{\\sigma_{t}}} \\right\\|^{2} \\right\\rbrack$$即 $s_{\\theta}\\left( x + \\sigma_{t}z,t \\right)$ 的真实值为\n$$\\nabla\\log\\mathcal{N}(u;x,\\sigma_{t}^{2}) = \\nabla\\frac{{- (u - x)}^{2}}{2\\sigma_{t}^{2}} = - \\frac{u - x}{\\sigma_{t}^{2}} = - \\frac{z}{\\sigma_{t}}$$而 $\\lambda(t)$ 是一个权重函数，用于平衡不同噪声水平下的损失贡献. 常见的选择是\n$$\\lambda(t) = \\sigma_{t}^{2}$$采样/去噪 条件 Diffusion Model 给定条件 $c$, 需要\n$$\\nabla_{x}\\log p\\left( x|c \\right)$$Bayes 公式：\n$$\\nabla_{x}\\log p\\left( x|c \\right) = \\nabla_{x}\\log p(x) + \\nabla_{x}\\log p\\left( c|x \\right)$$如何得到 $\\nabla_{x}\\log p\\left( c|x \\right)$:\nclassifier guidance：基于 $x_{t}$ 的分类器，通过反向传播获取梯度。 通过给 $\\nabla_{x}\\log p\\left( c|x \\right)$ 乘以一个系数 $s \u003e 1$，可以增强条件信息的影响，得到更符合条件的样本生成结果.\nClassifier-Free Diffusion Guidance (CFG) 不使用分类器，而是定义两种去噪模型的score：\n条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma,c \\right) - x_{0} \\right)$\n无条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right)$\n其中 $D_{\\theta}$ 是去噪器, 使用一个 null 条件（如全零向量）来表示无条件模型. 则上式的等价形式\n$$\\begin{aligned} \\nabla_{x}\\log p\\left( x|c \\right) \u0026 = \\nabla_{x}\\log p(x) + S\\nabla_{x}\\log p\\left( c|x \\right) \\\\ \u0026 = \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) + S\\left( \\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) - \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\right) \\\\ \u0026 = S\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) + (1 - S)\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\\\ \u0026 = \\frac{1}{\\sigma^{2}}\\left( SD_{\\theta}\\left( x_{t},\\sigma,c \\right) + (1 - S)D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right) \\end{aligned}$$即用二者的凸组合来进行去噪采样.\n","permalink":"http://localhost:1313/posts/2025-12-26-diffusion/","summary":"\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nt\"\u003emenu\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"nt\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/categories/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e10\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/tags/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e20\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ehttps://example.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e30\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch1 id=\"diffusion-model\"\u003eDiffusion Model\u003c/h1\u003e\n\u003ch2 id=\"加噪过程\"\u003e加噪过程\u003c/h2\u003e\n\u003cp\u003e定义一个\u003cstrong\u003e马尔可夫链\u003c/strong\u003e，从数据 $x_{0} \\sim q(x)$\n开始，每一步加一点噪声：\u003c/p\u003e","title":"Diffusion Model"},{"content":"证据下界 ELBO 在最大似然估计（Maximum Likelihood Estimation, MLE）中，目标是最大化观测数据 $x$ 的对数似然.\n参数 $\\theta$ 的对数似然（log likelihood）的定义为\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布 $q(z)$，有\n$$ \\begin{aligned} \\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\ \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\end{aligned} $$由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\n$$ \\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack. $$取等条件 Jensen 不等式能够取等，当且仅当对于所有 $z$, $\\frac{p_{\\theta}(x,z)}{q(z)}$ 为常数 $c$. 因此\n$$ \\begin{aligned} p_{\\theta}(x) \u0026= \\sum_{z}p_{\\theta}(x,z) = c\\sum_{z}q(z) = c \\\\ q(z) \u0026= \\frac{p_{\\theta}(x,z)}{p_{\\theta}(x)} = p_{\\theta}\\left( z|x \\right). \\end{aligned} $$这里的 $q(z)$ 可以是任意分布，但使用中常用 $q(z) = q_{\\varphi}\\left( z|x \\right)$，即 $z$ 的近似后验分布，而近似后验分布越接近真实后验分布 $p_{\\theta}\\left( z|x \\right)$，ELBO 越接近对数似然.\nKL散度 任意分布 $p(x)$ 的信息熵定义为\n$$H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log p(x) \\right\\rbrack$$即对随机事件编码长度的期望值. 如果认为 $x$ 服从另一分布 $q(x)$，在\u0026quot;真实\u0026quot;分布 $p(x)$ 下的编码长度期望值定义为交叉熵：\n$$H(p,q) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log q(x) \\right\\rbrack.$$KL散度即定义为“额外的”编码长度\n$$\\text{ KL}\\left( p\\|q \\right) = H(p,q) - H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack.$$ KL散度描述了两个分布的差异程度，但是不是距离度量，因为不满足对称性和三角不等式.\nKL 散度的非负性 对于任意分布 $p(x)$ 和 $q(x)$，有 $\\text{KL}(p \\|q) \\ge 0$，因为\n$$ \\begin{aligned} \\text{ KL}\\left( p\\|q \\right) \u0026 = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack \\\\ \u0026 = - {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log\\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \\left( \\text{Jensen} \\right) \u0026 \\geq - \\log{\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \u0026 = - \\log\\int_{x}p(x)\\left( \\frac{q(x)}{p(x)} \\right)dx \\\\ \u0026 = - \\log\\int_{x}q(x)dx \\\\ \u0026 = - \\log 1 \\\\ \u0026 = 0. \\end{aligned} $$易知当且仅当 $p = q$ 时，$\\text{KL}\\left( p\\|q \\right) = 0$.\nELBO 等价形式 回到 ELBO，ELBO 和真实对数似然的差距为\n$$ \\begin{aligned} \\ell(\\theta) - \\mathcal{F}(q,\\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x) - \\log p_{\\theta}(x,z) + \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack - \\log p_{\\theta}\\left( z|x \\right) + \\log q(z) \\right\\rbrack \\\\ \u0026= \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right) \\geq 0. \\end{aligned} $$因此，ELBO 等价于\n$$\\mathcal{F}(q,\\theta) = \\ell(\\theta) - \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right)$$显然，取等条件同样为 $q(z) = p_{\\theta}\\left( z|x \\right)$. 而一般的问题中，通常采用以下形式：\n$$ \\begin{aligned} \\mathcal{F}(q, \\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{p_{\\theta}(z)} \\right\\rbrack - \\left( {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(z) \\right\\rbrack \\right) \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q(z)\\|p_{\\theta}(z) \\right) \\end{aligned} $$EM EM 算法的目标是最大化参数 $\\theta$ 对数似然：\n$$\\ell(\\theta) = \\log p\\left( x|\\theta \\right)$$第 $i$ 步的参数和隐变量分布分别记为 $\\theta^{(i)}$ 和 $q^{(i)}(z)$.\nE 步 最大化 $\\ell(\\theta^{(i)})$ 的 ELBO，即取等条件\n$$q^{(i + 1)}(z) = p_{\\theta^{(i)}}\\left( z|x \\right)$$M 步 更新参数 $\\theta^{(i)}$ 以最大化 ELBO， $$\\theta^{(i + 1)} = \\arg\\max\\limits_{\\theta}\\mathcal{F}(q^{(i + 1)},\\theta)$$收敛性 $$\\ell(\\theta^{(i + 1)})\\underset{\\text{ELBO}}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i + 1)})\\underset{\\arg\\max}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i)})\\underset{\\text{满足取等条件}}{=}\\ell(\\theta^{(i)})$$因此对数似然单调不减.\n例子：高斯混合模型 GMM 假设观测数据 $x$ 来自 $K$ 个高斯分布的混合：\n$$p_{\\theta}(x) = \\sum_{k = 1}^{K}\\pi_{k}\\mathcal{N}(x|\\mu_{k},\\Sigma_{k})$$其中 $\\theta = \\left\\{ \\pi_{k},\\mu_{k},\\Sigma_{k} \\right\\}_{k=1}^K$ 是模型参数，$\\pi_{k}$ 是混合系数，满足 $\\sum_{k = 1}^{K}\\pi_{k} = 1$. 数据样本为 $\\left\\{ x^{i} \\right\\}_{i = 1}^{N}$，引入隐变量 $z$ 表示样本属于哪个高斯分布, $z^{i} = k$ 表示样本 $x^{i}$ 来自第 $k$ 个高斯分布.\nE 步 计算后验概率（责任度）：\n$$ \\begin{aligned} \\gamma_{z^{i} = k} \u0026 \\leftarrow p_{\\theta}\\left( z^{i} = k|x^{i} \\right) \\\\ \u0026 = \\frac{\\pi_{k}\\mathcal{N}(x^{i}|\\mu_{k},\\Sigma_{k})}{\\sum_{j = 1}^{K}\\pi_{j}\\mathcal{N}(x^{i}|\\mu_{j},\\Sigma_{j})} \\end{aligned} $$M 步 更新参数：\n$$\\theta = \\arg\\max\\limits_{\\theta}\\mathcal{F}(\\gamma,\\theta)$$即在已知责任度 $\\gamma_{z^{i} = k}$ 下，最大化似然的参数. 定义 $\\begin{aligned} N_{k} \u0026 = \\sum_{i = 1}^{N}\\gamma_{z^{i} = k} \\end{aligned}$,\n则更新步骤为\n$$ \\begin{aligned} \\pi_{k} \u0026 \\leftarrow \\frac{N_{k}}{N} \\\\ \\mu_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}x^{i} \\\\ \\Sigma_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}\\left( x^{i} - \\mu_{k} \\right)\\left( x^{i} - \\mu_{k} \\right)^{\\top} \\end{aligned} $$VAE 普通的自编码器（Autoencoder）就是编码\u0026ndash;解码：\n编码器把输入数据 $x$ 映射到一个隐空间向量 $z$；\n解码器把 $z$ 还原回数据空间，得到重构 $\\hat{x}$.\n但是，普通自编码器学习到的 $z$ 没有概率解释，不能直接采样用于生成.\nVAE 的关键思想是：\n给隐变量 $z$ 加一个概率分布的解释，并用变分推断来学习这个分布.\n编码器不再输出一个确定向量，而是输出一个 分布参数（均值 $\\mu(x)$、方差 $\\sigma^{2}(x)$）\n从这个分布中采样 $z \\sim q_{\\varphi(z|x)}$，再送给解码器生成 $\\hat{x}$.\n这样隐空间就被正则化成一个连续、平滑的概率空间，可以用来插值、采样、生成新样本.\n先验分布 $p(z)$ 隐变量 $z$ 的先验分布 $p(z)$ 通常取标准正态分布 $\\mathcal{N}(0,I)$.\n解码器（生成分布） $p_{\\theta}\\left( x|z \\right)$ 网络参数 $\\theta$ 输入隐变量 $z$，输出数据 $x$ 的分布参数，即高斯分布的均值 $\\mu(z)$ 和方差 $\\Sigma(z)$.\n编码器（近似后验分布）$q_{\\varphi}\\left( z|x \\right)$ 使用 $q_{\\varphi}\\left( z|x \\right)$ 拟合\u0026quot;真实\u0026quot;后验分布 $p_{\\theta}\\left( z|x \\right)$.同样使用神经网络参数 $\\varphi$，输入数据 $x$，输出隐变量 $z$ 的分布参数.\n\u0026ldquo;近似\u0026quot;后验 和 \u0026ldquo;真实\u0026quot;后验 \u0026ldquo;真实\u0026quot;的后验分布由贝叶斯公式得出\n$$ \\begin{aligned} p_{\\theta}\\left( x|z \\right) \u0026= \\frac{p_{\\theta}\\left( x|z \\right)p(z)}{p_{\\theta}(x)} \\\\ p_{\\theta}(x) \u0026= \\int p_{\\theta}\\left( x|z \\right)p(z)dz \\end{aligned} $$因此真实的后验不可解，使用近似后验 $q_{\\varphi}\\left( z|x \\right)$ 来代替.\nELBO 和损失函数 使用 ELBO 替代对数似然：\n$$\\log p_{\\theta}(x) \\geq {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$其中\n${\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack$ 是重构误差，衡量解码器重构 $\\hat{x}$ 与输入 $x$ 的差异；\n$\\text{KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$ 是正则化项，使近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 尽量接近先验分布 $p(z)$（标准正态分布）.\n训练和重参数化 目前我们有\n编码器 $q_{\\varphi}\\left( z|x \\right)$，输入 $x$，输出隐变量 $z$ 的高斯分布参数 $\\mu(x),\\sigma^{2}(x)$；\n解码器 $p_{\\theta}\\left( x|z \\right)$，输入隐变量 $z$，输出重构 $\\hat{x}$ 的分布；\n先验分布 $p(z)$，通常取标准正态分布 $\\mathcal{N}(0,I)$.\n损失函数 ELBO $$\\mathcal{L} = - {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack + \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$ 训练时，期望项（重构误差）没有解析解，使用 $z$ 的采样来近似. 为了保证采样 $z \\sim \\mathcal{N}(\\mu(x),\\sigma^{2}(x))$ 可导，使用重参数化技巧：\n$$ \\begin{array}{r} z = \\mu(x) + \\sigma(x) \\odot \\varepsilon, \\\\ \\end{array} $$其中 $\\varepsilon \\sim \\mathcal{N}(0,I)$ 是独立噪声.\n展开 KL 散度 记 $q_{\\text{agg }}(z) = {\\mathbb{E}}_{x \\sim P(x)}q\\left( z|x \\right)$,\n$$ \\begin{aligned} \\text{ELBO} \u0026= \\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right] - \\mathrm{KL}\\!\\left(q_{\\text{agg}}(z)\\|p(z)\\right) \\\\ \u0026= \\underbrace{\\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right]}_{\\text{重构项}} - \\underbrace{H\\!\\left(q_{\\text{agg}}(z),p(z)\\right)}_{\\text{交叉熵}} + \\underbrace{H\\!\\left(p(z)\\right)}_{\\text{熵}}. \\end{aligned} $$ 重构项：鼓励隐变量分布远离先验分布 $p(z)$，提高重构质量 交叉熵：把隐变量分布拉向先验分布 $p(z)$ 中心，会同时减小均值和方差 熵：鼓励隐变量分布增大方差，分布更扁平 VAE 的问题 Prior Hole VAE 的隐空间分布 $q_{\\text{agg }}(z)$ 往往只占据先验分布 $p(z)$ 的一小部分，导致从先验分布采样的 $z$ 很可能落在\u0026quot;空洞\u0026quot;区域，解码器无法生成有效样本.\nPosterior Collapse 如果解码器足够强大，例如 autoregressive 模型，可以不依赖 $z$, 或者仅从 $z$ 的一部分维度中重构输入 $x$. 即 $z$ 的某些维度对重构没有贡献，导致这些维度的近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 退化为先验分布 $p(z)$，从而无法学习到有效的隐表示.\n$$\\exists i\\ s.t.\\ \\forall x,q_{\\varphi}\\left( z_{i}|x \\right) = p\\left( z_{i} \\right)$$Vector Quantized VAE(VQ VAE) 让隐变量 $z$ 取离散值，而不是连续值. 定义一个有限的码本（codebook），编码器输出一个向量 $e_{i}$，然后将 $e_{i}$ 映射到码本中距离最近的离散向量 $e_{k}$.\n解决了 Prior Hole 和 Posterior Collapse 问题，但训练时需要使用特殊的技巧（如直通估计器）来处理离散变量的不可导问题.\n","permalink":"http://localhost:1313/posts/elbo-em-vae/","summary":"\u003ch1 id=\"证据下界-elbo\"\u003e证据下界 ELBO\u003c/h1\u003e\n\u003cp\u003e在最大似然估计（Maximum Likelihood Estimation,\nMLE）中，目标是最大化观测数据 $x$ 的对数似然.\u003c/p\u003e\n\u003cp\u003e参数 $\\theta$ 的对数似然（log likelihood）的定义为\u003c/p\u003e\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$\u003cp\u003e其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布\n$q(z)$，有\u003c/p\u003e\n$$\n\\begin{aligned}\n\\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\\n \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack\n\\end{aligned}\n$$\u003cp\u003e由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\u003c/p\u003e\n$$\n\\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack.\n$$\u003ch2 id=\"取等条件\"\u003e取等条件\u003c/h2\u003e\n\u003cp\u003eJensen 不等式能够取等，当且仅当对于所有 $z$,\n$\\frac{p_{\\theta}(x,z)}{q(z)}$\n为常数 $c$.\n因此\u003c/p\u003e","title":"ELBO，EM和VAE"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 menu: main: - identifier: categories name: categories url: /categories/ weight: 10 - identifier: tags name: tags url: /tags/ weight: 20 - identifier: example name: example.org url: https://example.org weight: 30 Diffusion Model 加噪过程 定义一个马尔可夫链，从数据 $x_{0} \\sim q(x)$ 开始，每一步加一点噪声：\n$$q\\left( x_{t}~|~x_{t - 1} \\right) = \\mathcal{N}(x_{t};\\sqrt{1 - \\beta_{t}}x_{t - 1},\\beta_{t}I)$$使用重参数化，等价于\n$$x_{t} = \\sqrt{1 - \\beta_{t}}x_{t - 1} + \\sqrt{\\beta_{t}}\\varepsilon_{t},\\quad\\varepsilon_{t} \\sim N(0,I),$$其中 $\\beta$ 是一系列预定义的参数.\n对于两个高斯分布 $x_{1} \\sim \\mathcal{N}(\\mu_{1},\\sigma_{1}^{2})$ 和 $x_{2} \\sim \\mathcal{N}(\\mu_{2},\\sigma_{2}^{2})$，我们有：\n$$x_{1} + x_{2} \\sim \\mathcal{N}(\\mu_{1} + \\mu_{2},\\sigma_{1}^{2} + \\sigma_{2}^{2})$$于是定义 $\\alpha_{t} = 1 - \\beta_{t}$，则\n$$\\begin{aligned} x_{t} \u0026 = \\sqrt{\\alpha_{t}}x_{t - 1} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{\\alpha_{t}\\left( 1 - \\alpha_{t - 1} \\right)}\\varepsilon_{t} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}}\\varepsilon \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}x_{t - 3} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}\\varepsilon \\\\ \u0026 = \\ldots \\end{aligned}$$定义 ${\\overline{\\alpha}}_{t} = \\prod_{s = 1}^{t}\\alpha_{s}$, 得到 $x_{t}$ 的封闭形式\n$$x_{t} = \\sqrt{{\\overline{\\alpha}}_{t}}x_{0} + \\sqrt{1 - {\\overline{\\alpha}}_{t}}\\varepsilon,\\quad\\varepsilon \\sim N(0,I).$$即\n$$q\\left( x_{t}~|~x_{0} \\right) = \\mathcal{N}(x_{t};\\sqrt{{\\overline{\\alpha}}_{t}}x_{0},\\left( 1 - {\\overline{\\alpha}}_{t} \\right)I)$$因为 $\\alpha_{t} \u003c 1$, 因此 ${\\overline{\\alpha}}_{\\infty} \\rightarrow 0$，此时 $q\\left( x_{t}~|~x_{0} \\right) \\rightarrow \\mathcal{N}(0,I)$. 即随着 $t$ 增大，$x_{t}$ 趋近于纯噪声.\n去噪过程 我们的目标是找到加噪过程 $q\\left( x_{t}~|~x_{t - 1} \\right)$ 的逆过程，即逐步去噪的条件高斯分布\n$$q\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{t}\\left( x_{t} \\right),\\Sigma_{t}\\left( x_{t} \\right))$$$q\\left( x_{t - 1}~|~x_{t} \\right)$不可解，因此使用一个模型 $\\theta$ 近似，以 $x_{t}$ 和 $t$ 作为输入，输出分布参数\n$$p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{\\theta}\\left( x_{t},t \\right),\\Sigma_{\\theta}\\left( x_{t},t \\right))$$最大似然估计 MLE 目标是最小化去噪模型 $p_{\\theta}$ 对初始数据 $x_{0}$ 的负对数似然：\n$$\\mathcal{L}(\\theta) = - \\log p_{\\theta}\\left( x_{0} \\right)$$同样地，使用变分下界 ELBO 优化，其中 $x_{0}$ 是已知变量，$x_{1:T}$ 是隐变量：\n$$\\begin{array}{r} \\mathcal{F}(q,\\theta) = {\\mathbb{E}}_{q\\left( x_{1:T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0:T} \\right) - \\log q\\left( x_{1:T}|x_{0} \\right) \\right\\rbrack \\\\ \\mathcal{L}(\\theta) \\leq - \\mathcal{F}(q,\\theta) \\end{array}$$根据马尔可夫性质，\n$$\\begin{array}{r} q\\left( x_{1:T}|x_{0} \\right) = q\\left( x_{T}~|~x_{0} \\right)\\prod_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\\\ p_{\\theta}\\left( x_{0:T} \\right) = p_{\\theta}\\left( x_{T} \\right)\\prod_{t = 1}^{T}p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\end{array}$$代入得到 $\\mathcal{F}(q,\\theta)$\n$$\\begin{aligned} = \u0026 {\\mathbb{E}}_{q\\left( x_{1}:x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) + \\sum_{t = 1}^{T}\\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) - \\sum_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t},x_{t - 1}|x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}{\\mathbb{E}}_{q\\left( x_{t - 1}|x_{t},x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right) \\\\ \u0026 - \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right) \\end{aligned}$$分别记作\n$$\\mathcal{L} ≔ - \\mathcal{F}(q,\\theta) = \\mathcal{L}_{0} + \\sum_{t = 2}^{T}\\mathcal{L}_{t - 1} + \\mathcal{L}_{T}.$$其中\n初始项 $\\mathcal{L}_{0} = - {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack$\n最小化最后一步 $x_{1}$ 到 $x_{0}$ 的重建误差\n当 $p_{\\theta}$ 取高斯分布时，相当于最小化均方误差 MSE: ${\\mathbb{E}}\\left\\lbrack \\left\\| {x_{1} - x_{0}} \\right\\|^{2} \\right\\rbrack$\n中间项 $\\mathcal{L}_{t - 1} = {\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right)$\n让模型 $p_{\\theta}$ 学习去噪过程，缩小和真实后验 $q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)$ 的差距。\n$$q\\left( x_{t - 1}|x_{t},x_{0} \\right) = \\frac{q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)}{q\\left( x_{t}|x_{0} \\right)} \\propto q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)$$ 终端项 $\\mathcal{L}_{T} = \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right)$\n让模型 $p_{\\theta}$ 的先验分布接近 $q\\left( x_{T}~|~x_{0} \\right)$\n对于足够大的 $T$，$q\\left( x_{T}~|~x_{0} \\right) \\approx \\mathcal{N}(0,I)$，而先验 $p_{\\theta}\\left( x_{T} \\right)$ 被定义为 $\\mathcal{N}(0,I)$\n因此该项可以忽略不计.\nScore-based Diffusion Model \u0026amp; Langevin dynamics Langevin dynamics Boltzmann distribution 统计力学的玻尔兹曼分布（Boltzmann distribution）指出一个系统的状态分布为\n$$p_{i} \\propto \\exp( - \\frac{\\varepsilon_{i}}{kT})$$ []{#eq:boltzmann}\n其中 $\\varepsilon_{i}$ 是状态 $i$ 的能量，$k$ 是玻尔兹曼常数，$T$ 是温度.\nLangevin equation 而 Langevin equation 描述的是粒子在（一维）势能场中的布朗运动，\n$$dx_{t} = - \\frac{1}{\\gamma}\\nabla_{x}U\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t}$$ []{#eq:langevin}\n其中\n$x$ 是粒子位置\n$U(x)$ 是势能函数\n$\\gamma$ 是阻尼系数\n$W_{t}$ 是标准 Wiener 过程：$W_{t + \\Delta} = W_{t} + \\mathcal{N}(0,\\Delta)$\n根据 Boltzmann distribution\n$$U(x) = - kT\\log p(x) + \\text{ constant},$$代入得\n$$\\begin{aligned} dx_{t} \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\\\ \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\end{aligned}$$方程在离散时间 $x_{k} ≔ x(k\\tau)$ 下的形式为\n$$\\begin{array}{rlr} x_{k + 1} - x_{k} \u0026 = - \\frac{kT}{\\gamma}\\tau\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{\\frac{2kT}{\\gamma}\\tau}\\xi\\quad \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\\\ \u0026 = - \\eta\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{2\\eta}\\xi \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\end{array}$$其中 $\\eta = \\frac{kT}{\\gamma}\\tau$ 是步长. 回忆 $x_{t}$ 描述的是粒子的随机位置，因此\n$$x_{k} \\sim p(x)$$即已知对数梯度 $\\nabla\\log p(x)$ 时，Langevin dynamics 迭代的过程可以对分布 $p(x)$ 采样，而不需要显式地知道 $p(x)$ 的形式。\n观察迭代形式，这实际上是一个带随机扰动的对数梯度上升过程，梯度项使得粒子趋向于高概率区域，而随机扰动则保证了采样的多样性.\nSimulated Annealing 实际上，如果令玻尔兹曼分布 ([@eq]:boltzmann) 中势能不变，$T$ 逐渐收敛至 $0$, 则分布收敛到单点分布 $p(x) = \\delta(x - x^{\\ast})$，其中 $x^{\\ast} = \\arg\\min\\limits_{x}U(x)$ 是势能的最小值点, 此时 Langevin equation ([@eq]:langevin) 中的随机扰动项收敛至 $0$，Langevin dynamics 退化为势能的对数梯度下降. 而温度 $T$ 的收敛速度控制了采样过程的随机性，快速的降温会导致探索不足，陷入局部势能极小值，反之则有更大概率达到势能全局最小值。这种模拟降温过程的方法即为模拟退火 Simulated Annealing.\nScore-based Diffusion Model 定义 score 函数，即数据分布的对数梯度：\n$$\\text{ score}(x) = \\nabla_{x}\\log p(x)$$根据 Langevin dynamics ([@eq]:langevin)，只要能估计出数据分布的 score 函数，即可通过迭代采样得到数据分布的样本.\n学习 score 在 Score-based Diffusion Model 中，唯一需要学习的就是一个 noise-conditioned score network:\n$$s_{\\theta}\\left( x_{t},t \\right) \\approx \\nabla_{x_{t}}\\log p\\left( x_{t} \\right)$$采取 DSM（Denoising Score Matching）损失：\n$$\\mathcal{L} = {\\mathbb{E}}_{x,z,t}\\left\\lbrack \\lambda(t)\\left\\| {s_{\\theta}\\left( x + \\sigma_{t}z,t \\right) + \\frac{z}{\\sigma_{t}}} \\right\\|^{2} \\right\\rbrack$$即 $s_{\\theta}\\left( x + \\sigma_{t}z,t \\right)$ 的真实值为\n$$\\nabla\\log\\mathcal{N}(u;x,\\sigma_{t}^{2}) = \\nabla\\frac{{- (u - x)}^{2}}{2\\sigma_{t}^{2}} = - \\frac{u - x}{\\sigma_{t}^{2}} = - \\frac{z}{\\sigma_{t}}$$而 $\\lambda(t)$ 是一个权重函数，用于平衡不同噪声水平下的损失贡献. 常见的选择是\n$$\\lambda(t) = \\sigma_{t}^{2}$$采样/去噪 条件 Diffusion Model 给定条件 $c$, 需要\n$$\\nabla_{x}\\log p\\left( x|c \\right)$$Bayes 公式：\n$$\\nabla_{x}\\log p\\left( x|c \\right) = \\nabla_{x}\\log p(x) + \\nabla_{x}\\log p\\left( c|x \\right)$$如何得到 $\\nabla_{x}\\log p\\left( c|x \\right)$:\nclassifier guidance：基于 $x_{t}$ 的分类器，通过反向传播获取梯度。 通过给 $\\nabla_{x}\\log p\\left( c|x \\right)$ 乘以一个系数 $s \u003e 1$，可以增强条件信息的影响，得到更符合条件的样本生成结果.\nClassifier-Free Diffusion Guidance (CFG) 不使用分类器，而是定义两种去噪模型的score：\n条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma,c \\right) - x_{0} \\right)$\n无条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right)$\n其中 $D_{\\theta}$ 是去噪器, 使用一个 null 条件（如全零向量）来表示无条件模型. 则上式的等价形式\n$$\\begin{aligned} \\nabla_{x}\\log p\\left( x|c \\right) \u0026 = \\nabla_{x}\\log p(x) + S\\nabla_{x}\\log p\\left( c|x \\right) \\\\ \u0026 = \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) + S\\left( \\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) - \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\right) \\\\ \u0026 = S\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) + (1 - S)\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\\\ \u0026 = \\frac{1}{\\sigma^{2}}\\left( SD_{\\theta}\\left( x_{t},\\sigma,c \\right) + (1 - S)D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right) \\end{aligned}$$即用二者的凸组合来进行去噪采样.\n","permalink":"http://localhost:1313/posts/2025-12-26-diffusion/","summary":"\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nt\"\u003emenu\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"nt\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/categories/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e10\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/tags/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e20\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ehttps://example.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e30\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch1 id=\"diffusion-model\"\u003eDiffusion Model\u003c/h1\u003e\n\u003ch2 id=\"加噪过程\"\u003e加噪过程\u003c/h2\u003e\n\u003cp\u003e定义一个\u003cstrong\u003e马尔可夫链\u003c/strong\u003e，从数据 $x_{0} \\sim q(x)$\n开始，每一步加一点噪声：\u003c/p\u003e","title":"Diffusion Model"},{"content":"证据下界 ELBO 在最大似然估计（Maximum Likelihood Estimation, MLE）中，目标是最大化观测数据 $x$ 的对数似然.\n参数 $\\theta$ 的对数似然（log likelihood）的定义为\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布 $q(z)$，有\n$$ \\begin{aligned} \\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\ \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\end{aligned} $$由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\n$$ \\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack. $$取等条件 Jensen 不等式能够取等，当且仅当对于所有 $z$, $\\frac{p_{\\theta}(x,z)}{q(z)}$ 为常数 $c$. 因此\n$$ \\begin{aligned} p_{\\theta}(x) \u0026= \\sum_{z}p_{\\theta}(x,z) = c\\sum_{z}q(z) = c \\\\ q(z) \u0026= \\frac{p_{\\theta}(x,z)}{p_{\\theta}(x)} = p_{\\theta}\\left( z|x \\right). \\end{aligned} $$这里的 $q(z)$ 可以是任意分布，但使用中常用 $q(z) = q_{\\varphi}\\left( z|x \\right)$，即 $z$ 的近似后验分布，而近似后验分布越接近真实后验分布 $p_{\\theta}\\left( z|x \\right)$，ELBO 越接近对数似然.\nKL散度 任意分布 $p(x)$ 的信息熵定义为\n$$H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log p(x) \\right\\rbrack$$即对随机事件编码长度的期望值. 如果认为 $x$ 服从另一分布 $q(x)$，在\u0026quot;真实\u0026quot;分布 $p(x)$ 下的编码长度期望值定义为交叉熵：\n$$H(p,q) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log q(x) \\right\\rbrack.$$KL散度即定义为“额外的”编码长度\n$$\\text{ KL}\\left( p\\|q \\right) = H(p,q) - H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack.$$ KL散度描述了两个分布的差异程度，但是不是距离度量，因为不满足对称性和三角不等式.\nKL 散度的非负性 对于任意分布 $p(x)$ 和 $q(x)$，有 $\\text{KL}(p \\|q) \\ge 0$，因为\n$$ \\begin{aligned} \\text{ KL}\\left( p\\|q \\right) \u0026 = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack \\\\ \u0026 = - {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log\\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \\left( \\text{Jensen} \\right) \u0026 \\geq - \\log{\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \u0026 = - \\log\\int_{x}p(x)\\left( \\frac{q(x)}{p(x)} \\right)dx \\\\ \u0026 = - \\log\\int_{x}q(x)dx \\\\ \u0026 = - \\log 1 \\\\ \u0026 = 0. \\end{aligned} $$易知当且仅当 $p = q$ 时，$\\text{KL}\\left( p\\|q \\right) = 0$.\nELBO 等价形式 回到 ELBO，ELBO 和真实对数似然的差距为\n$$ \\begin{aligned} \\ell(\\theta) - \\mathcal{F}(q,\\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x) - \\log p_{\\theta}(x,z) + \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack - \\log p_{\\theta}\\left( z|x \\right) + \\log q(z) \\right\\rbrack \\\\ \u0026= \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right) \\geq 0. \\end{aligned} $$因此，ELBO 等价于\n$$\\mathcal{F}(q,\\theta) = \\ell(\\theta) - \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right)$$显然，取等条件同样为 $q(z) = p_{\\theta}\\left( z|x \\right)$. 而一般的问题中，通常采用以下形式：\n$$ \\begin{aligned} \\mathcal{F}(q, \\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{p_{\\theta}(z)} \\right\\rbrack - \\left( {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(z) \\right\\rbrack \\right) \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q(z)\\|p_{\\theta}(z) \\right) \\end{aligned} $$EM EM 算法的目标是最大化参数 $\\theta$ 对数似然：\n$$\\ell(\\theta) = \\log p\\left( x|\\theta \\right)$$第 $i$ 步的参数和隐变量分布分别记为 $\\theta^{(i)}$ 和 $q^{(i)}(z)$.\nE 步 最大化 $\\ell(\\theta^{(i)})$ 的 ELBO，即取等条件\n$$q^{(i + 1)}(z) = p_{\\theta^{(i)}}\\left( z|x \\right)$$M 步 更新参数 $\\theta^{(i)}$ 以最大化 ELBO， $$\\theta^{(i + 1)} = \\arg\\max\\limits_{\\theta}\\mathcal{F}(q^{(i + 1)},\\theta)$$收敛性 $$\\ell(\\theta^{(i + 1)})\\underset{\\text{ELBO}}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i + 1)})\\underset{\\arg\\max}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i)})\\underset{\\text{满足取等条件}}{=}\\ell(\\theta^{(i)})$$因此对数似然单调不减.\n例子：高斯混合模型 GMM 假设观测数据 $x$ 来自 $K$ 个高斯分布的混合：\n$$p_{\\theta}(x) = \\sum_{k = 1}^{K}\\pi_{k}\\mathcal{N}(x|\\mu_{k},\\Sigma_{k})$$其中 $\\theta = \\left\\{ \\pi_{k},\\mu_{k},\\Sigma_{k} \\right\\}_{k=1}^K$ 是模型参数，$\\pi_{k}$ 是混合系数，满足 $\\sum_{k = 1}^{K}\\pi_{k} = 1$. 数据样本为 $\\left\\{ x^{i} \\right\\}_{i = 1}^{N}$，引入隐变量 $z$ 表示样本属于哪个高斯分布, $z^{i} = k$ 表示样本 $x^{i}$ 来自第 $k$ 个高斯分布.\nE 步 计算后验概率（责任度）：\n$$ \\begin{aligned} \\gamma_{z^{i} = k} \u0026 \\leftarrow p_{\\theta}\\left( z^{i} = k|x^{i} \\right) \\\\ \u0026 = \\frac{\\pi_{k}\\mathcal{N}(x^{i}|\\mu_{k},\\Sigma_{k})}{\\sum_{j = 1}^{K}\\pi_{j}\\mathcal{N}(x^{i}|\\mu_{j},\\Sigma_{j})} \\end{aligned} $$M 步 更新参数：\n$$\\theta = \\arg\\max\\limits_{\\theta}\\mathcal{F}(\\gamma,\\theta)$$即在已知责任度 $\\gamma_{z^{i} = k}$ 下，最大化似然的参数. 定义 $\\begin{aligned} N_{k} \u0026 = \\sum_{i = 1}^{N}\\gamma_{z^{i} = k} \\end{aligned}$,\n则更新步骤为\n$$ \\begin{aligned} \\pi_{k} \u0026 \\leftarrow \\frac{N_{k}}{N} \\\\ \\mu_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}x^{i} \\\\ \\Sigma_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}\\left( x^{i} - \\mu_{k} \\right)\\left( x^{i} - \\mu_{k} \\right)^{\\top} \\end{aligned} $$VAE 普通的自编码器（Autoencoder）就是编码\u0026ndash;解码：\n编码器把输入数据 $x$ 映射到一个隐空间向量 $z$；\n解码器把 $z$ 还原回数据空间，得到重构 $\\hat{x}$.\n但是，普通自编码器学习到的 $z$ 没有概率解释，不能直接采样用于生成.\nVAE 的关键思想是：\n给隐变量 $z$ 加一个概率分布的解释，并用变分推断来学习这个分布.\n编码器不再输出一个确定向量，而是输出一个 分布参数（均值 $\\mu(x)$、方差 $\\sigma^{2}(x)$）\n从这个分布中采样 $z \\sim q_{\\varphi(z|x)}$，再送给解码器生成 $\\hat{x}$.\n这样隐空间就被正则化成一个连续、平滑的概率空间，可以用来插值、采样、生成新样本.\n先验分布 $p(z)$ 隐变量 $z$ 的先验分布 $p(z)$ 通常取标准正态分布 $\\mathcal{N}(0,I)$.\n解码器（生成分布） $p_{\\theta}\\left( x|z \\right)$ 网络参数 $\\theta$ 输入隐变量 $z$，输出数据 $x$ 的分布参数，即高斯分布的均值 $\\mu(z)$ 和方差 $\\Sigma(z)$.\n编码器（近似后验分布）$q_{\\varphi}\\left( z|x \\right)$ 使用 $q_{\\varphi}\\left( z|x \\right)$ 拟合\u0026quot;真实\u0026quot;后验分布 $p_{\\theta}\\left( z|x \\right)$.同样使用神经网络参数 $\\varphi$，输入数据 $x$，输出隐变量 $z$ 的分布参数.\n\u0026ldquo;近似\u0026quot;后验 和 \u0026ldquo;真实\u0026quot;后验 \u0026ldquo;真实\u0026quot;的后验分布由贝叶斯公式得出\n$$ \\begin{aligned} p_{\\theta}\\left( x|z \\right) \u0026= \\frac{p_{\\theta}\\left( x|z \\right)p(z)}{p_{\\theta}(x)} \\\\ p_{\\theta}(x) \u0026= \\int p_{\\theta}\\left( x|z \\right)p(z)dz \\end{aligned} $$因此真实的后验不可解，使用近似后验 $q_{\\varphi}\\left( z|x \\right)$ 来代替.\nELBO 和损失函数 使用 ELBO 替代对数似然：\n$$\\log p_{\\theta}(x) \\geq {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$其中\n${\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack$ 是重构误差，衡量解码器重构 $\\hat{x}$ 与输入 $x$ 的差异；\n$\\text{KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$ 是正则化项，使近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 尽量接近先验分布 $p(z)$（标准正态分布）.\n训练和重参数化 目前我们有\n编码器 $q_{\\varphi}\\left( z|x \\right)$，输入 $x$，输出隐变量 $z$ 的高斯分布参数 $\\mu(x),\\sigma^{2}(x)$；\n解码器 $p_{\\theta}\\left( x|z \\right)$，输入隐变量 $z$，输出重构 $\\hat{x}$ 的分布；\n先验分布 $p(z)$，通常取标准正态分布 $\\mathcal{N}(0,I)$.\n损失函数 ELBO $$\\mathcal{L} = - {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack + \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$ 训练时，期望项（重构误差）没有解析解，使用 $z$ 的采样来近似. 为了保证采样 $z \\sim \\mathcal{N}(\\mu(x),\\sigma^{2}(x))$ 可导，使用重参数化技巧：\n$$ \\begin{array}{r} z = \\mu(x) + \\sigma(x) \\odot \\varepsilon, \\\\ \\end{array} $$其中 $\\varepsilon \\sim \\mathcal{N}(0,I)$ 是独立噪声.\n展开 KL 散度 记 $q_{\\text{agg }}(z) = {\\mathbb{E}}_{x \\sim P(x)}q\\left( z|x \\right)$,\n$$ \\begin{aligned} \\text{ELBO} \u0026= \\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right] - \\mathrm{KL}\\!\\left(q_{\\text{agg}}(z)\\|p(z)\\right) \\\\ \u0026= \\underbrace{\\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right]}_{\\text{重构项}} - \\underbrace{H\\!\\left(q_{\\text{agg}}(z),p(z)\\right)}_{\\text{交叉熵}} + \\underbrace{H\\!\\left(p(z)\\right)}_{\\text{熵}}. \\end{aligned} $$ 重构项：鼓励隐变量分布远离先验分布 $p(z)$，提高重构质量 交叉熵：把隐变量分布拉向先验分布 $p(z)$ 中心，会同时减小均值和方差 熵：鼓励隐变量分布增大方差，分布更扁平 VAE 的问题 Prior Hole VAE 的隐空间分布 $q_{\\text{agg }}(z)$ 往往只占据先验分布 $p(z)$ 的一小部分，导致从先验分布采样的 $z$ 很可能落在\u0026quot;空洞\u0026quot;区域，解码器无法生成有效样本.\nPosterior Collapse 如果解码器足够强大，例如 autoregressive 模型，可以不依赖 $z$, 或者仅从 $z$ 的一部分维度中重构输入 $x$. 即 $z$ 的某些维度对重构没有贡献，导致这些维度的近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 退化为先验分布 $p(z)$，从而无法学习到有效的隐表示.\n$$\\exists i\\ s.t.\\ \\forall x,q_{\\varphi}\\left( z_{i}|x \\right) = p\\left( z_{i} \\right)$$Vector Quantized VAE(VQ VAE) 让隐变量 $z$ 取离散值，而不是连续值. 定义一个有限的码本（codebook），编码器输出一个向量 $e_{i}$，然后将 $e_{i}$ 映射到码本中距离最近的离散向量 $e_{k}$.\n解决了 Prior Hole 和 Posterior Collapse 问题，但训练时需要使用特殊的技巧（如直通估计器）来处理离散变量的不可导问题.\n","permalink":"http://localhost:1313/posts/elbo-em-vae/","summary":"\u003ch1 id=\"证据下界-elbo\"\u003e证据下界 ELBO\u003c/h1\u003e\n\u003cp\u003e在最大似然估计（Maximum Likelihood Estimation,\nMLE）中，目标是最大化观测数据 $x$ 的对数似然.\u003c/p\u003e\n\u003cp\u003e参数 $\\theta$ 的对数似然（log likelihood）的定义为\u003c/p\u003e\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$\u003cp\u003e其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布\n$q(z)$，有\u003c/p\u003e\n$$\n\\begin{aligned}\n\\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\\n \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack\n\\end{aligned}\n$$\u003cp\u003e由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\u003c/p\u003e\n$$\n\\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack.\n$$\u003ch2 id=\"取等条件\"\u003e取等条件\u003c/h2\u003e\n\u003cp\u003eJensen 不等式能够取等，当且仅当对于所有 $z$,\n$\\frac{p_{\\theta}(x,z)}{q(z)}$\n为常数 $c$.\n因此\u003c/p\u003e","title":"ELBO，EM和VAE"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 menu: main: - identifier: categories name: categories url: /categories/ weight: 10 - identifier: tags name: tags url: /tags/ weight: 20 - identifier: example name: example.org url: https://example.org weight: 30 Diffusion Model 加噪过程 定义一个马尔可夫链，从数据 $x_{0} \\sim q(x)$ 开始，每一步加一点噪声：\n$$q\\left( x_{t}~|~x_{t - 1} \\right) = \\mathcal{N}(x_{t};\\sqrt{1 - \\beta_{t}}x_{t - 1},\\beta_{t}I)$$使用重参数化，等价于\n$$x_{t} = \\sqrt{1 - \\beta_{t}}x_{t - 1} + \\sqrt{\\beta_{t}}\\varepsilon_{t},\\quad\\varepsilon_{t} \\sim N(0,I),$$其中 $\\beta$ 是一系列预定义的参数.\n对于两个高斯分布 $x_{1} \\sim \\mathcal{N}(\\mu_{1},\\sigma_{1}^{2})$ 和 $x_{2} \\sim \\mathcal{N}(\\mu_{2},\\sigma_{2}^{2})$，我们有：\n$$x_{1} + x_{2} \\sim \\mathcal{N}(\\mu_{1} + \\mu_{2},\\sigma_{1}^{2} + \\sigma_{2}^{2})$$于是定义 $\\alpha_{t} = 1 - \\beta_{t}$，则\n$$\\begin{aligned} x_{t} \u0026 = \\sqrt{\\alpha_{t}}x_{t - 1} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{\\alpha_{t}\\left( 1 - \\alpha_{t - 1} \\right)}\\varepsilon_{t} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}}\\varepsilon \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}x_{t - 3} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}\\varepsilon \\\\ \u0026 = \\ldots \\end{aligned}$$定义 ${\\overline{\\alpha}}_{t} = \\prod_{s = 1}^{t}\\alpha_{s}$, 得到 $x_{t}$ 的封闭形式\n$$x_{t} = \\sqrt{{\\overline{\\alpha}}_{t}}x_{0} + \\sqrt{1 - {\\overline{\\alpha}}_{t}}\\varepsilon,\\quad\\varepsilon \\sim N(0,I).$$即\n$$q\\left( x_{t}~|~x_{0} \\right) = \\mathcal{N}(x_{t};\\sqrt{{\\overline{\\alpha}}_{t}}x_{0},\\left( 1 - {\\overline{\\alpha}}_{t} \\right)I)$$因为 $\\alpha_{t} \u003c 1$, 因此 ${\\overline{\\alpha}}_{\\infty} \\rightarrow 0$，此时 $q\\left( x_{t}~|~x_{0} \\right) \\rightarrow \\mathcal{N}(0,I)$. 即随着 $t$ 增大，$x_{t}$ 趋近于纯噪声.\n去噪过程 我们的目标是找到加噪过程 $q\\left( x_{t}~|~x_{t - 1} \\right)$ 的逆过程，即逐步去噪的条件高斯分布\n$$q\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{t}\\left( x_{t} \\right),\\Sigma_{t}\\left( x_{t} \\right))$$$q\\left( x_{t - 1}~|~x_{t} \\right)$不可解，因此使用一个模型 $\\theta$ 近似，以 $x_{t}$ 和 $t$ 作为输入，输出分布参数\n$$p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{\\theta}\\left( x_{t},t \\right),\\Sigma_{\\theta}\\left( x_{t},t \\right))$$最大似然估计 MLE 目标是最小化去噪模型 $p_{\\theta}$ 对初始数据 $x_{0}$ 的负对数似然：\n$$\\mathcal{L}(\\theta) = - \\log p_{\\theta}\\left( x_{0} \\right)$$同样地，使用变分下界 ELBO 优化，其中 $x_{0}$ 是已知变量，$x_{1:T}$ 是隐变量：\n$$\\begin{array}{r} \\mathcal{F}(q,\\theta) = {\\mathbb{E}}_{q\\left( x_{1:T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0:T} \\right) - \\log q\\left( x_{1:T}|x_{0} \\right) \\right\\rbrack \\\\ \\mathcal{L}(\\theta) \\leq - \\mathcal{F}(q,\\theta) \\end{array}$$根据马尔可夫性质，\n$$\\begin{array}{r} q\\left( x_{1:T}|x_{0} \\right) = q\\left( x_{T}~|~x_{0} \\right)\\prod_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\\\ p_{\\theta}\\left( x_{0:T} \\right) = p_{\\theta}\\left( x_{T} \\right)\\prod_{t = 1}^{T}p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\end{array}$$代入得到 $\\mathcal{F}(q,\\theta)$\n$$\\begin{aligned} = \u0026 {\\mathbb{E}}_{q\\left( x_{1}:x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) + \\sum_{t = 1}^{T}\\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) - \\sum_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t},x_{t - 1}|x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}{\\mathbb{E}}_{q\\left( x_{t - 1}|x_{t},x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right) \\\\ \u0026 - \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right) \\end{aligned}$$分别记作\n$$\\mathcal{L} ≔ - \\mathcal{F}(q,\\theta) = \\mathcal{L}_{0} + \\sum_{t = 2}^{T}\\mathcal{L}_{t - 1} + \\mathcal{L}_{T}.$$其中\n初始项 $\\mathcal{L}_{0} = - {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack$\n最小化最后一步 $x_{1}$ 到 $x_{0}$ 的重建误差\n当 $p_{\\theta}$ 取高斯分布时，相当于最小化均方误差 MSE: ${\\mathbb{E}}\\left\\lbrack \\left\\| {x_{1} - x_{0}} \\right\\|^{2} \\right\\rbrack$\n中间项 $\\mathcal{L}_{t - 1} = {\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right)$\n让模型 $p_{\\theta}$ 学习去噪过程，缩小和真实后验 $q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)$ 的差距。\n$$q\\left( x_{t - 1}|x_{t},x_{0} \\right) = \\frac{q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)}{q\\left( x_{t}|x_{0} \\right)} \\propto q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)$$ 终端项 $\\mathcal{L}_{T} = \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right)$\n让模型 $p_{\\theta}$ 的先验分布接近 $q\\left( x_{T}~|~x_{0} \\right)$\n对于足够大的 $T$，$q\\left( x_{T}~|~x_{0} \\right) \\approx \\mathcal{N}(0,I)$，而先验 $p_{\\theta}\\left( x_{T} \\right)$ 被定义为 $\\mathcal{N}(0,I)$\n因此该项可以忽略不计.\nScore-based Diffusion Model \u0026amp; Langevin dynamics Langevin dynamics Boltzmann distribution 统计力学的玻尔兹曼分布（Boltzmann distribution）指出一个系统的状态分布为\n$$p_{i} \\propto \\exp( - \\frac{\\varepsilon_{i}}{kT})$$ []{#eq:boltzmann}\n其中 $\\varepsilon_{i}$ 是状态 $i$ 的能量，$k$ 是玻尔兹曼常数，$T$ 是温度.\nLangevin equation 而 Langevin equation 描述的是粒子在（一维）势能场中的布朗运动，\n$$dx_{t} = - \\frac{1}{\\gamma}\\nabla_{x}U\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t}$$ []{#eq:langevin}\n其中\n$x$ 是粒子位置\n$U(x)$ 是势能函数\n$\\gamma$ 是阻尼系数\n$W_{t}$ 是标准 Wiener 过程：$W_{t + \\Delta} = W_{t} + \\mathcal{N}(0,\\Delta)$\n根据 Boltzmann distribution\n$$U(x) = - kT\\log p(x) + \\text{ constant},$$代入得\n$$\\begin{aligned} dx_{t} \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\\\ \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\end{aligned}$$方程在离散时间 $x_{k} ≔ x(k\\tau)$ 下的形式为\n$$\\begin{array}{rlr} x_{k + 1} - x_{k} \u0026 = - \\frac{kT}{\\gamma}\\tau\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{\\frac{2kT}{\\gamma}\\tau}\\xi\\quad \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\\\ \u0026 = - \\eta\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{2\\eta}\\xi \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\end{array}$$其中 $\\eta = \\frac{kT}{\\gamma}\\tau$ 是步长. 回忆 $x_{t}$ 描述的是粒子的随机位置，因此\n$$x_{k} \\sim p(x)$$即已知对数梯度 $\\nabla\\log p(x)$ 时，Langevin dynamics 迭代的过程可以对分布 $p(x)$ 采样，而不需要显式地知道 $p(x)$ 的形式。\n观察迭代形式，这实际上是一个带随机扰动的对数梯度上升过程，梯度项使得粒子趋向于高概率区域，而随机扰动则保证了采样的多样性.\nSimulated Annealing 实际上，如果令玻尔兹曼分布 ([@eq]:boltzmann) 中势能不变，$T$ 逐渐收敛至 $0$, 则分布收敛到单点分布 $p(x) = \\delta(x - x^{\\ast})$，其中 $x^{\\ast} = \\arg\\min\\limits_{x}U(x)$ 是势能的最小值点, 此时 Langevin equation ([@eq]:langevin) 中的随机扰动项收敛至 $0$，Langevin dynamics 退化为势能的对数梯度下降. 而温度 $T$ 的收敛速度控制了采样过程的随机性，快速的降温会导致探索不足，陷入局部势能极小值，反之则有更大概率达到势能全局最小值。这种模拟降温过程的方法即为模拟退火 Simulated Annealing.\nScore-based Diffusion Model 定义 score 函数，即数据分布的对数梯度：\n$$\\text{ score}(x) = \\nabla_{x}\\log p(x)$$根据 Langevin dynamics ([@eq]:langevin)，只要能估计出数据分布的 score 函数，即可通过迭代采样得到数据分布的样本.\n学习 score 在 Score-based Diffusion Model 中，唯一需要学习的就是一个 noise-conditioned score network:\n$$s_{\\theta}\\left( x_{t},t \\right) \\approx \\nabla_{x_{t}}\\log p\\left( x_{t} \\right)$$采取 DSM（Denoising Score Matching）损失：\n$$\\mathcal{L} = {\\mathbb{E}}_{x,z,t}\\left\\lbrack \\lambda(t)\\left\\| {s_{\\theta}\\left( x + \\sigma_{t}z,t \\right) + \\frac{z}{\\sigma_{t}}} \\right\\|^{2} \\right\\rbrack$$即 $s_{\\theta}\\left( x + \\sigma_{t}z,t \\right)$ 的真实值为\n$$\\nabla\\log\\mathcal{N}(u;x,\\sigma_{t}^{2}) = \\nabla\\frac{{- (u - x)}^{2}}{2\\sigma_{t}^{2}} = - \\frac{u - x}{\\sigma_{t}^{2}} = - \\frac{z}{\\sigma_{t}}$$而 $\\lambda(t)$ 是一个权重函数，用于平衡不同噪声水平下的损失贡献. 常见的选择是\n$$\\lambda(t) = \\sigma_{t}^{2}$$采样/去噪 条件 Diffusion Model 给定条件 $c$, 需要\n$$\\nabla_{x}\\log p\\left( x|c \\right)$$Bayes 公式：\n$$\\nabla_{x}\\log p\\left( x|c \\right) = \\nabla_{x}\\log p(x) + \\nabla_{x}\\log p\\left( c|x \\right)$$如何得到 $\\nabla_{x}\\log p\\left( c|x \\right)$:\nclassifier guidance：基于 $x_{t}$ 的分类器，通过反向传播获取梯度。 通过给 $\\nabla_{x}\\log p\\left( c|x \\right)$ 乘以一个系数 $s \u003e 1$，可以增强条件信息的影响，得到更符合条件的样本生成结果.\nClassifier-Free Diffusion Guidance (CFG) 不使用分类器，而是定义两种去噪模型的score：\n条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma,c \\right) - x_{0} \\right)$\n无条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right)$\n其中 $D_{\\theta}$ 是去噪器, 使用一个 null 条件（如全零向量）来表示无条件模型. 则上式的等价形式\n$$\\begin{aligned} \\nabla_{x}\\log p\\left( x|c \\right) \u0026 = \\nabla_{x}\\log p(x) + S\\nabla_{x}\\log p\\left( c|x \\right) \\\\ \u0026 = \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) + S\\left( \\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) - \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\right) \\\\ \u0026 = S\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) + (1 - S)\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\\\ \u0026 = \\frac{1}{\\sigma^{2}}\\left( SD_{\\theta}\\left( x_{t},\\sigma,c \\right) + (1 - S)D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right) \\end{aligned}$$即用二者的凸组合来进行去噪采样.\n","permalink":"http://localhost:1313/posts/2025-12-26-diffusion/","summary":"\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nt\"\u003emenu\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"nt\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/categories/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e10\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/tags/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e20\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ehttps://example.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e30\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch1 id=\"diffusion-model\"\u003eDiffusion Model\u003c/h1\u003e\n\u003ch2 id=\"加噪过程\"\u003e加噪过程\u003c/h2\u003e\n\u003cp\u003e定义一个\u003cstrong\u003e马尔可夫链\u003c/strong\u003e，从数据 $x_{0} \\sim q(x)$\n开始，每一步加一点噪声：\u003c/p\u003e","title":"Diffusion Model"},{"content":"证据下界 ELBO 在最大似然估计（Maximum Likelihood Estimation, MLE）中，目标是最大化观测数据 $x$ 的对数似然.\n参数 $\\theta$ 的对数似然（log likelihood）的定义为\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布 $q(z)$，有\n$$ \\begin{aligned} \\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\ \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\end{aligned} $$由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\n$$ \\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack. $$取等条件 Jensen 不等式能够取等，当且仅当对于所有 $z$, $\\frac{p_{\\theta}(x,z)}{q(z)}$ 为常数 $c$. 因此\n$$ \\begin{aligned} p_{\\theta}(x) \u0026= \\sum_{z}p_{\\theta}(x,z) = c\\sum_{z}q(z) = c \\\\ q(z) \u0026= \\frac{p_{\\theta}(x,z)}{p_{\\theta}(x)} = p_{\\theta}\\left( z|x \\right). \\end{aligned} $$这里的 $q(z)$ 可以是任意分布，但使用中常用 $q(z) = q_{\\varphi}\\left( z|x \\right)$，即 $z$ 的近似后验分布，而近似后验分布越接近真实后验分布 $p_{\\theta}\\left( z|x \\right)$，ELBO 越接近对数似然.\nKL散度 任意分布 $p(x)$ 的信息熵定义为\n$$H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log p(x) \\right\\rbrack$$即对随机事件编码长度的期望值. 如果认为 $x$ 服从另一分布 $q(x)$，在\u0026quot;真实\u0026quot;分布 $p(x)$ 下的编码长度期望值定义为交叉熵：\n$$H(p,q) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log q(x) \\right\\rbrack.$$KL散度即定义为“额外的”编码长度\n$$\\text{ KL}\\left( p\\|q \\right) = H(p,q) - H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack.$$ KL散度描述了两个分布的差异程度，但是不是距离度量，因为不满足对称性和三角不等式.\nKL 散度的非负性 对于任意分布 $p(x)$ 和 $q(x)$，有 $\\text{KL}(p \\|q) \\ge 0$，因为\n$$ \\begin{aligned} \\text{ KL}\\left( p\\|q \\right) \u0026 = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack \\\\ \u0026 = - {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log\\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \\left( \\text{Jensen} \\right) \u0026 \\geq - \\log{\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \u0026 = - \\log\\int_{x}p(x)\\left( \\frac{q(x)}{p(x)} \\right)dx \\\\ \u0026 = - \\log\\int_{x}q(x)dx \\\\ \u0026 = - \\log 1 \\\\ \u0026 = 0. \\end{aligned} $$易知当且仅当 $p = q$ 时，$\\text{KL}\\left( p\\|q \\right) = 0$.\nELBO 等价形式 回到 ELBO，ELBO 和真实对数似然的差距为\n$$ \\begin{aligned} \\ell(\\theta) - \\mathcal{F}(q,\\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x) - \\log p_{\\theta}(x,z) + \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack - \\log p_{\\theta}\\left( z|x \\right) + \\log q(z) \\right\\rbrack \\\\ \u0026= \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right) \\geq 0. \\end{aligned} $$因此，ELBO 等价于\n$$\\mathcal{F}(q,\\theta) = \\ell(\\theta) - \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right)$$显然，取等条件同样为 $q(z) = p_{\\theta}\\left( z|x \\right)$. 而一般的问题中，通常采用以下形式：\n$$ \\begin{aligned} \\mathcal{F}(q, \\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{p_{\\theta}(z)} \\right\\rbrack - \\left( {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(z) \\right\\rbrack \\right) \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q(z)\\|p_{\\theta}(z) \\right) \\end{aligned} $$EM EM 算法的目标是最大化参数 $\\theta$ 对数似然：\n$$\\ell(\\theta) = \\log p\\left( x|\\theta \\right)$$第 $i$ 步的参数和隐变量分布分别记为 $\\theta^{(i)}$ 和 $q^{(i)}(z)$.\nE 步 最大化 $\\ell(\\theta^{(i)})$ 的 ELBO，即取等条件\n$$q^{(i + 1)}(z) = p_{\\theta^{(i)}}\\left( z|x \\right)$$M 步 更新参数 $\\theta^{(i)}$ 以最大化 ELBO， $$\\theta^{(i + 1)} = \\arg\\max\\limits_{\\theta}\\mathcal{F}(q^{(i + 1)},\\theta)$$收敛性 $$\\ell(\\theta^{(i + 1)})\\underset{\\text{ELBO}}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i + 1)})\\underset{\\arg\\max}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i)})\\underset{\\text{满足取等条件}}{=}\\ell(\\theta^{(i)})$$因此对数似然单调不减.\n例子：高斯混合模型 GMM 假设观测数据 $x$ 来自 $K$ 个高斯分布的混合：\n$$p_{\\theta}(x) = \\sum_{k = 1}^{K}\\pi_{k}\\mathcal{N}(x|\\mu_{k},\\Sigma_{k})$$其中 $\\theta = \\left\\{ \\pi_{k},\\mu_{k},\\Sigma_{k} \\right\\}_{k=1}^K$ 是模型参数，$\\pi_{k}$ 是混合系数，满足 $\\sum_{k = 1}^{K}\\pi_{k} = 1$. 数据样本为 $\\left\\{ x^{i} \\right\\}_{i = 1}^{N}$，引入隐变量 $z$ 表示样本属于哪个高斯分布, $z^{i} = k$ 表示样本 $x^{i}$ 来自第 $k$ 个高斯分布.\nE 步 计算后验概率（责任度）：\n$$ \\begin{aligned} \\gamma_{z^{i} = k} \u0026 \\leftarrow p_{\\theta}\\left( z^{i} = k|x^{i} \\right) \\\\ \u0026 = \\frac{\\pi_{k}\\mathcal{N}(x^{i}|\\mu_{k},\\Sigma_{k})}{\\sum_{j = 1}^{K}\\pi_{j}\\mathcal{N}(x^{i}|\\mu_{j},\\Sigma_{j})} \\end{aligned} $$M 步 更新参数：\n$$\\theta = \\arg\\max\\limits_{\\theta}\\mathcal{F}(\\gamma,\\theta)$$即在已知责任度 $\\gamma_{z^{i} = k}$ 下，最大化似然的参数. 定义 $\\begin{aligned} N_{k} \u0026 = \\sum_{i = 1}^{N}\\gamma_{z^{i} = k} \\end{aligned}$,\n则更新步骤为\n$$ \\begin{aligned} \\pi_{k} \u0026 \\leftarrow \\frac{N_{k}}{N} \\\\ \\mu_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}x^{i} \\\\ \\Sigma_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}\\left( x^{i} - \\mu_{k} \\right)\\left( x^{i} - \\mu_{k} \\right)^{\\top} \\end{aligned} $$VAE 普通的自编码器（Autoencoder）就是编码\u0026ndash;解码：\n编码器把输入数据 $x$ 映射到一个隐空间向量 $z$；\n解码器把 $z$ 还原回数据空间，得到重构 $\\hat{x}$.\n但是，普通自编码器学习到的 $z$ 没有概率解释，不能直接采样用于生成.\nVAE 的关键思想是：\n给隐变量 $z$ 加一个概率分布的解释，并用变分推断来学习这个分布.\n编码器不再输出一个确定向量，而是输出一个 分布参数（均值 $\\mu(x)$、方差 $\\sigma^{2}(x)$）\n从这个分布中采样 $z \\sim q_{\\varphi(z|x)}$，再送给解码器生成 $\\hat{x}$.\n这样隐空间就被正则化成一个连续、平滑的概率空间，可以用来插值、采样、生成新样本.\n先验分布 $p(z)$ 隐变量 $z$ 的先验分布 $p(z)$ 通常取标准正态分布 $\\mathcal{N}(0,I)$.\n解码器（生成分布） $p_{\\theta}\\left( x|z \\right)$ 网络参数 $\\theta$ 输入隐变量 $z$，输出数据 $x$ 的分布参数，即高斯分布的均值 $\\mu(z)$ 和方差 $\\Sigma(z)$.\n编码器（近似后验分布）$q_{\\varphi}\\left( z|x \\right)$ 使用 $q_{\\varphi}\\left( z|x \\right)$ 拟合\u0026quot;真实\u0026quot;后验分布 $p_{\\theta}\\left( z|x \\right)$.同样使用神经网络参数 $\\varphi$，输入数据 $x$，输出隐变量 $z$ 的分布参数.\n\u0026ldquo;近似\u0026quot;后验 和 \u0026ldquo;真实\u0026quot;后验 \u0026ldquo;真实\u0026quot;的后验分布由贝叶斯公式得出\n$$ \\begin{aligned} p_{\\theta}\\left( x|z \\right) \u0026= \\frac{p_{\\theta}\\left( x|z \\right)p(z)}{p_{\\theta}(x)} \\\\ p_{\\theta}(x) \u0026= \\int p_{\\theta}\\left( x|z \\right)p(z)dz \\end{aligned} $$因此真实的后验不可解，使用近似后验 $q_{\\varphi}\\left( z|x \\right)$ 来代替.\nELBO 和损失函数 使用 ELBO 替代对数似然：\n$$\\log p_{\\theta}(x) \\geq {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$其中\n${\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack$ 是重构误差，衡量解码器重构 $\\hat{x}$ 与输入 $x$ 的差异；\n$\\text{KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$ 是正则化项，使近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 尽量接近先验分布 $p(z)$（标准正态分布）.\n训练和重参数化 目前我们有\n编码器 $q_{\\varphi}\\left( z|x \\right)$，输入 $x$，输出隐变量 $z$ 的高斯分布参数 $\\mu(x),\\sigma^{2}(x)$；\n解码器 $p_{\\theta}\\left( x|z \\right)$，输入隐变量 $z$，输出重构 $\\hat{x}$ 的分布；\n先验分布 $p(z)$，通常取标准正态分布 $\\mathcal{N}(0,I)$.\n损失函数 ELBO $$\\mathcal{L} = - {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack + \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$ 训练时，期望项（重构误差）没有解析解，使用 $z$ 的采样来近似. 为了保证采样 $z \\sim \\mathcal{N}(\\mu(x),\\sigma^{2}(x))$ 可导，使用重参数化技巧：\n$$ \\begin{array}{r} z = \\mu(x) + \\sigma(x) \\odot \\varepsilon, \\\\ \\end{array} $$其中 $\\varepsilon \\sim \\mathcal{N}(0,I)$ 是独立噪声.\n展开 KL 散度 记 $q_{\\text{agg }}(z) = {\\mathbb{E}}_{x \\sim P(x)}q\\left( z|x \\right)$,\n$$ \\begin{aligned} \\text{ELBO} \u0026= \\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right] - \\mathrm{KL}\\!\\left(q_{\\text{agg}}(z)\\|p(z)\\right) \\\\ \u0026= \\underbrace{\\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right]}_{\\text{重构项}} - \\underbrace{H\\!\\left(q_{\\text{agg}}(z),p(z)\\right)}_{\\text{交叉熵}} + \\underbrace{H\\!\\left(p(z)\\right)}_{\\text{熵}}. \\end{aligned} $$ 重构项：鼓励隐变量分布远离先验分布 $p(z)$，提高重构质量 交叉熵：把隐变量分布拉向先验分布 $p(z)$ 中心，会同时减小均值和方差 熵：鼓励隐变量分布增大方差，分布更扁平 VAE 的问题 Prior Hole VAE 的隐空间分布 $q_{\\text{agg }}(z)$ 往往只占据先验分布 $p(z)$ 的一小部分，导致从先验分布采样的 $z$ 很可能落在\u0026quot;空洞\u0026quot;区域，解码器无法生成有效样本.\nPosterior Collapse 如果解码器足够强大，例如 autoregressive 模型，可以不依赖 $z$, 或者仅从 $z$ 的一部分维度中重构输入 $x$. 即 $z$ 的某些维度对重构没有贡献，导致这些维度的近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 退化为先验分布 $p(z)$，从而无法学习到有效的隐表示.\n$$\\exists i\\ s.t.\\ \\forall x,q_{\\varphi}\\left( z_{i}|x \\right) = p\\left( z_{i} \\right)$$Vector Quantized VAE(VQ VAE) 让隐变量 $z$ 取离散值，而不是连续值. 定义一个有限的码本（codebook），编码器输出一个向量 $e_{i}$，然后将 $e_{i}$ 映射到码本中距离最近的离散向量 $e_{k}$.\n解决了 Prior Hole 和 Posterior Collapse 问题，但训练时需要使用特殊的技巧（如直通估计器）来处理离散变量的不可导问题.\n","permalink":"http://localhost:1313/posts/elbo-em-vae/","summary":"\u003ch1 id=\"证据下界-elbo\"\u003e证据下界 ELBO\u003c/h1\u003e\n\u003cp\u003e在最大似然估计（Maximum Likelihood Estimation,\nMLE）中，目标是最大化观测数据 $x$ 的对数似然.\u003c/p\u003e\n\u003cp\u003e参数 $\\theta$ 的对数似然（log likelihood）的定义为\u003c/p\u003e\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$\u003cp\u003e其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布\n$q(z)$，有\u003c/p\u003e\n$$\n\\begin{aligned}\n\\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\\n \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack\n\\end{aligned}\n$$\u003cp\u003e由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\u003c/p\u003e\n$$\n\\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack.\n$$\u003ch2 id=\"取等条件\"\u003e取等条件\u003c/h2\u003e\n\u003cp\u003eJensen 不等式能够取等，当且仅当对于所有 $z$,\n$\\frac{p_{\\theta}(x,z)}{q(z)}$\n为常数 $c$.\n因此\u003c/p\u003e","title":"ELBO，EM和VAE"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 menu: main: - identifier: categories name: categories url: /categories/ weight: 10 - identifier: tags name: tags url: /tags/ weight: 20 - identifier: example name: example.org url: https://example.org weight: 30 Diffusion Model 加噪过程 定义一个马尔可夫链，从数据 $x_{0} \\sim q(x)$ 开始，每一步加一点噪声：\n$$q\\left( x_{t}~|~x_{t - 1} \\right) = \\mathcal{N}(x_{t};\\sqrt{1 - \\beta_{t}}x_{t - 1},\\beta_{t}I)$$使用重参数化，等价于\n$$x_{t} = \\sqrt{1 - \\beta_{t}}x_{t - 1} + \\sqrt{\\beta_{t}}\\varepsilon_{t},\\quad\\varepsilon_{t} \\sim N(0,I),$$其中 $\\beta$ 是一系列预定义的参数.\n对于两个高斯分布 $x_{1} \\sim \\mathcal{N}(\\mu_{1},\\sigma_{1}^{2})$ 和 $x_{2} \\sim \\mathcal{N}(\\mu_{2},\\sigma_{2}^{2})$，我们有：\n$$x_{1} + x_{2} \\sim \\mathcal{N}(\\mu_{1} + \\mu_{2},\\sigma_{1}^{2} + \\sigma_{2}^{2})$$于是定义 $\\alpha_{t} = 1 - \\beta_{t}$，则\n$$\\begin{aligned} x_{t} \u0026 = \\sqrt{\\alpha_{t}}x_{t - 1} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{\\alpha_{t}\\left( 1 - \\alpha_{t - 1} \\right)}\\varepsilon_{t} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}}\\varepsilon \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}x_{t - 3} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}\\varepsilon \\\\ \u0026 = \\ldots \\end{aligned}$$定义 ${\\overline{\\alpha}}_{t} = \\prod_{s = 1}^{t}\\alpha_{s}$, 得到 $x_{t}$ 的封闭形式\n$$x_{t} = \\sqrt{{\\overline{\\alpha}}_{t}}x_{0} + \\sqrt{1 - {\\overline{\\alpha}}_{t}}\\varepsilon,\\quad\\varepsilon \\sim N(0,I).$$即\n$$q\\left( x_{t}~|~x_{0} \\right) = \\mathcal{N}(x_{t};\\sqrt{{\\overline{\\alpha}}_{t}}x_{0},\\left( 1 - {\\overline{\\alpha}}_{t} \\right)I)$$因为 $\\alpha_{t} \u003c 1$, 因此 ${\\overline{\\alpha}}_{\\infty} \\rightarrow 0$，此时 $q\\left( x_{t}~|~x_{0} \\right) \\rightarrow \\mathcal{N}(0,I)$. 即随着 $t$ 增大，$x_{t}$ 趋近于纯噪声.\n去噪过程 我们的目标是找到加噪过程 $q\\left( x_{t}~|~x_{t - 1} \\right)$ 的逆过程，即逐步去噪的条件高斯分布\n$$q\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{t}\\left( x_{t} \\right),\\Sigma_{t}\\left( x_{t} \\right))$$$q\\left( x_{t - 1}~|~x_{t} \\right)$不可解，因此使用一个模型 $\\theta$ 近似，以 $x_{t}$ 和 $t$ 作为输入，输出分布参数\n$$p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{\\theta}\\left( x_{t},t \\right),\\Sigma_{\\theta}\\left( x_{t},t \\right))$$最大似然估计 MLE 目标是最小化去噪模型 $p_{\\theta}$ 对初始数据 $x_{0}$ 的负对数似然：\n$$\\mathcal{L}(\\theta) = - \\log p_{\\theta}\\left( x_{0} \\right)$$同样地，使用变分下界 ELBO 优化，其中 $x_{0}$ 是已知变量，$x_{1:T}$ 是隐变量：\n$$\\begin{array}{r} \\mathcal{F}(q,\\theta) = {\\mathbb{E}}_{q\\left( x_{1:T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0:T} \\right) - \\log q\\left( x_{1:T}|x_{0} \\right) \\right\\rbrack \\\\ \\mathcal{L}(\\theta) \\leq - \\mathcal{F}(q,\\theta) \\end{array}$$根据马尔可夫性质，\n$$\\begin{array}{r} q\\left( x_{1:T}|x_{0} \\right) = q\\left( x_{T}~|~x_{0} \\right)\\prod_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\\\ p_{\\theta}\\left( x_{0:T} \\right) = p_{\\theta}\\left( x_{T} \\right)\\prod_{t = 1}^{T}p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\end{array}$$代入得到 $\\mathcal{F}(q,\\theta)$\n$$\\begin{aligned} = \u0026 {\\mathbb{E}}_{q\\left( x_{1}:x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) + \\sum_{t = 1}^{T}\\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) - \\sum_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t},x_{t - 1}|x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}{\\mathbb{E}}_{q\\left( x_{t - 1}|x_{t},x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right) \\\\ \u0026 - \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right) \\end{aligned}$$分别记作\n$$\\mathcal{L} ≔ - \\mathcal{F}(q,\\theta) = \\mathcal{L}_{0} + \\sum_{t = 2}^{T}\\mathcal{L}_{t - 1} + \\mathcal{L}_{T}.$$其中\n初始项 $\\mathcal{L}_{0} = - {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack$\n最小化最后一步 $x_{1}$ 到 $x_{0}$ 的重建误差\n当 $p_{\\theta}$ 取高斯分布时，相当于最小化均方误差 MSE: ${\\mathbb{E}}\\left\\lbrack \\left\\| {x_{1} - x_{0}} \\right\\|^{2} \\right\\rbrack$\n中间项 $\\mathcal{L}_{t - 1} = {\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right)$\n让模型 $p_{\\theta}$ 学习去噪过程，缩小和真实后验 $q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)$ 的差距。\n$$q\\left( x_{t - 1}|x_{t},x_{0} \\right) = \\frac{q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)}{q\\left( x_{t}|x_{0} \\right)} \\propto q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)$$ 终端项 $\\mathcal{L}_{T} = \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right)$\n让模型 $p_{\\theta}$ 的先验分布接近 $q\\left( x_{T}~|~x_{0} \\right)$\n对于足够大的 $T$，$q\\left( x_{T}~|~x_{0} \\right) \\approx \\mathcal{N}(0,I)$，而先验 $p_{\\theta}\\left( x_{T} \\right)$ 被定义为 $\\mathcal{N}(0,I)$\n因此该项可以忽略不计.\nScore-based Diffusion Model \u0026amp; Langevin dynamics Langevin dynamics Boltzmann distribution 统计力学的玻尔兹曼分布（Boltzmann distribution）指出一个系统的状态分布为\n$$p_{i} \\propto \\exp( - \\frac{\\varepsilon_{i}}{kT})$$ []{#eq:boltzmann}\n其中 $\\varepsilon_{i}$ 是状态 $i$ 的能量，$k$ 是玻尔兹曼常数，$T$ 是温度.\nLangevin equation 而 Langevin equation 描述的是粒子在（一维）势能场中的布朗运动，\n$$dx_{t} = - \\frac{1}{\\gamma}\\nabla_{x}U\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t}$$ []{#eq:langevin}\n其中\n$x$ 是粒子位置\n$U(x)$ 是势能函数\n$\\gamma$ 是阻尼系数\n$W_{t}$ 是标准 Wiener 过程：$W_{t + \\Delta} = W_{t} + \\mathcal{N}(0,\\Delta)$\n根据 Boltzmann distribution\n$$U(x) = - kT\\log p(x) + \\text{ constant},$$代入得\n$$\\begin{aligned} dx_{t} \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\\\ \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\end{aligned}$$方程在离散时间 $x_{k} ≔ x(k\\tau)$ 下的形式为\n$$\\begin{array}{rlr} x_{k + 1} - x_{k} \u0026 = - \\frac{kT}{\\gamma}\\tau\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{\\frac{2kT}{\\gamma}\\tau}\\xi\\quad \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\\\ \u0026 = - \\eta\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{2\\eta}\\xi \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\end{array}$$其中 $\\eta = \\frac{kT}{\\gamma}\\tau$ 是步长. 回忆 $x_{t}$ 描述的是粒子的随机位置，因此\n$$x_{k} \\sim p(x)$$即已知对数梯度 $\\nabla\\log p(x)$ 时，Langevin dynamics 迭代的过程可以对分布 $p(x)$ 采样，而不需要显式地知道 $p(x)$ 的形式。\n观察迭代形式，这实际上是一个带随机扰动的对数梯度上升过程，梯度项使得粒子趋向于高概率区域，而随机扰动则保证了采样的多样性.\nSimulated Annealing 实际上，如果令玻尔兹曼分布 ([@eq]:boltzmann) 中势能不变，$T$ 逐渐收敛至 $0$, 则分布收敛到单点分布 $p(x) = \\delta(x - x^{\\ast})$，其中 $x^{\\ast} = \\arg\\min\\limits_{x}U(x)$ 是势能的最小值点, 此时 Langevin equation ([@eq]:langevin) 中的随机扰动项收敛至 $0$，Langevin dynamics 退化为势能的对数梯度下降. 而温度 $T$ 的收敛速度控制了采样过程的随机性，快速的降温会导致探索不足，陷入局部势能极小值，反之则有更大概率达到势能全局最小值。这种模拟降温过程的方法即为模拟退火 Simulated Annealing.\nScore-based Diffusion Model 定义 score 函数，即数据分布的对数梯度：\n$$\\text{ score}(x) = \\nabla_{x}\\log p(x)$$根据 Langevin dynamics ([@eq]:langevin)，只要能估计出数据分布的 score 函数，即可通过迭代采样得到数据分布的样本.\n学习 score 在 Score-based Diffusion Model 中，唯一需要学习的就是一个 noise-conditioned score network:\n$$s_{\\theta}\\left( x_{t},t \\right) \\approx \\nabla_{x_{t}}\\log p\\left( x_{t} \\right)$$采取 DSM（Denoising Score Matching）损失：\n$$\\mathcal{L} = {\\mathbb{E}}_{x,z,t}\\left\\lbrack \\lambda(t)\\left\\| {s_{\\theta}\\left( x + \\sigma_{t}z,t \\right) + \\frac{z}{\\sigma_{t}}} \\right\\|^{2} \\right\\rbrack$$即 $s_{\\theta}\\left( x + \\sigma_{t}z,t \\right)$ 的真实值为\n$$\\nabla\\log\\mathcal{N}(u;x,\\sigma_{t}^{2}) = \\nabla\\frac{{- (u - x)}^{2}}{2\\sigma_{t}^{2}} = - \\frac{u - x}{\\sigma_{t}^{2}} = - \\frac{z}{\\sigma_{t}}$$而 $\\lambda(t)$ 是一个权重函数，用于平衡不同噪声水平下的损失贡献. 常见的选择是\n$$\\lambda(t) = \\sigma_{t}^{2}$$采样/去噪 条件 Diffusion Model 给定条件 $c$, 需要\n$$\\nabla_{x}\\log p\\left( x|c \\right)$$Bayes 公式：\n$$\\nabla_{x}\\log p\\left( x|c \\right) = \\nabla_{x}\\log p(x) + \\nabla_{x}\\log p\\left( c|x \\right)$$如何得到 $\\nabla_{x}\\log p\\left( c|x \\right)$:\nclassifier guidance：基于 $x_{t}$ 的分类器，通过反向传播获取梯度。 通过给 $\\nabla_{x}\\log p\\left( c|x \\right)$ 乘以一个系数 $s \u003e 1$，可以增强条件信息的影响，得到更符合条件的样本生成结果.\nClassifier-Free Diffusion Guidance (CFG) 不使用分类器，而是定义两种去噪模型的score：\n条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma,c \\right) - x_{0} \\right)$\n无条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right)$\n其中 $D_{\\theta}$ 是去噪器, 使用一个 null 条件（如全零向量）来表示无条件模型. 则上式的等价形式\n$$\\begin{aligned} \\nabla_{x}\\log p\\left( x|c \\right) \u0026 = \\nabla_{x}\\log p(x) + S\\nabla_{x}\\log p\\left( c|x \\right) \\\\ \u0026 = \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) + S\\left( \\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) - \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\right) \\\\ \u0026 = S\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) + (1 - S)\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\\\ \u0026 = \\frac{1}{\\sigma^{2}}\\left( SD_{\\theta}\\left( x_{t},\\sigma,c \\right) + (1 - S)D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right) \\end{aligned}$$即用二者的凸组合来进行去噪采样.\n","permalink":"http://localhost:1313/posts/2025-12-26-diffusion/","summary":"\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nt\"\u003emenu\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"nt\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/categories/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e10\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/tags/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e20\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ehttps://example.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e30\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch1 id=\"diffusion-model\"\u003eDiffusion Model\u003c/h1\u003e\n\u003ch2 id=\"加噪过程\"\u003e加噪过程\u003c/h2\u003e\n\u003cp\u003e定义一个\u003cstrong\u003e马尔可夫链\u003c/strong\u003e，从数据 $x_{0} \\sim q(x)$\n开始，每一步加一点噪声：\u003c/p\u003e","title":"Diffusion Model"},{"content":"证据下界 ELBO 在最大似然估计（Maximum Likelihood Estimation, MLE）中，目标是最大化观测数据 $x$ 的对数似然.\n参数 $\\theta$ 的对数似然（log likelihood）的定义为\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布 $q(z)$，有\n$$ \\begin{aligned} \\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\ \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\end{aligned} $$由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\n$$ \\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack. $$取等条件 Jensen 不等式能够取等，当且仅当对于所有 $z$, $\\frac{p_{\\theta}(x,z)}{q(z)}$ 为常数 $c$. 因此\n$$ \\begin{aligned} p_{\\theta}(x) \u0026= \\sum_{z}p_{\\theta}(x,z) = c\\sum_{z}q(z) = c \\\\ q(z) \u0026= \\frac{p_{\\theta}(x,z)}{p_{\\theta}(x)} = p_{\\theta}\\left( z|x \\right). \\end{aligned} $$这里的 $q(z)$ 可以是任意分布，但使用中常用 $q(z) = q_{\\varphi}\\left( z|x \\right)$，即 $z$ 的近似后验分布，而近似后验分布越接近真实后验分布 $p_{\\theta}\\left( z|x \\right)$，ELBO 越接近对数似然.\nKL散度 任意分布 $p(x)$ 的信息熵定义为\n$$H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log p(x) \\right\\rbrack$$即对随机事件编码长度的期望值. 如果认为 $x$ 服从另一分布 $q(x)$，在\u0026quot;真实\u0026quot;分布 $p(x)$ 下的编码长度期望值定义为交叉熵：\n$$H(p,q) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log q(x) \\right\\rbrack.$$KL散度即定义为“额外的”编码长度\n$$\\text{ KL}\\left( p\\|q \\right) = H(p,q) - H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack.$$ KL散度描述了两个分布的差异程度，但是不是距离度量，因为不满足对称性和三角不等式.\nKL 散度的非负性 对于任意分布 $p(x)$ 和 $q(x)$，有 $\\text{KL}(p \\|q) \\ge 0$，因为\n$$ \\begin{aligned} \\text{ KL}\\left( p\\|q \\right) \u0026 = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack \\\\ \u0026 = - {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log\\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \\left( \\text{Jensen} \\right) \u0026 \\geq - \\log{\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \u0026 = - \\log\\int_{x}p(x)\\left( \\frac{q(x)}{p(x)} \\right)dx \\\\ \u0026 = - \\log\\int_{x}q(x)dx \\\\ \u0026 = - \\log 1 \\\\ \u0026 = 0. \\end{aligned} $$易知当且仅当 $p = q$ 时，$\\text{KL}\\left( p\\|q \\right) = 0$.\nELBO 等价形式 回到 ELBO，ELBO 和真实对数似然的差距为\n$$ \\begin{aligned} \\ell(\\theta) - \\mathcal{F}(q,\\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x) - \\log p_{\\theta}(x,z) + \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack - \\log p_{\\theta}\\left( z|x \\right) + \\log q(z) \\right\\rbrack \\\\ \u0026= \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right) \\geq 0. \\end{aligned} $$因此，ELBO 等价于\n$$\\mathcal{F}(q,\\theta) = \\ell(\\theta) - \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right)$$显然，取等条件同样为 $q(z) = p_{\\theta}\\left( z|x \\right)$. 而一般的问题中，通常采用以下形式：\n$$ \\begin{aligned} \\mathcal{F}(q, \\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{p_{\\theta}(z)} \\right\\rbrack - \\left( {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(z) \\right\\rbrack \\right) \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q(z)\\|p_{\\theta}(z) \\right) \\end{aligned} $$EM EM 算法的目标是最大化参数 $\\theta$ 对数似然：\n$$\\ell(\\theta) = \\log p\\left( x|\\theta \\right)$$第 $i$ 步的参数和隐变量分布分别记为 $\\theta^{(i)}$ 和 $q^{(i)}(z)$.\nE 步 最大化 $\\ell(\\theta^{(i)})$ 的 ELBO，即取等条件\n$$q^{(i + 1)}(z) = p_{\\theta^{(i)}}\\left( z|x \\right)$$M 步 更新参数 $\\theta^{(i)}$ 以最大化 ELBO， $$\\theta^{(i + 1)} = \\arg\\max\\limits_{\\theta}\\mathcal{F}(q^{(i + 1)},\\theta)$$收敛性 $$\\ell(\\theta^{(i + 1)})\\underset{\\text{ELBO}}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i + 1)})\\underset{\\arg\\max}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i)})\\underset{\\text{满足取等条件}}{=}\\ell(\\theta^{(i)})$$因此对数似然单调不减.\n例子：高斯混合模型 GMM 假设观测数据 $x$ 来自 $K$ 个高斯分布的混合：\n$$p_{\\theta}(x) = \\sum_{k = 1}^{K}\\pi_{k}\\mathcal{N}(x|\\mu_{k},\\Sigma_{k})$$其中 $\\theta = \\left\\{ \\pi_{k},\\mu_{k},\\Sigma_{k} \\right\\}_{k=1}^K$ 是模型参数，$\\pi_{k}$ 是混合系数，满足 $\\sum_{k = 1}^{K}\\pi_{k} = 1$. 数据样本为 $\\left\\{ x^{i} \\right\\}_{i = 1}^{N}$，引入隐变量 $z$ 表示样本属于哪个高斯分布, $z^{i} = k$ 表示样本 $x^{i}$ 来自第 $k$ 个高斯分布.\nE 步 计算后验概率（责任度）：\n$$ \\begin{aligned} \\gamma_{z^{i} = k} \u0026 \\leftarrow p_{\\theta}\\left( z^{i} = k|x^{i} \\right) \\\\ \u0026 = \\frac{\\pi_{k}\\mathcal{N}(x^{i}|\\mu_{k},\\Sigma_{k})}{\\sum_{j = 1}^{K}\\pi_{j}\\mathcal{N}(x^{i}|\\mu_{j},\\Sigma_{j})} \\end{aligned} $$M 步 更新参数：\n$$\\theta = \\arg\\max\\limits_{\\theta}\\mathcal{F}(\\gamma,\\theta)$$即在已知责任度 $\\gamma_{z^{i} = k}$ 下，最大化似然的参数. 定义 $\\begin{aligned} N_{k} \u0026 = \\sum_{i = 1}^{N}\\gamma_{z^{i} = k} \\end{aligned}$,\n则更新步骤为\n$$ \\begin{aligned} \\pi_{k} \u0026 \\leftarrow \\frac{N_{k}}{N} \\\\ \\mu_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}x^{i} \\\\ \\Sigma_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}\\left( x^{i} - \\mu_{k} \\right)\\left( x^{i} - \\mu_{k} \\right)^{\\top} \\end{aligned} $$VAE 普通的自编码器（Autoencoder）就是编码\u0026ndash;解码：\n编码器把输入数据 $x$ 映射到一个隐空间向量 $z$；\n解码器把 $z$ 还原回数据空间，得到重构 $\\hat{x}$.\n但是，普通自编码器学习到的 $z$ 没有概率解释，不能直接采样用于生成.\nVAE 的关键思想是：\n给隐变量 $z$ 加一个概率分布的解释，并用变分推断来学习这个分布.\n编码器不再输出一个确定向量，而是输出一个 分布参数（均值 $\\mu(x)$、方差 $\\sigma^{2}(x)$）\n从这个分布中采样 $z \\sim q_{\\varphi(z|x)}$，再送给解码器生成 $\\hat{x}$.\n这样隐空间就被正则化成一个连续、平滑的概率空间，可以用来插值、采样、生成新样本.\n先验分布 $p(z)$ 隐变量 $z$ 的先验分布 $p(z)$ 通常取标准正态分布 $\\mathcal{N}(0,I)$.\n解码器（生成分布） $p_{\\theta}\\left( x|z \\right)$ 网络参数 $\\theta$ 输入隐变量 $z$，输出数据 $x$ 的分布参数，即高斯分布的均值 $\\mu(z)$ 和方差 $\\Sigma(z)$.\n编码器（近似后验分布）$q_{\\varphi}\\left( z|x \\right)$ 使用 $q_{\\varphi}\\left( z|x \\right)$ 拟合\u0026quot;真实\u0026quot;后验分布 $p_{\\theta}\\left( z|x \\right)$.同样使用神经网络参数 $\\varphi$，输入数据 $x$，输出隐变量 $z$ 的分布参数.\n\u0026ldquo;近似\u0026quot;后验 和 \u0026ldquo;真实\u0026quot;后验 \u0026ldquo;真实\u0026quot;的后验分布由贝叶斯公式得出\n$$ \\begin{aligned} p_{\\theta}\\left( x|z \\right) \u0026= \\frac{p_{\\theta}\\left( x|z \\right)p(z)}{p_{\\theta}(x)} \\\\ p_{\\theta}(x) \u0026= \\int p_{\\theta}\\left( x|z \\right)p(z)dz \\end{aligned} $$因此真实的后验不可解，使用近似后验 $q_{\\varphi}\\left( z|x \\right)$ 来代替.\nELBO 和损失函数 使用 ELBO 替代对数似然：\n$$\\log p_{\\theta}(x) \\geq {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$其中\n${\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack$ 是重构误差，衡量解码器重构 $\\hat{x}$ 与输入 $x$ 的差异；\n$\\text{KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$ 是正则化项，使近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 尽量接近先验分布 $p(z)$（标准正态分布）.\n训练和重参数化 目前我们有\n编码器 $q_{\\varphi}\\left( z|x \\right)$，输入 $x$，输出隐变量 $z$ 的高斯分布参数 $\\mu(x),\\sigma^{2}(x)$；\n解码器 $p_{\\theta}\\left( x|z \\right)$，输入隐变量 $z$，输出重构 $\\hat{x}$ 的分布；\n先验分布 $p(z)$，通常取标准正态分布 $\\mathcal{N}(0,I)$.\n损失函数 ELBO $$\\mathcal{L} = - {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack + \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$ 训练时，期望项（重构误差）没有解析解，使用 $z$ 的采样来近似. 为了保证采样 $z \\sim \\mathcal{N}(\\mu(x),\\sigma^{2}(x))$ 可导，使用重参数化技巧：\n$$ \\begin{array}{r} z = \\mu(x) + \\sigma(x) \\odot \\varepsilon, \\\\ \\end{array} $$其中 $\\varepsilon \\sim \\mathcal{N}(0,I)$ 是独立噪声.\n展开 KL 散度 记 $q_{\\text{agg }}(z) = {\\mathbb{E}}_{x \\sim P(x)}q\\left( z|x \\right)$,\n$$ \\begin{aligned} \\text{ELBO} \u0026= \\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right] - \\mathrm{KL}\\!\\left(q_{\\text{agg}}(z)\\|p(z)\\right) \\\\ \u0026= \\underbrace{\\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right]}_{\\text{重构项}} - \\underbrace{H\\!\\left(q_{\\text{agg}}(z),p(z)\\right)}_{\\text{交叉熵}} + \\underbrace{H\\!\\left(p(z)\\right)}_{\\text{熵}}. \\end{aligned} $$ 重构项：鼓励隐变量分布远离先验分布 $p(z)$，提高重构质量 交叉熵：把隐变量分布拉向先验分布 $p(z)$ 中心，会同时减小均值和方差 熵：鼓励隐变量分布增大方差，分布更扁平 VAE 的问题 Prior Hole VAE 的隐空间分布 $q_{\\text{agg }}(z)$ 往往只占据先验分布 $p(z)$ 的一小部分，导致从先验分布采样的 $z$ 很可能落在\u0026quot;空洞\u0026quot;区域，解码器无法生成有效样本.\nPosterior Collapse 如果解码器足够强大，例如 autoregressive 模型，可以不依赖 $z$, 或者仅从 $z$ 的一部分维度中重构输入 $x$. 即 $z$ 的某些维度对重构没有贡献，导致这些维度的近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 退化为先验分布 $p(z)$，从而无法学习到有效的隐表示.\n$$\\exists i\\ s.t.\\ \\forall x,q_{\\varphi}\\left( z_{i}|x \\right) = p\\left( z_{i} \\right)$$Vector Quantized VAE(VQ VAE) 让隐变量 $z$ 取离散值，而不是连续值. 定义一个有限的码本（codebook），编码器输出一个向量 $e_{i}$，然后将 $e_{i}$ 映射到码本中距离最近的离散向量 $e_{k}$.\n解决了 Prior Hole 和 Posterior Collapse 问题，但训练时需要使用特殊的技巧（如直通估计器）来处理离散变量的不可导问题.\n","permalink":"http://localhost:1313/posts/elbo-em-vae/","summary":"\u003ch1 id=\"证据下界-elbo\"\u003e证据下界 ELBO\u003c/h1\u003e\n\u003cp\u003e在最大似然估计（Maximum Likelihood Estimation,\nMLE）中，目标是最大化观测数据 $x$ 的对数似然.\u003c/p\u003e\n\u003cp\u003e参数 $\\theta$ 的对数似然（log likelihood）的定义为\u003c/p\u003e\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$\u003cp\u003e其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布\n$q(z)$，有\u003c/p\u003e\n$$\n\\begin{aligned}\n\\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\\n \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack\n\\end{aligned}\n$$\u003cp\u003e由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\u003c/p\u003e\n$$\n\\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack.\n$$\u003ch2 id=\"取等条件\"\u003e取等条件\u003c/h2\u003e\n\u003cp\u003eJensen 不等式能够取等，当且仅当对于所有 $z$,\n$\\frac{p_{\\theta}(x,z)}{q(z)}$\n为常数 $c$.\n因此\u003c/p\u003e","title":"ELBO，EM和VAE"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 menu: main: - identifier: categories name: categories url: /categories/ weight: 10 - identifier: tags name: tags url: /tags/ weight: 20 - identifier: example name: example.org url: https://example.org weight: 30 Diffusion Model 加噪过程 定义一个马尔可夫链，从数据 $x_{0} \\sim q(x)$ 开始，每一步加一点噪声：\n$$q\\left( x_{t}~|~x_{t - 1} \\right) = \\mathcal{N}(x_{t};\\sqrt{1 - \\beta_{t}}x_{t - 1},\\beta_{t}I)$$使用重参数化，等价于\n$$x_{t} = \\sqrt{1 - \\beta_{t}}x_{t - 1} + \\sqrt{\\beta_{t}}\\varepsilon_{t},\\quad\\varepsilon_{t} \\sim N(0,I),$$其中 $\\beta$ 是一系列预定义的参数.\n对于两个高斯分布 $x_{1} \\sim \\mathcal{N}(\\mu_{1},\\sigma_{1}^{2})$ 和 $x_{2} \\sim \\mathcal{N}(\\mu_{2},\\sigma_{2}^{2})$，我们有：\n$$x_{1} + x_{2} \\sim \\mathcal{N}(\\mu_{1} + \\mu_{2},\\sigma_{1}^{2} + \\sigma_{2}^{2})$$于是定义 $\\alpha_{t} = 1 - \\beta_{t}$，则\n$$\\begin{aligned} x_{t} \u0026 = \\sqrt{\\alpha_{t}}x_{t - 1} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{\\alpha_{t}\\left( 1 - \\alpha_{t - 1} \\right)}\\varepsilon_{t} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}}\\varepsilon \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}x_{t - 3} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}\\varepsilon \\\\ \u0026 = \\ldots \\end{aligned}$$定义 ${\\overline{\\alpha}}_{t} = \\prod_{s = 1}^{t}\\alpha_{s}$, 得到 $x_{t}$ 的封闭形式\n$$x_{t} = \\sqrt{{\\overline{\\alpha}}_{t}}x_{0} + \\sqrt{1 - {\\overline{\\alpha}}_{t}}\\varepsilon,\\quad\\varepsilon \\sim N(0,I).$$即\n$$q\\left( x_{t}~|~x_{0} \\right) = \\mathcal{N}(x_{t};\\sqrt{{\\overline{\\alpha}}_{t}}x_{0},\\left( 1 - {\\overline{\\alpha}}_{t} \\right)I)$$因为 $\\alpha_{t} \u003c 1$, 因此 ${\\overline{\\alpha}}_{\\infty} \\rightarrow 0$，此时 $q\\left( x_{t}~|~x_{0} \\right) \\rightarrow \\mathcal{N}(0,I)$. 即随着 $t$ 增大，$x_{t}$ 趋近于纯噪声.\n去噪过程 我们的目标是找到加噪过程 $q\\left( x_{t}~|~x_{t - 1} \\right)$ 的逆过程，即逐步去噪的条件高斯分布\n$$q\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{t}\\left( x_{t} \\right),\\Sigma_{t}\\left( x_{t} \\right))$$$q\\left( x_{t - 1}~|~x_{t} \\right)$不可解，因此使用一个模型 $\\theta$ 近似，以 $x_{t}$ 和 $t$ 作为输入，输出分布参数\n$$p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{\\theta}\\left( x_{t},t \\right),\\Sigma_{\\theta}\\left( x_{t},t \\right))$$最大似然估计 MLE 目标是最小化去噪模型 $p_{\\theta}$ 对初始数据 $x_{0}$ 的负对数似然：\n$$\\mathcal{L}(\\theta) = - \\log p_{\\theta}\\left( x_{0} \\right)$$同样地，使用变分下界 ELBO 优化，其中 $x_{0}$ 是已知变量，$x_{1:T}$ 是隐变量：\n$$\\begin{array}{r} \\mathcal{F}(q,\\theta) = {\\mathbb{E}}_{q\\left( x_{1:T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0:T} \\right) - \\log q\\left( x_{1:T}|x_{0} \\right) \\right\\rbrack \\\\ \\mathcal{L}(\\theta) \\leq - \\mathcal{F}(q,\\theta) \\end{array}$$根据马尔可夫性质，\n$$\\begin{array}{r} q\\left( x_{1:T}|x_{0} \\right) = q\\left( x_{T}~|~x_{0} \\right)\\prod_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\\\ p_{\\theta}\\left( x_{0:T} \\right) = p_{\\theta}\\left( x_{T} \\right)\\prod_{t = 1}^{T}p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\end{array}$$代入得到 $\\mathcal{F}(q,\\theta)$\n$$\\begin{aligned} = \u0026 {\\mathbb{E}}_{q\\left( x_{1}:x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) + \\sum_{t = 1}^{T}\\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) - \\sum_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t},x_{t - 1}|x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}{\\mathbb{E}}_{q\\left( x_{t - 1}|x_{t},x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right) \\\\ \u0026 - \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right) \\end{aligned}$$分别记作\n$$\\mathcal{L} ≔ - \\mathcal{F}(q,\\theta) = \\mathcal{L}_{0} + \\sum_{t = 2}^{T}\\mathcal{L}_{t - 1} + \\mathcal{L}_{T}.$$其中\n初始项 $\\mathcal{L}_{0} = - {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack$\n最小化最后一步 $x_{1}$ 到 $x_{0}$ 的重建误差\n当 $p_{\\theta}$ 取高斯分布时，相当于最小化均方误差 MSE: ${\\mathbb{E}}\\left\\lbrack \\left\\| {x_{1} - x_{0}} \\right\\|^{2} \\right\\rbrack$\n中间项 $\\mathcal{L}_{t - 1} = {\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right)$\n让模型 $p_{\\theta}$ 学习去噪过程，缩小和真实后验 $q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)$ 的差距。\n$$q\\left( x_{t - 1}|x_{t},x_{0} \\right) = \\frac{q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)}{q\\left( x_{t}|x_{0} \\right)} \\propto q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)$$ 终端项 $\\mathcal{L}_{T} = \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right)$\n让模型 $p_{\\theta}$ 的先验分布接近 $q\\left( x_{T}~|~x_{0} \\right)$\n对于足够大的 $T$，$q\\left( x_{T}~|~x_{0} \\right) \\approx \\mathcal{N}(0,I)$，而先验 $p_{\\theta}\\left( x_{T} \\right)$ 被定义为 $\\mathcal{N}(0,I)$\n因此该项可以忽略不计.\nScore-based Diffusion Model \u0026amp; Langevin dynamics Langevin dynamics Boltzmann distribution 统计力学的玻尔兹曼分布（Boltzmann distribution）指出一个系统的状态分布为\n$$p_{i} \\propto \\exp( - \\frac{\\varepsilon_{i}}{kT})$$ []{#eq:boltzmann}\n其中 $\\varepsilon_{i}$ 是状态 $i$ 的能量，$k$ 是玻尔兹曼常数，$T$ 是温度.\nLangevin equation 而 Langevin equation 描述的是粒子在（一维）势能场中的布朗运动，\n$$dx_{t} = - \\frac{1}{\\gamma}\\nabla_{x}U\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t}$$ []{#eq:langevin}\n其中\n$x$ 是粒子位置\n$U(x)$ 是势能函数\n$\\gamma$ 是阻尼系数\n$W_{t}$ 是标准 Wiener 过程：$W_{t + \\Delta} = W_{t} + \\mathcal{N}(0,\\Delta)$\n根据 Boltzmann distribution\n$$U(x) = - kT\\log p(x) + \\text{ constant},$$代入得\n$$\\begin{aligned} dx_{t} \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\\\ \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\end{aligned}$$方程在离散时间 $x_{k} ≔ x(k\\tau)$ 下的形式为\n$$\\begin{array}{rlr} x_{k + 1} - x_{k} \u0026 = - \\frac{kT}{\\gamma}\\tau\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{\\frac{2kT}{\\gamma}\\tau}\\xi\\quad \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\\\ \u0026 = - \\eta\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{2\\eta}\\xi \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\end{array}$$其中 $\\eta = \\frac{kT}{\\gamma}\\tau$ 是步长. 回忆 $x_{t}$ 描述的是粒子的随机位置，因此\n$$x_{k} \\sim p(x)$$即已知对数梯度 $\\nabla\\log p(x)$ 时，Langevin dynamics 迭代的过程可以对分布 $p(x)$ 采样，而不需要显式地知道 $p(x)$ 的形式。\n观察迭代形式，这实际上是一个带随机扰动的对数梯度上升过程，梯度项使得粒子趋向于高概率区域，而随机扰动则保证了采样的多样性.\nSimulated Annealing 实际上，如果令玻尔兹曼分布 ([@eq]:boltzmann) 中势能不变，$T$ 逐渐收敛至 $0$, 则分布收敛到单点分布 $p(x) = \\delta(x - x^{\\ast})$，其中 $x^{\\ast} = \\arg\\min\\limits_{x}U(x)$ 是势能的最小值点, 此时 Langevin equation ([@eq]:langevin) 中的随机扰动项收敛至 $0$，Langevin dynamics 退化为势能的对数梯度下降. 而温度 $T$ 的收敛速度控制了采样过程的随机性，快速的降温会导致探索不足，陷入局部势能极小值，反之则有更大概率达到势能全局最小值。这种模拟降温过程的方法即为模拟退火 Simulated Annealing.\nScore-based Diffusion Model 定义 score 函数，即数据分布的对数梯度：\n$$\\text{ score}(x) = \\nabla_{x}\\log p(x)$$根据 Langevin dynamics ([@eq]:langevin)，只要能估计出数据分布的 score 函数，即可通过迭代采样得到数据分布的样本.\n学习 score 在 Score-based Diffusion Model 中，唯一需要学习的就是一个 noise-conditioned score network:\n$$s_{\\theta}\\left( x_{t},t \\right) \\approx \\nabla_{x_{t}}\\log p\\left( x_{t} \\right)$$采取 DSM（Denoising Score Matching）损失：\n$$\\mathcal{L} = {\\mathbb{E}}_{x,z,t}\\left\\lbrack \\lambda(t)\\left\\| {s_{\\theta}\\left( x + \\sigma_{t}z,t \\right) + \\frac{z}{\\sigma_{t}}} \\right\\|^{2} \\right\\rbrack$$即 $s_{\\theta}\\left( x + \\sigma_{t}z,t \\right)$ 的真实值为\n$$\\nabla\\log\\mathcal{N}(u;x,\\sigma_{t}^{2}) = \\nabla\\frac{{- (u - x)}^{2}}{2\\sigma_{t}^{2}} = - \\frac{u - x}{\\sigma_{t}^{2}} = - \\frac{z}{\\sigma_{t}}$$而 $\\lambda(t)$ 是一个权重函数，用于平衡不同噪声水平下的损失贡献. 常见的选择是\n$$\\lambda(t) = \\sigma_{t}^{2}$$采样/去噪 条件 Diffusion Model 给定条件 $c$, 需要\n$$\\nabla_{x}\\log p\\left( x|c \\right)$$Bayes 公式：\n$$\\nabla_{x}\\log p\\left( x|c \\right) = \\nabla_{x}\\log p(x) + \\nabla_{x}\\log p\\left( c|x \\right)$$如何得到 $\\nabla_{x}\\log p\\left( c|x \\right)$:\nclassifier guidance：基于 $x_{t}$ 的分类器，通过反向传播获取梯度。 通过给 $\\nabla_{x}\\log p\\left( c|x \\right)$ 乘以一个系数 $s \u003e 1$，可以增强条件信息的影响，得到更符合条件的样本生成结果.\nClassifier-Free Diffusion Guidance (CFG) 不使用分类器，而是定义两种去噪模型的score：\n条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma,c \\right) - x_{0} \\right)$\n无条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right)$\n其中 $D_{\\theta}$ 是去噪器, 使用一个 null 条件（如全零向量）来表示无条件模型. 则上式的等价形式\n$$\\begin{aligned} \\nabla_{x}\\log p\\left( x|c \\right) \u0026 = \\nabla_{x}\\log p(x) + S\\nabla_{x}\\log p\\left( c|x \\right) \\\\ \u0026 = \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) + S\\left( \\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) - \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\right) \\\\ \u0026 = S\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) + (1 - S)\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\\\ \u0026 = \\frac{1}{\\sigma^{2}}\\left( SD_{\\theta}\\left( x_{t},\\sigma,c \\right) + (1 - S)D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right) \\end{aligned}$$即用二者的凸组合来进行去噪采样.\n","permalink":"http://localhost:1313/posts/2025-12-26-diffusion/","summary":"\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nt\"\u003emenu\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"nt\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/categories/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e10\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/tags/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e20\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ehttps://example.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e30\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch1 id=\"diffusion-model\"\u003eDiffusion Model\u003c/h1\u003e\n\u003ch2 id=\"加噪过程\"\u003e加噪过程\u003c/h2\u003e\n\u003cp\u003e定义一个\u003cstrong\u003e马尔可夫链\u003c/strong\u003e，从数据 $x_{0} \\sim q(x)$\n开始，每一步加一点噪声：\u003c/p\u003e","title":"Diffusion Model"},{"content":"证据下界 ELBO 在最大似然估计（Maximum Likelihood Estimation, MLE）中，目标是最大化观测数据 $x$ 的对数似然.\n参数 $\\theta$ 的对数似然（log likelihood）的定义为\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布 $q(z)$，有\n$$ \\begin{aligned} \\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\ \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\end{aligned} $$由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\n$$ \\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack. $$取等条件 Jensen 不等式能够取等，当且仅当对于所有 $z$, $\\frac{p_{\\theta}(x,z)}{q(z)}$ 为常数 $c$. 因此\n$$ \\begin{aligned} p_{\\theta}(x) \u0026= \\sum_{z}p_{\\theta}(x,z) = c\\sum_{z}q(z) = c \\\\ q(z) \u0026= \\frac{p_{\\theta}(x,z)}{p_{\\theta}(x)} = p_{\\theta}\\left( z|x \\right). \\end{aligned} $$这里的 $q(z)$ 可以是任意分布，但使用中常用 $q(z) = q_{\\varphi}\\left( z|x \\right)$，即 $z$ 的近似后验分布，而近似后验分布越接近真实后验分布 $p_{\\theta}\\left( z|x \\right)$，ELBO 越接近对数似然.\nKL散度 任意分布 $p(x)$ 的信息熵定义为\n$$H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log p(x) \\right\\rbrack$$即对随机事件编码长度的期望值. 如果认为 $x$ 服从另一分布 $q(x)$，在\u0026quot;真实\u0026quot;分布 $p(x)$ 下的编码长度期望值定义为交叉熵：\n$$H(p,q) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log q(x) \\right\\rbrack.$$KL散度即定义为“额外的”编码长度\n$$\\text{ KL}\\left( p\\|q \\right) = H(p,q) - H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack.$$ KL散度描述了两个分布的差异程度，但是不是距离度量，因为不满足对称性和三角不等式.\nKL 散度的非负性 对于任意分布 $p(x)$ 和 $q(x)$，有 $\\text{KL}(p \\|q) \\ge 0$，因为\n$$ \\begin{aligned} \\text{ KL}\\left( p\\|q \\right) \u0026 = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack \\\\ \u0026 = - {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log\\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \\left( \\text{Jensen} \\right) \u0026 \\geq - \\log{\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \u0026 = - \\log\\int_{x}p(x)\\left( \\frac{q(x)}{p(x)} \\right)dx \\\\ \u0026 = - \\log\\int_{x}q(x)dx \\\\ \u0026 = - \\log 1 \\\\ \u0026 = 0. \\end{aligned} $$易知当且仅当 $p = q$ 时，$\\text{KL}\\left( p\\|q \\right) = 0$.\nELBO 等价形式 回到 ELBO，ELBO 和真实对数似然的差距为\n$$ \\begin{aligned} \\ell(\\theta) - \\mathcal{F}(q,\\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x) - \\log p_{\\theta}(x,z) + \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack - \\log p_{\\theta}\\left( z|x \\right) + \\log q(z) \\right\\rbrack \\\\ \u0026= \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right) \\geq 0. \\end{aligned} $$因此，ELBO 等价于\n$$\\mathcal{F}(q,\\theta) = \\ell(\\theta) - \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right)$$显然，取等条件同样为 $q(z) = p_{\\theta}\\left( z|x \\right)$. 而一般的问题中，通常采用以下形式：\n$$ \\begin{aligned} \\mathcal{F}(q, \\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{p_{\\theta}(z)} \\right\\rbrack - \\left( {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(z) \\right\\rbrack \\right) \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q(z)\\|p_{\\theta}(z) \\right) \\end{aligned} $$EM EM 算法的目标是最大化参数 $\\theta$ 对数似然：\n$$\\ell(\\theta) = \\log p\\left( x|\\theta \\right)$$第 $i$ 步的参数和隐变量分布分别记为 $\\theta^{(i)}$ 和 $q^{(i)}(z)$.\nE 步 最大化 $\\ell(\\theta^{(i)})$ 的 ELBO，即取等条件\n$$q^{(i + 1)}(z) = p_{\\theta^{(i)}}\\left( z|x \\right)$$M 步 更新参数 $\\theta^{(i)}$ 以最大化 ELBO， $$\\theta^{(i + 1)} = \\arg\\max\\limits_{\\theta}\\mathcal{F}(q^{(i + 1)},\\theta)$$收敛性 $$\\ell(\\theta^{(i + 1)})\\underset{\\text{ELBO}}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i + 1)})\\underset{\\arg\\max}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i)})\\underset{\\text{满足取等条件}}{=}\\ell(\\theta^{(i)})$$因此对数似然单调不减.\n例子：高斯混合模型 GMM 假设观测数据 $x$ 来自 $K$ 个高斯分布的混合：\n$$p_{\\theta}(x) = \\sum_{k = 1}^{K}\\pi_{k}\\mathcal{N}(x|\\mu_{k},\\Sigma_{k})$$其中 $\\theta = \\left\\{ \\pi_{k},\\mu_{k},\\Sigma_{k} \\right\\}_{k=1}^K$ 是模型参数，$\\pi_{k}$ 是混合系数，满足 $\\sum_{k = 1}^{K}\\pi_{k} = 1$. 数据样本为 $\\left\\{ x^{i} \\right\\}_{i = 1}^{N}$，引入隐变量 $z$ 表示样本属于哪个高斯分布, $z^{i} = k$ 表示样本 $x^{i}$ 来自第 $k$ 个高斯分布.\nE 步 计算后验概率（责任度）：\n$$ \\begin{aligned} \\gamma_{z^{i} = k} \u0026 \\leftarrow p_{\\theta}\\left( z^{i} = k|x^{i} \\right) \\\\ \u0026 = \\frac{\\pi_{k}\\mathcal{N}(x^{i}|\\mu_{k},\\Sigma_{k})}{\\sum_{j = 1}^{K}\\pi_{j}\\mathcal{N}(x^{i}|\\mu_{j},\\Sigma_{j})} \\end{aligned} $$M 步 更新参数：\n$$\\theta = \\arg\\max\\limits_{\\theta}\\mathcal{F}(\\gamma,\\theta)$$即在已知责任度 $\\gamma_{z^{i} = k}$ 下，最大化似然的参数. 定义 $\\begin{aligned} N_{k} \u0026 = \\sum_{i = 1}^{N}\\gamma_{z^{i} = k} \\end{aligned}$,\n则更新步骤为\n$$ \\begin{aligned} \\pi_{k} \u0026 \\leftarrow \\frac{N_{k}}{N} \\\\ \\mu_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}x^{i} \\\\ \\Sigma_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}\\left( x^{i} - \\mu_{k} \\right)\\left( x^{i} - \\mu_{k} \\right)^{\\top} \\end{aligned} $$VAE 普通的自编码器（Autoencoder）就是编码\u0026ndash;解码：\n编码器把输入数据 $x$ 映射到一个隐空间向量 $z$；\n解码器把 $z$ 还原回数据空间，得到重构 $\\hat{x}$.\n但是，普通自编码器学习到的 $z$ 没有概率解释，不能直接采样用于生成.\nVAE 的关键思想是：\n给隐变量 $z$ 加一个概率分布的解释，并用变分推断来学习这个分布.\n编码器不再输出一个确定向量，而是输出一个 分布参数（均值 $\\mu(x)$、方差 $\\sigma^{2}(x)$）\n从这个分布中采样 $z \\sim q_{\\varphi(z|x)}$，再送给解码器生成 $\\hat{x}$.\n这样隐空间就被正则化成一个连续、平滑的概率空间，可以用来插值、采样、生成新样本.\n先验分布 $p(z)$ 隐变量 $z$ 的先验分布 $p(z)$ 通常取标准正态分布 $\\mathcal{N}(0,I)$.\n解码器（生成分布） $p_{\\theta}\\left( x|z \\right)$ 网络参数 $\\theta$ 输入隐变量 $z$，输出数据 $x$ 的分布参数，即高斯分布的均值 $\\mu(z)$ 和方差 $\\Sigma(z)$.\n编码器（近似后验分布）$q_{\\varphi}\\left( z|x \\right)$ 使用 $q_{\\varphi}\\left( z|x \\right)$ 拟合\u0026quot;真实\u0026quot;后验分布 $p_{\\theta}\\left( z|x \\right)$.同样使用神经网络参数 $\\varphi$，输入数据 $x$，输出隐变量 $z$ 的分布参数.\n\u0026ldquo;近似\u0026quot;后验 和 \u0026ldquo;真实\u0026quot;后验 \u0026ldquo;真实\u0026quot;的后验分布由贝叶斯公式得出\n$$ \\begin{aligned} p_{\\theta}\\left( x|z \\right) \u0026= \\frac{p_{\\theta}\\left( x|z \\right)p(z)}{p_{\\theta}(x)} \\\\ p_{\\theta}(x) \u0026= \\int p_{\\theta}\\left( x|z \\right)p(z)dz \\end{aligned} $$因此真实的后验不可解，使用近似后验 $q_{\\varphi}\\left( z|x \\right)$ 来代替.\nELBO 和损失函数 使用 ELBO 替代对数似然：\n$$\\log p_{\\theta}(x) \\geq {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$其中\n${\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack$ 是重构误差，衡量解码器重构 $\\hat{x}$ 与输入 $x$ 的差异；\n$\\text{KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$ 是正则化项，使近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 尽量接近先验分布 $p(z)$（标准正态分布）.\n训练和重参数化 目前我们有\n编码器 $q_{\\varphi}\\left( z|x \\right)$，输入 $x$，输出隐变量 $z$ 的高斯分布参数 $\\mu(x),\\sigma^{2}(x)$；\n解码器 $p_{\\theta}\\left( x|z \\right)$，输入隐变量 $z$，输出重构 $\\hat{x}$ 的分布；\n先验分布 $p(z)$，通常取标准正态分布 $\\mathcal{N}(0,I)$.\n损失函数 ELBO $$\\mathcal{L} = - {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack + \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$ 训练时，期望项（重构误差）没有解析解，使用 $z$ 的采样来近似. 为了保证采样 $z \\sim \\mathcal{N}(\\mu(x),\\sigma^{2}(x))$ 可导，使用重参数化技巧：\n$$ \\begin{array}{r} z = \\mu(x) + \\sigma(x) \\odot \\varepsilon, \\\\ \\end{array} $$其中 $\\varepsilon \\sim \\mathcal{N}(0,I)$ 是独立噪声.\n展开 KL 散度 记 $q_{\\text{agg }}(z) = {\\mathbb{E}}_{x \\sim P(x)}q\\left( z|x \\right)$,\n$$ \\begin{aligned} \\text{ELBO} \u0026= \\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right] - \\mathrm{KL}\\!\\left(q_{\\text{agg}}(z)\\|p(z)\\right) \\\\ \u0026= \\underbrace{\\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right]}_{\\text{重构项}} - \\underbrace{H\\!\\left(q_{\\text{agg}}(z),p(z)\\right)}_{\\text{交叉熵}} + \\underbrace{H\\!\\left(p(z)\\right)}_{\\text{熵}}. \\end{aligned} $$ 重构项：鼓励隐变量分布远离先验分布 $p(z)$，提高重构质量 交叉熵：把隐变量分布拉向先验分布 $p(z)$ 中心，会同时减小均值和方差 熵：鼓励隐变量分布增大方差，分布更扁平 VAE 的问题 Prior Hole VAE 的隐空间分布 $q_{\\text{agg }}(z)$ 往往只占据先验分布 $p(z)$ 的一小部分，导致从先验分布采样的 $z$ 很可能落在\u0026quot;空洞\u0026quot;区域，解码器无法生成有效样本.\nPosterior Collapse 如果解码器足够强大，例如 autoregressive 模型，可以不依赖 $z$, 或者仅从 $z$ 的一部分维度中重构输入 $x$. 即 $z$ 的某些维度对重构没有贡献，导致这些维度的近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 退化为先验分布 $p(z)$，从而无法学习到有效的隐表示.\n$$\\exists i\\ s.t.\\ \\forall x,q_{\\varphi}\\left( z_{i}|x \\right) = p\\left( z_{i} \\right)$$Vector Quantized VAE(VQ VAE) 让隐变量 $z$ 取离散值，而不是连续值. 定义一个有限的码本（codebook），编码器输出一个向量 $e_{i}$，然后将 $e_{i}$ 映射到码本中距离最近的离散向量 $e_{k}$.\n解决了 Prior Hole 和 Posterior Collapse 问题，但训练时需要使用特殊的技巧（如直通估计器）来处理离散变量的不可导问题.\n","permalink":"http://localhost:1313/posts/elbo-em-vae/","summary":"\u003ch1 id=\"证据下界-elbo\"\u003e证据下界 ELBO\u003c/h1\u003e\n\u003cp\u003e在最大似然估计（Maximum Likelihood Estimation,\nMLE）中，目标是最大化观测数据 $x$ 的对数似然.\u003c/p\u003e\n\u003cp\u003e参数 $\\theta$ 的对数似然（log likelihood）的定义为\u003c/p\u003e\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$\u003cp\u003e其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布\n$q(z)$，有\u003c/p\u003e\n$$\n\\begin{aligned}\n\\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\\n \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack\n\\end{aligned}\n$$\u003cp\u003e由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\u003c/p\u003e\n$$\n\\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack.\n$$\u003ch2 id=\"取等条件\"\u003e取等条件\u003c/h2\u003e\n\u003cp\u003eJensen 不等式能够取等，当且仅当对于所有 $z$,\n$\\frac{p_{\\theta}(x,z)}{q(z)}$\n为常数 $c$.\n因此\u003c/p\u003e","title":"ELBO，EM和VAE"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 menu: main: - identifier: categories name: categories url: /categories/ weight: 10 - identifier: tags name: tags url: /tags/ weight: 20 - identifier: example name: example.org url: https://example.org weight: 30 Diffusion Model 加噪过程 定义一个马尔可夫链，从数据 $x_{0} \\sim q(x)$ 开始，每一步加一点噪声：\n$$q\\left( x_{t}~|~x_{t - 1} \\right) = \\mathcal{N}(x_{t};\\sqrt{1 - \\beta_{t}}x_{t - 1},\\beta_{t}I)$$使用重参数化，等价于\n$$x_{t} = \\sqrt{1 - \\beta_{t}}x_{t - 1} + \\sqrt{\\beta_{t}}\\varepsilon_{t},\\quad\\varepsilon_{t} \\sim N(0,I),$$其中 $\\beta$ 是一系列预定义的参数.\n对于两个高斯分布 $x_{1} \\sim \\mathcal{N}(\\mu_{1},\\sigma_{1}^{2})$ 和 $x_{2} \\sim \\mathcal{N}(\\mu_{2},\\sigma_{2}^{2})$，我们有：\n$$x_{1} + x_{2} \\sim \\mathcal{N}(\\mu_{1} + \\mu_{2},\\sigma_{1}^{2} + \\sigma_{2}^{2})$$于是定义 $\\alpha_{t} = 1 - \\beta_{t}$，则\n$$\\begin{aligned} x_{t} \u0026 = \\sqrt{\\alpha_{t}}x_{t - 1} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{\\alpha_{t}\\left( 1 - \\alpha_{t - 1} \\right)}\\varepsilon_{t} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}}\\varepsilon \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}x_{t - 3} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}\\varepsilon \\\\ \u0026 = \\ldots \\end{aligned}$$定义 ${\\overline{\\alpha}}_{t} = \\prod_{s = 1}^{t}\\alpha_{s}$, 得到 $x_{t}$ 的封闭形式\n$$x_{t} = \\sqrt{{\\overline{\\alpha}}_{t}}x_{0} + \\sqrt{1 - {\\overline{\\alpha}}_{t}}\\varepsilon,\\quad\\varepsilon \\sim N(0,I).$$即\n$$q\\left( x_{t}~|~x_{0} \\right) = \\mathcal{N}(x_{t};\\sqrt{{\\overline{\\alpha}}_{t}}x_{0},\\left( 1 - {\\overline{\\alpha}}_{t} \\right)I)$$因为 $\\alpha_{t} \u003c 1$, 因此 ${\\overline{\\alpha}}_{\\infty} \\rightarrow 0$，此时 $q\\left( x_{t}~|~x_{0} \\right) \\rightarrow \\mathcal{N}(0,I)$. 即随着 $t$ 增大，$x_{t}$ 趋近于纯噪声.\n去噪过程 我们的目标是找到加噪过程 $q\\left( x_{t}~|~x_{t - 1} \\right)$ 的逆过程，即逐步去噪的条件高斯分布\n$$q\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{t}\\left( x_{t} \\right),\\Sigma_{t}\\left( x_{t} \\right))$$$q\\left( x_{t - 1}~|~x_{t} \\right)$不可解，因此使用一个模型 $\\theta$ 近似，以 $x_{t}$ 和 $t$ 作为输入，输出分布参数\n$$p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{\\theta}\\left( x_{t},t \\right),\\Sigma_{\\theta}\\left( x_{t},t \\right))$$最大似然估计 MLE 目标是最小化去噪模型 $p_{\\theta}$ 对初始数据 $x_{0}$ 的负对数似然：\n$$\\mathcal{L}(\\theta) = - \\log p_{\\theta}\\left( x_{0} \\right)$$同样地，使用变分下界 ELBO 优化，其中 $x_{0}$ 是已知变量，$x_{1:T}$ 是隐变量：\n$$\\begin{array}{r} \\mathcal{F}(q,\\theta) = {\\mathbb{E}}_{q\\left( x_{1:T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0:T} \\right) - \\log q\\left( x_{1:T}|x_{0} \\right) \\right\\rbrack \\\\ \\mathcal{L}(\\theta) \\leq - \\mathcal{F}(q,\\theta) \\end{array}$$根据马尔可夫性质，\n$$\\begin{array}{r} q\\left( x_{1:T}|x_{0} \\right) = q\\left( x_{T}~|~x_{0} \\right)\\prod_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\\\ p_{\\theta}\\left( x_{0:T} \\right) = p_{\\theta}\\left( x_{T} \\right)\\prod_{t = 1}^{T}p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\end{array}$$代入得到 $\\mathcal{F}(q,\\theta)$\n$$\\begin{aligned} = \u0026 {\\mathbb{E}}_{q\\left( x_{1}:x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) + \\sum_{t = 1}^{T}\\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) - \\sum_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t},x_{t - 1}|x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}{\\mathbb{E}}_{q\\left( x_{t - 1}|x_{t},x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right) \\\\ \u0026 - \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right) \\end{aligned}$$分别记作\n$$\\mathcal{L} ≔ - \\mathcal{F}(q,\\theta) = \\mathcal{L}_{0} + \\sum_{t = 2}^{T}\\mathcal{L}_{t - 1} + \\mathcal{L}_{T}.$$其中\n初始项 $\\mathcal{L}_{0} = - {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack$\n最小化最后一步 $x_{1}$ 到 $x_{0}$ 的重建误差\n当 $p_{\\theta}$ 取高斯分布时，相当于最小化均方误差 MSE: ${\\mathbb{E}}\\left\\lbrack \\left\\| {x_{1} - x_{0}} \\right\\|^{2} \\right\\rbrack$\n中间项 $\\mathcal{L}_{t - 1} = {\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right)$\n让模型 $p_{\\theta}$ 学习去噪过程，缩小和真实后验 $q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)$ 的差距。\n$$q\\left( x_{t - 1}|x_{t},x_{0} \\right) = \\frac{q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)}{q\\left( x_{t}|x_{0} \\right)} \\propto q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)$$ 终端项 $\\mathcal{L}_{T} = \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right)$\n让模型 $p_{\\theta}$ 的先验分布接近 $q\\left( x_{T}~|~x_{0} \\right)$\n对于足够大的 $T$，$q\\left( x_{T}~|~x_{0} \\right) \\approx \\mathcal{N}(0,I)$，而先验 $p_{\\theta}\\left( x_{T} \\right)$ 被定义为 $\\mathcal{N}(0,I)$\n因此该项可以忽略不计.\nScore-based Diffusion Model \u0026amp; Langevin dynamics Langevin dynamics Boltzmann distribution 统计力学的玻尔兹曼分布（Boltzmann distribution）指出一个系统的状态分布为\n$$p_{i} \\propto \\exp( - \\frac{\\varepsilon_{i}}{kT})$$ []{#eq:boltzmann}\n其中 $\\varepsilon_{i}$ 是状态 $i$ 的能量，$k$ 是玻尔兹曼常数，$T$ 是温度.\nLangevin equation 而 Langevin equation 描述的是粒子在（一维）势能场中的布朗运动，\n$$dx_{t} = - \\frac{1}{\\gamma}\\nabla_{x}U\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t}$$ []{#eq:langevin}\n其中\n$x$ 是粒子位置\n$U(x)$ 是势能函数\n$\\gamma$ 是阻尼系数\n$W_{t}$ 是标准 Wiener 过程：$W_{t + \\Delta} = W_{t} + \\mathcal{N}(0,\\Delta)$\n根据 Boltzmann distribution\n$$U(x) = - kT\\log p(x) + \\text{ constant},$$代入得\n$$\\begin{aligned} dx_{t} \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\\\ \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\end{aligned}$$方程在离散时间 $x_{k} ≔ x(k\\tau)$ 下的形式为\n$$\\begin{array}{rlr} x_{k + 1} - x_{k} \u0026 = - \\frac{kT}{\\gamma}\\tau\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{\\frac{2kT}{\\gamma}\\tau}\\xi\\quad \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\\\ \u0026 = - \\eta\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{2\\eta}\\xi \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\end{array}$$其中 $\\eta = \\frac{kT}{\\gamma}\\tau$ 是步长. 回忆 $x_{t}$ 描述的是粒子的随机位置，因此\n$$x_{k} \\sim p(x)$$即已知对数梯度 $\\nabla\\log p(x)$ 时，Langevin dynamics 迭代的过程可以对分布 $p(x)$ 采样，而不需要显式地知道 $p(x)$ 的形式。\n观察迭代形式，这实际上是一个带随机扰动的对数梯度上升过程，梯度项使得粒子趋向于高概率区域，而随机扰动则保证了采样的多样性.\nSimulated Annealing 实际上，如果令玻尔兹曼分布 ([@eq]:boltzmann) 中势能不变，$T$ 逐渐收敛至 $0$, 则分布收敛到单点分布 $p(x) = \\delta(x - x^{\\ast})$，其中 $x^{\\ast} = \\arg\\min\\limits_{x}U(x)$ 是势能的最小值点, 此时 Langevin equation ([@eq]:langevin) 中的随机扰动项收敛至 $0$，Langevin dynamics 退化为势能的对数梯度下降. 而温度 $T$ 的收敛速度控制了采样过程的随机性，快速的降温会导致探索不足，陷入局部势能极小值，反之则有更大概率达到势能全局最小值。这种模拟降温过程的方法即为模拟退火 Simulated Annealing.\nScore-based Diffusion Model 定义 score 函数，即数据分布的对数梯度：\n$$\\text{ score}(x) = \\nabla_{x}\\log p(x)$$根据 Langevin dynamics ([@eq]:langevin)，只要能估计出数据分布的 score 函数，即可通过迭代采样得到数据分布的样本.\n学习 score 在 Score-based Diffusion Model 中，唯一需要学习的就是一个 noise-conditioned score network:\n$$s_{\\theta}\\left( x_{t},t \\right) \\approx \\nabla_{x_{t}}\\log p\\left( x_{t} \\right)$$采取 DSM（Denoising Score Matching）损失：\n$$\\mathcal{L} = {\\mathbb{E}}_{x,z,t}\\left\\lbrack \\lambda(t)\\left\\| {s_{\\theta}\\left( x + \\sigma_{t}z,t \\right) + \\frac{z}{\\sigma_{t}}} \\right\\|^{2} \\right\\rbrack$$即 $s_{\\theta}\\left( x + \\sigma_{t}z,t \\right)$ 的真实值为\n$$\\nabla\\log\\mathcal{N}(u;x,\\sigma_{t}^{2}) = \\nabla\\frac{{- (u - x)}^{2}}{2\\sigma_{t}^{2}} = - \\frac{u - x}{\\sigma_{t}^{2}} = - \\frac{z}{\\sigma_{t}}$$而 $\\lambda(t)$ 是一个权重函数，用于平衡不同噪声水平下的损失贡献. 常见的选择是\n$$\\lambda(t) = \\sigma_{t}^{2}$$采样/去噪 条件 Diffusion Model 给定条件 $c$, 需要\n$$\\nabla_{x}\\log p\\left( x|c \\right)$$Bayes 公式：\n$$\\nabla_{x}\\log p\\left( x|c \\right) = \\nabla_{x}\\log p(x) + \\nabla_{x}\\log p\\left( c|x \\right)$$如何得到 $\\nabla_{x}\\log p\\left( c|x \\right)$:\nclassifier guidance：基于 $x_{t}$ 的分类器，通过反向传播获取梯度。 通过给 $\\nabla_{x}\\log p\\left( c|x \\right)$ 乘以一个系数 $s \u003e 1$，可以增强条件信息的影响，得到更符合条件的样本生成结果.\nClassifier-Free Diffusion Guidance (CFG) 不使用分类器，而是定义两种去噪模型的score：\n条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma,c \\right) - x_{0} \\right)$\n无条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right)$\n其中 $D_{\\theta}$ 是去噪器, 使用一个 null 条件（如全零向量）来表示无条件模型. 则上式的等价形式\n$$\\begin{aligned} \\nabla_{x}\\log p\\left( x|c \\right) \u0026 = \\nabla_{x}\\log p(x) + S\\nabla_{x}\\log p\\left( c|x \\right) \\\\ \u0026 = \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) + S\\left( \\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) - \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\right) \\\\ \u0026 = S\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) + (1 - S)\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\\\ \u0026 = \\frac{1}{\\sigma^{2}}\\left( SD_{\\theta}\\left( x_{t},\\sigma,c \\right) + (1 - S)D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right) \\end{aligned}$$即用二者的凸组合来进行去噪采样.\n","permalink":"http://localhost:1313/posts/2025-12-26-diffusion/","summary":"\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nt\"\u003emenu\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"nt\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/categories/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e10\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/tags/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e20\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ehttps://example.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e30\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch1 id=\"diffusion-model\"\u003eDiffusion Model\u003c/h1\u003e\n\u003ch2 id=\"加噪过程\"\u003e加噪过程\u003c/h2\u003e\n\u003cp\u003e定义一个\u003cstrong\u003e马尔可夫链\u003c/strong\u003e，从数据 $x_{0} \\sim q(x)$\n开始，每一步加一点噪声：\u003c/p\u003e","title":"Diffusion Model"},{"content":"证据下界 ELBO 在最大似然估计（Maximum Likelihood Estimation, MLE）中，目标是最大化观测数据 $x$ 的对数似然.\n参数 $\\theta$ 的对数似然（log likelihood）的定义为\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布 $q(z)$，有\n$$ \\begin{aligned} \\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\ \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\end{aligned} $$由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\n$$ \\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack. $$取等条件 Jensen 不等式能够取等，当且仅当对于所有 $z$, $\\frac{p_{\\theta}(x,z)}{q(z)}$ 为常数 $c$. 因此\n$$ \\begin{aligned} p_{\\theta}(x) \u0026= \\sum_{z}p_{\\theta}(x,z) = c\\sum_{z}q(z) = c \\\\ q(z) \u0026= \\frac{p_{\\theta}(x,z)}{p_{\\theta}(x)} = p_{\\theta}\\left( z|x \\right). \\end{aligned} $$这里的 $q(z)$ 可以是任意分布，但使用中常用 $q(z) = q_{\\varphi}\\left( z|x \\right)$，即 $z$ 的近似后验分布，而近似后验分布越接近真实后验分布 $p_{\\theta}\\left( z|x \\right)$，ELBO 越接近对数似然.\nKL散度 任意分布 $p(x)$ 的信息熵定义为\n$$H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log p(x) \\right\\rbrack$$即对随机事件编码长度的期望值. 如果认为 $x$ 服从另一分布 $q(x)$，在\u0026quot;真实\u0026quot;分布 $p(x)$ 下的编码长度期望值定义为交叉熵：\n$$H(p,q) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log q(x) \\right\\rbrack.$$KL散度即定义为“额外的”编码长度\n$$\\text{ KL}\\left( p\\|q \\right) = H(p,q) - H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack.$$ KL散度描述了两个分布的差异程度，但是不是距离度量，因为不满足对称性和三角不等式.\nKL 散度的非负性 对于任意分布 $p(x)$ 和 $q(x)$，有 $\\text{KL}(p \\|q) \\ge 0$，因为\n$$ \\begin{aligned} \\text{ KL}\\left( p\\|q \\right) \u0026 = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack \\\\ \u0026 = - {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log\\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \\left( \\text{Jensen} \\right) \u0026 \\geq - \\log{\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \u0026 = - \\log\\int_{x}p(x)\\left( \\frac{q(x)}{p(x)} \\right)dx \\\\ \u0026 = - \\log\\int_{x}q(x)dx \\\\ \u0026 = - \\log 1 \\\\ \u0026 = 0. \\end{aligned} $$易知当且仅当 $p = q$ 时，$\\text{KL}\\left( p\\|q \\right) = 0$.\nELBO 等价形式 回到 ELBO，ELBO 和真实对数似然的差距为\n$$ \\begin{aligned} \\ell(\\theta) - \\mathcal{F}(q,\\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x) - \\log p_{\\theta}(x,z) + \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack - \\log p_{\\theta}\\left( z|x \\right) + \\log q(z) \\right\\rbrack \\\\ \u0026= \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right) \\geq 0. \\end{aligned} $$因此，ELBO 等价于\n$$\\mathcal{F}(q,\\theta) = \\ell(\\theta) - \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right)$$显然，取等条件同样为 $q(z) = p_{\\theta}\\left( z|x \\right)$. 而一般的问题中，通常采用以下形式：\n$$ \\begin{aligned} \\mathcal{F}(q, \\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{p_{\\theta}(z)} \\right\\rbrack - \\left( {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(z) \\right\\rbrack \\right) \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q(z)\\|p_{\\theta}(z) \\right) \\end{aligned} $$EM EM 算法的目标是最大化参数 $\\theta$ 对数似然：\n$$\\ell(\\theta) = \\log p\\left( x|\\theta \\right)$$第 $i$ 步的参数和隐变量分布分别记为 $\\theta^{(i)}$ 和 $q^{(i)}(z)$.\nE 步 最大化 $\\ell(\\theta^{(i)})$ 的 ELBO，即取等条件\n$$q^{(i + 1)}(z) = p_{\\theta^{(i)}}\\left( z|x \\right)$$M 步 更新参数 $\\theta^{(i)}$ 以最大化 ELBO， $$\\theta^{(i + 1)} = \\arg\\max\\limits_{\\theta}\\mathcal{F}(q^{(i + 1)},\\theta)$$收敛性 $$\\ell(\\theta^{(i + 1)})\\underset{\\text{ELBO}}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i + 1)})\\underset{\\arg\\max}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i)})\\underset{\\text{满足取等条件}}{=}\\ell(\\theta^{(i)})$$因此对数似然单调不减.\n例子：高斯混合模型 GMM 假设观测数据 $x$ 来自 $K$ 个高斯分布的混合：\n$$p_{\\theta}(x) = \\sum_{k = 1}^{K}\\pi_{k}\\mathcal{N}(x|\\mu_{k},\\Sigma_{k})$$其中 $\\theta = \\left\\{ \\pi_{k},\\mu_{k},\\Sigma_{k} \\right\\}_{k=1}^K$ 是模型参数，$\\pi_{k}$ 是混合系数，满足 $\\sum_{k = 1}^{K}\\pi_{k} = 1$. 数据样本为 $\\left\\{ x^{i} \\right\\}_{i = 1}^{N}$，引入隐变量 $z$ 表示样本属于哪个高斯分布, $z^{i} = k$ 表示样本 $x^{i}$ 来自第 $k$ 个高斯分布.\nE 步 计算后验概率（责任度）：\n$$ \\begin{aligned} \\gamma_{z^{i} = k} \u0026 \\leftarrow p_{\\theta}\\left( z^{i} = k|x^{i} \\right) \\\\ \u0026 = \\frac{\\pi_{k}\\mathcal{N}(x^{i}|\\mu_{k},\\Sigma_{k})}{\\sum_{j = 1}^{K}\\pi_{j}\\mathcal{N}(x^{i}|\\mu_{j},\\Sigma_{j})} \\end{aligned} $$M 步 更新参数：\n$$\\theta = \\arg\\max\\limits_{\\theta}\\mathcal{F}(\\gamma,\\theta)$$即在已知责任度 $\\gamma_{z^{i} = k}$ 下，最大化似然的参数. 定义 $\\begin{aligned} N_{k} \u0026 = \\sum_{i = 1}^{N}\\gamma_{z^{i} = k} \\end{aligned}$,\n则更新步骤为\n$$ \\begin{aligned} \\pi_{k} \u0026 \\leftarrow \\frac{N_{k}}{N} \\\\ \\mu_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}x^{i} \\\\ \\Sigma_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}\\left( x^{i} - \\mu_{k} \\right)\\left( x^{i} - \\mu_{k} \\right)^{\\top} \\end{aligned} $$VAE 普通的自编码器（Autoencoder）就是编码\u0026ndash;解码：\n编码器把输入数据 $x$ 映射到一个隐空间向量 $z$；\n解码器把 $z$ 还原回数据空间，得到重构 $\\hat{x}$.\n但是，普通自编码器学习到的 $z$ 没有概率解释，不能直接采样用于生成.\nVAE 的关键思想是：\n给隐变量 $z$ 加一个概率分布的解释，并用变分推断来学习这个分布.\n编码器不再输出一个确定向量，而是输出一个 分布参数（均值 $\\mu(x)$、方差 $\\sigma^{2}(x)$）\n从这个分布中采样 $z \\sim q_{\\varphi(z|x)}$，再送给解码器生成 $\\hat{x}$.\n这样隐空间就被正则化成一个连续、平滑的概率空间，可以用来插值、采样、生成新样本.\n先验分布 $p(z)$ 隐变量 $z$ 的先验分布 $p(z)$ 通常取标准正态分布 $\\mathcal{N}(0,I)$.\n解码器（生成分布） $p_{\\theta}\\left( x|z \\right)$ 网络参数 $\\theta$ 输入隐变量 $z$，输出数据 $x$ 的分布参数，即高斯分布的均值 $\\mu(z)$ 和方差 $\\Sigma(z)$.\n编码器（近似后验分布）$q_{\\varphi}\\left( z|x \\right)$ 使用 $q_{\\varphi}\\left( z|x \\right)$ 拟合\u0026quot;真实\u0026quot;后验分布 $p_{\\theta}\\left( z|x \\right)$.同样使用神经网络参数 $\\varphi$，输入数据 $x$，输出隐变量 $z$ 的分布参数.\n\u0026ldquo;近似\u0026quot;后验 和 \u0026ldquo;真实\u0026quot;后验 \u0026ldquo;真实\u0026quot;的后验分布由贝叶斯公式得出\n$$ \\begin{aligned} p_{\\theta}\\left( x|z \\right) \u0026= \\frac{p_{\\theta}\\left( x|z \\right)p(z)}{p_{\\theta}(x)} \\\\ p_{\\theta}(x) \u0026= \\int p_{\\theta}\\left( x|z \\right)p(z)dz \\end{aligned} $$因此真实的后验不可解，使用近似后验 $q_{\\varphi}\\left( z|x \\right)$ 来代替.\nELBO 和损失函数 使用 ELBO 替代对数似然：\n$$\\log p_{\\theta}(x) \\geq {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$其中\n${\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack$ 是重构误差，衡量解码器重构 $\\hat{x}$ 与输入 $x$ 的差异；\n$\\text{KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$ 是正则化项，使近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 尽量接近先验分布 $p(z)$（标准正态分布）.\n训练和重参数化 目前我们有\n编码器 $q_{\\varphi}\\left( z|x \\right)$，输入 $x$，输出隐变量 $z$ 的高斯分布参数 $\\mu(x),\\sigma^{2}(x)$；\n解码器 $p_{\\theta}\\left( x|z \\right)$，输入隐变量 $z$，输出重构 $\\hat{x}$ 的分布；\n先验分布 $p(z)$，通常取标准正态分布 $\\mathcal{N}(0,I)$.\n损失函数 ELBO $$\\mathcal{L} = - {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack + \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$ 训练时，期望项（重构误差）没有解析解，使用 $z$ 的采样来近似. 为了保证采样 $z \\sim \\mathcal{N}(\\mu(x),\\sigma^{2}(x))$ 可导，使用重参数化技巧：\n$$ \\begin{array}{r} z = \\mu(x) + \\sigma(x) \\odot \\varepsilon, \\\\ \\end{array} $$其中 $\\varepsilon \\sim \\mathcal{N}(0,I)$ 是独立噪声.\n展开 KL 散度 记 $q_{\\text{agg }}(z) = {\\mathbb{E}}_{x \\sim P(x)}q\\left( z|x \\right)$,\n$$ \\begin{aligned} \\text{ELBO} \u0026= \\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right] - \\mathrm{KL}\\!\\left(q_{\\text{agg}}(z)\\|p(z)\\right) \\\\ \u0026= \\underbrace{\\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right]}_{\\text{重构项}} - \\underbrace{H\\!\\left(q_{\\text{agg}}(z),p(z)\\right)}_{\\text{交叉熵}} + \\underbrace{H\\!\\left(p(z)\\right)}_{\\text{熵}}. \\end{aligned} $$ 重构项：鼓励隐变量分布远离先验分布 $p(z)$，提高重构质量 交叉熵：把隐变量分布拉向先验分布 $p(z)$ 中心，会同时减小均值和方差 熵：鼓励隐变量分布增大方差，分布更扁平 VAE 的问题 Prior Hole VAE 的隐空间分布 $q_{\\text{agg }}(z)$ 往往只占据先验分布 $p(z)$ 的一小部分，导致从先验分布采样的 $z$ 很可能落在\u0026quot;空洞\u0026quot;区域，解码器无法生成有效样本.\nPosterior Collapse 如果解码器足够强大，例如 autoregressive 模型，可以不依赖 $z$, 或者仅从 $z$ 的一部分维度中重构输入 $x$. 即 $z$ 的某些维度对重构没有贡献，导致这些维度的近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 退化为先验分布 $p(z)$，从而无法学习到有效的隐表示.\n$$\\exists i\\ s.t.\\ \\forall x,q_{\\varphi}\\left( z_{i}|x \\right) = p\\left( z_{i} \\right)$$Vector Quantized VAE(VQ VAE) 让隐变量 $z$ 取离散值，而不是连续值. 定义一个有限的码本（codebook），编码器输出一个向量 $e_{i}$，然后将 $e_{i}$ 映射到码本中距离最近的离散向量 $e_{k}$.\n解决了 Prior Hole 和 Posterior Collapse 问题，但训练时需要使用特殊的技巧（如直通估计器）来处理离散变量的不可导问题.\n","permalink":"http://localhost:1313/posts/elbo-em-vae/","summary":"\u003ch1 id=\"证据下界-elbo\"\u003e证据下界 ELBO\u003c/h1\u003e\n\u003cp\u003e在最大似然估计（Maximum Likelihood Estimation,\nMLE）中，目标是最大化观测数据 $x$ 的对数似然.\u003c/p\u003e\n\u003cp\u003e参数 $\\theta$ 的对数似然（log likelihood）的定义为\u003c/p\u003e\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$\u003cp\u003e其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布\n$q(z)$，有\u003c/p\u003e\n$$\n\\begin{aligned}\n\\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\\n \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack\n\\end{aligned}\n$$\u003cp\u003e由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\u003c/p\u003e\n$$\n\\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack.\n$$\u003ch2 id=\"取等条件\"\u003e取等条件\u003c/h2\u003e\n\u003cp\u003eJensen 不等式能够取等，当且仅当对于所有 $z$,\n$\\frac{p_{\\theta}(x,z)}{q(z)}$\n为常数 $c$.\n因此\u003c/p\u003e","title":"ELBO，EM和VAE"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 menu: main: - identifier: categories name: categories url: /categories/ weight: 10 - identifier: tags name: tags url: /tags/ weight: 20 - identifier: example name: example.org url: https://example.org weight: 30 Diffusion Model 加噪过程 定义一个马尔可夫链，从数据 $x_{0} \\sim q(x)$ 开始，每一步加一点噪声：\n$$q\\left( x_{t}~|~x_{t - 1} \\right) = \\mathcal{N}(x_{t};\\sqrt{1 - \\beta_{t}}x_{t - 1},\\beta_{t}I)$$使用重参数化，等价于\n$$x_{t} = \\sqrt{1 - \\beta_{t}}x_{t - 1} + \\sqrt{\\beta_{t}}\\varepsilon_{t},\\quad\\varepsilon_{t} \\sim N(0,I),$$其中 $\\beta$ 是一系列预定义的参数.\n对于两个高斯分布 $x_{1} \\sim \\mathcal{N}(\\mu_{1},\\sigma_{1}^{2})$ 和 $x_{2} \\sim \\mathcal{N}(\\mu_{2},\\sigma_{2}^{2})$，我们有：\n$$x_{1} + x_{2} \\sim \\mathcal{N}(\\mu_{1} + \\mu_{2},\\sigma_{1}^{2} + \\sigma_{2}^{2})$$于是定义 $\\alpha_{t} = 1 - \\beta_{t}$，则\n$$\\begin{aligned} x_{t} \u0026 = \\sqrt{\\alpha_{t}}x_{t - 1} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{\\alpha_{t}\\left( 1 - \\alpha_{t - 1} \\right)}\\varepsilon_{t} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}}\\varepsilon \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}x_{t - 3} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}\\varepsilon \\\\ \u0026 = \\ldots \\end{aligned}$$定义 ${\\overline{\\alpha}}_{t} = \\prod_{s = 1}^{t}\\alpha_{s}$, 得到 $x_{t}$ 的封闭形式\n$$x_{t} = \\sqrt{{\\overline{\\alpha}}_{t}}x_{0} + \\sqrt{1 - {\\overline{\\alpha}}_{t}}\\varepsilon,\\quad\\varepsilon \\sim N(0,I).$$即\n$$q\\left( x_{t}~|~x_{0} \\right) = \\mathcal{N}(x_{t};\\sqrt{{\\overline{\\alpha}}_{t}}x_{0},\\left( 1 - {\\overline{\\alpha}}_{t} \\right)I)$$因为 $\\alpha_{t} \u003c 1$, 因此 ${\\overline{\\alpha}}_{\\infty} \\rightarrow 0$，此时 $q\\left( x_{t}~|~x_{0} \\right) \\rightarrow \\mathcal{N}(0,I)$. 即随着 $t$ 增大，$x_{t}$ 趋近于纯噪声.\n去噪过程 我们的目标是找到加噪过程 $q\\left( x_{t}~|~x_{t - 1} \\right)$ 的逆过程，即逐步去噪的条件高斯分布\n$$q\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{t}\\left( x_{t} \\right),\\Sigma_{t}\\left( x_{t} \\right))$$$q\\left( x_{t - 1}~|~x_{t} \\right)$不可解，因此使用一个模型 $\\theta$ 近似，以 $x_{t}$ 和 $t$ 作为输入，输出分布参数\n$$p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{\\theta}\\left( x_{t},t \\right),\\Sigma_{\\theta}\\left( x_{t},t \\right))$$最大似然估计 MLE 目标是最小化去噪模型 $p_{\\theta}$ 对初始数据 $x_{0}$ 的负对数似然：\n$$\\mathcal{L}(\\theta) = - \\log p_{\\theta}\\left( x_{0} \\right)$$同样地，使用变分下界 ELBO 优化，其中 $x_{0}$ 是已知变量，$x_{1:T}$ 是隐变量：\n$$\\begin{array}{r} \\mathcal{F}(q,\\theta) = {\\mathbb{E}}_{q\\left( x_{1:T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0:T} \\right) - \\log q\\left( x_{1:T}|x_{0} \\right) \\right\\rbrack \\\\ \\mathcal{L}(\\theta) \\leq - \\mathcal{F}(q,\\theta) \\end{array}$$根据马尔可夫性质，\n$$\\begin{array}{r} q\\left( x_{1:T}|x_{0} \\right) = q\\left( x_{T}~|~x_{0} \\right)\\prod_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\\\ p_{\\theta}\\left( x_{0:T} \\right) = p_{\\theta}\\left( x_{T} \\right)\\prod_{t = 1}^{T}p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\end{array}$$代入得到 $\\mathcal{F}(q,\\theta)$\n$$\\begin{aligned} = \u0026 {\\mathbb{E}}_{q\\left( x_{1}:x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) + \\sum_{t = 1}^{T}\\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) - \\sum_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t},x_{t - 1}|x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}{\\mathbb{E}}_{q\\left( x_{t - 1}|x_{t},x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right) \\\\ \u0026 - \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right) \\end{aligned}$$分别记作\n$$\\mathcal{L} ≔ - \\mathcal{F}(q,\\theta) = \\mathcal{L}_{0} + \\sum_{t = 2}^{T}\\mathcal{L}_{t - 1} + \\mathcal{L}_{T}.$$其中\n初始项 $\\mathcal{L}_{0} = - {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack$\n最小化最后一步 $x_{1}$ 到 $x_{0}$ 的重建误差\n当 $p_{\\theta}$ 取高斯分布时，相当于最小化均方误差 MSE: ${\\mathbb{E}}\\left\\lbrack \\left\\| {x_{1} - x_{0}} \\right\\|^{2} \\right\\rbrack$\n中间项 $\\mathcal{L}_{t - 1} = {\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right)$\n让模型 $p_{\\theta}$ 学习去噪过程，缩小和真实后验 $q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)$ 的差距。\n$$q\\left( x_{t - 1}|x_{t},x_{0} \\right) = \\frac{q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)}{q\\left( x_{t}|x_{0} \\right)} \\propto q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)$$ 终端项 $\\mathcal{L}_{T} = \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right)$\n让模型 $p_{\\theta}$ 的先验分布接近 $q\\left( x_{T}~|~x_{0} \\right)$\n对于足够大的 $T$，$q\\left( x_{T}~|~x_{0} \\right) \\approx \\mathcal{N}(0,I)$，而先验 $p_{\\theta}\\left( x_{T} \\right)$ 被定义为 $\\mathcal{N}(0,I)$\n因此该项可以忽略不计.\nScore-based Diffusion Model \u0026amp; Langevin dynamics Langevin dynamics Boltzmann distribution 统计力学的玻尔兹曼分布（Boltzmann distribution）指出一个系统的状态分布为\n$$p_{i} \\propto \\exp( - \\frac{\\varepsilon_{i}}{kT})$$ []{#eq:boltzmann}\n其中 $\\varepsilon_{i}$ 是状态 $i$ 的能量，$k$ 是玻尔兹曼常数，$T$ 是温度.\nLangevin equation 而 Langevin equation 描述的是粒子在（一维）势能场中的布朗运动，\n$$dx_{t} = - \\frac{1}{\\gamma}\\nabla_{x}U\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t}$$ []{#eq:langevin}\n其中\n$x$ 是粒子位置\n$U(x)$ 是势能函数\n$\\gamma$ 是阻尼系数\n$W_{t}$ 是标准 Wiener 过程：$W_{t + \\Delta} = W_{t} + \\mathcal{N}(0,\\Delta)$\n根据 Boltzmann distribution\n$$U(x) = - kT\\log p(x) + \\text{ constant},$$代入得\n$$\\begin{aligned} dx_{t} \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\\\ \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\end{aligned}$$方程在离散时间 $x_{k} ≔ x(k\\tau)$ 下的形式为\n$$\\begin{array}{rlr} x_{k + 1} - x_{k} \u0026 = - \\frac{kT}{\\gamma}\\tau\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{\\frac{2kT}{\\gamma}\\tau}\\xi\\quad \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\\\ \u0026 = - \\eta\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{2\\eta}\\xi \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\end{array}$$其中 $\\eta = \\frac{kT}{\\gamma}\\tau$ 是步长. 回忆 $x_{t}$ 描述的是粒子的随机位置，因此\n$$x_{k} \\sim p(x)$$即已知对数梯度 $\\nabla\\log p(x)$ 时，Langevin dynamics 迭代的过程可以对分布 $p(x)$ 采样，而不需要显式地知道 $p(x)$ 的形式。\n观察迭代形式，这实际上是一个带随机扰动的对数梯度上升过程，梯度项使得粒子趋向于高概率区域，而随机扰动则保证了采样的多样性.\nSimulated Annealing 实际上，如果令玻尔兹曼分布 ([@eq]:boltzmann) 中势能不变，$T$ 逐渐收敛至 $0$, 则分布收敛到单点分布 $p(x) = \\delta(x - x^{\\ast})$，其中 $x^{\\ast} = \\arg\\min\\limits_{x}U(x)$ 是势能的最小值点, 此时 Langevin equation ([@eq]:langevin) 中的随机扰动项收敛至 $0$，Langevin dynamics 退化为势能的对数梯度下降. 而温度 $T$ 的收敛速度控制了采样过程的随机性，快速的降温会导致探索不足，陷入局部势能极小值，反之则有更大概率达到势能全局最小值。这种模拟降温过程的方法即为模拟退火 Simulated Annealing.\nScore-based Diffusion Model 定义 score 函数，即数据分布的对数梯度：\n$$\\text{ score}(x) = \\nabla_{x}\\log p(x)$$根据 Langevin dynamics ([@eq]:langevin)，只要能估计出数据分布的 score 函数，即可通过迭代采样得到数据分布的样本.\n学习 score 在 Score-based Diffusion Model 中，唯一需要学习的就是一个 noise-conditioned score network:\n$$s_{\\theta}\\left( x_{t},t \\right) \\approx \\nabla_{x_{t}}\\log p\\left( x_{t} \\right)$$采取 DSM（Denoising Score Matching）损失：\n$$\\mathcal{L} = {\\mathbb{E}}_{x,z,t}\\left\\lbrack \\lambda(t)\\left\\| {s_{\\theta}\\left( x + \\sigma_{t}z,t \\right) + \\frac{z}{\\sigma_{t}}} \\right\\|^{2} \\right\\rbrack$$即 $s_{\\theta}\\left( x + \\sigma_{t}z,t \\right)$ 的真实值为\n$$\\nabla\\log\\mathcal{N}(u;x,\\sigma_{t}^{2}) = \\nabla\\frac{{- (u - x)}^{2}}{2\\sigma_{t}^{2}} = - \\frac{u - x}{\\sigma_{t}^{2}} = - \\frac{z}{\\sigma_{t}}$$而 $\\lambda(t)$ 是一个权重函数，用于平衡不同噪声水平下的损失贡献. 常见的选择是\n$$\\lambda(t) = \\sigma_{t}^{2}$$采样/去噪 条件 Diffusion Model 给定条件 $c$, 需要\n$$\\nabla_{x}\\log p\\left( x|c \\right)$$Bayes 公式：\n$$\\nabla_{x}\\log p\\left( x|c \\right) = \\nabla_{x}\\log p(x) + \\nabla_{x}\\log p\\left( c|x \\right)$$如何得到 $\\nabla_{x}\\log p\\left( c|x \\right)$:\nclassifier guidance：基于 $x_{t}$ 的分类器，通过反向传播获取梯度。 通过给 $\\nabla_{x}\\log p\\left( c|x \\right)$ 乘以一个系数 $s \u003e 1$，可以增强条件信息的影响，得到更符合条件的样本生成结果.\nClassifier-Free Diffusion Guidance (CFG) 不使用分类器，而是定义两种去噪模型的score：\n条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma,c \\right) - x_{0} \\right)$\n无条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right)$\n其中 $D_{\\theta}$ 是去噪器, 使用一个 null 条件（如全零向量）来表示无条件模型. 则上式的等价形式\n$$\\begin{aligned} \\nabla_{x}\\log p\\left( x|c \\right) \u0026 = \\nabla_{x}\\log p(x) + S\\nabla_{x}\\log p\\left( c|x \\right) \\\\ \u0026 = \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) + S\\left( \\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) - \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\right) \\\\ \u0026 = S\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) + (1 - S)\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\\\ \u0026 = \\frac{1}{\\sigma^{2}}\\left( SD_{\\theta}\\left( x_{t},\\sigma,c \\right) + (1 - S)D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right) \\end{aligned}$$即用二者的凸组合来进行去噪采样.\n","permalink":"http://localhost:1313/posts/2025-12-26-diffusion/","summary":"\u003cdiv class=\"highlight\"\u003e\u003cdiv class=\"chroma\"\u003e\n\u003ctable class=\"lntable\"\u003e\u003ctr\u003e\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode\u003e\u003cspan class=\"lnt\"\u003e 1\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 2\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 3\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 4\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 5\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 6\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 7\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 8\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e 9\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e10\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e11\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e12\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e13\n\u003c/span\u003e\u003cspan class=\"lnt\"\u003e14\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\n\u003ctd class=\"lntd\"\u003e\n\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"nt\"\u003emenu\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e  \u003c/span\u003e\u003cspan class=\"nt\"\u003emain\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ecategories\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/categories/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e10\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003etags\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003e/tags/\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e20\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e    \u003c/span\u003e- \u003cspan class=\"nt\"\u003eidentifier\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003ename\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003eexample.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eurl\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"l\"\u003ehttps://example.org\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003e\u003cspan class=\"w\"\u003e      \u003c/span\u003e\u003cspan class=\"nt\"\u003eweight\u003c/span\u003e\u003cspan class=\"p\"\u003e:\u003c/span\u003e\u003cspan class=\"w\"\u003e \u003c/span\u003e\u003cspan class=\"m\"\u003e30\u003c/span\u003e\u003cspan class=\"w\"\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\n\u003c/div\u003e\n\u003c/div\u003e\u003ch1 id=\"diffusion-model\"\u003eDiffusion Model\u003c/h1\u003e\n\u003ch2 id=\"加噪过程\"\u003e加噪过程\u003c/h2\u003e\n\u003cp\u003e定义一个\u003cstrong\u003e马尔可夫链\u003c/strong\u003e，从数据 $x_{0} \\sim q(x)$\n开始，每一步加一点噪声：\u003c/p\u003e","title":"Diffusion Model"},{"content":"证据下界 ELBO 在最大似然估计（Maximum Likelihood Estimation, MLE）中，目标是最大化观测数据 $x$ 的对数似然.\n参数 $\\theta$ 的对数似然（log likelihood）的定义为\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布 $q(z)$，有\n$$ \\begin{aligned} \\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\ \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\end{aligned} $$由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\n$$ \\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack. $$取等条件 Jensen 不等式能够取等，当且仅当对于所有 $z$, $\\frac{p_{\\theta}(x,z)}{q(z)}$ 为常数 $c$. 因此\n$$ \\begin{aligned} p_{\\theta}(x) \u0026= \\sum_{z}p_{\\theta}(x,z) = c\\sum_{z}q(z) = c \\\\ q(z) \u0026= \\frac{p_{\\theta}(x,z)}{p_{\\theta}(x)} = p_{\\theta}\\left( z|x \\right). \\end{aligned} $$这里的 $q(z)$ 可以是任意分布，但使用中常用 $q(z) = q_{\\varphi}\\left( z|x \\right)$，即 $z$ 的近似后验分布，而近似后验分布越接近真实后验分布 $p_{\\theta}\\left( z|x \\right)$，ELBO 越接近对数似然.\nKL散度 任意分布 $p(x)$ 的信息熵定义为\n$$H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log p(x) \\right\\rbrack$$即对随机事件编码长度的期望值. 如果认为 $x$ 服从另一分布 $q(x)$，在\u0026quot;真实\u0026quot;分布 $p(x)$ 下的编码长度期望值定义为交叉熵：\n$$H(p,q) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log q(x) \\right\\rbrack.$$KL散度即定义为“额外的”编码长度\n$$\\text{ KL}\\left( p\\|q \\right) = H(p,q) - H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack.$$ KL散度描述了两个分布的差异程度，但是不是距离度量，因为不满足对称性和三角不等式.\nKL 散度的非负性 对于任意分布 $p(x)$ 和 $q(x)$，有 $\\text{KL}(p \\|q) \\ge 0$，因为\n$$ \\begin{aligned} \\text{ KL}\\left( p\\|q \\right) \u0026 = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack \\\\ \u0026 = - {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log\\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \\left( \\text{Jensen} \\right) \u0026 \\geq - \\log{\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \u0026 = - \\log\\int_{x}p(x)\\left( \\frac{q(x)}{p(x)} \\right)dx \\\\ \u0026 = - \\log\\int_{x}q(x)dx \\\\ \u0026 = - \\log 1 \\\\ \u0026 = 0. \\end{aligned} $$易知当且仅当 $p = q$ 时，$\\text{KL}\\left( p\\|q \\right) = 0$.\nELBO 等价形式 回到 ELBO，ELBO 和真实对数似然的差距为\n$$ \\begin{aligned} \\ell(\\theta) - \\mathcal{F}(q,\\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x) - \\log p_{\\theta}(x,z) + \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack - \\log p_{\\theta}\\left( z|x \\right) + \\log q(z) \\right\\rbrack \\\\ \u0026= \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right) \\geq 0. \\end{aligned} $$因此，ELBO 等价于\n$$\\mathcal{F}(q,\\theta) = \\ell(\\theta) - \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right)$$显然，取等条件同样为 $q(z) = p_{\\theta}\\left( z|x \\right)$. 而一般的问题中，通常采用以下形式：\n$$ \\begin{aligned} \\mathcal{F}(q, \\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{p_{\\theta}(z)} \\right\\rbrack - \\left( {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(z) \\right\\rbrack \\right) \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q(z)\\|p_{\\theta}(z) \\right) \\end{aligned} $$EM EM 算法的目标是最大化参数 $\\theta$ 对数似然：\n$$\\ell(\\theta) = \\log p\\left( x|\\theta \\right)$$第 $i$ 步的参数和隐变量分布分别记为 $\\theta^{(i)}$ 和 $q^{(i)}(z)$.\nE 步 最大化 $\\ell(\\theta^{(i)})$ 的 ELBO，即取等条件\n$$q^{(i + 1)}(z) = p_{\\theta^{(i)}}\\left( z|x \\right)$$M 步 更新参数 $\\theta^{(i)}$ 以最大化 ELBO， $$\\theta^{(i + 1)} = \\arg\\max\\limits_{\\theta}\\mathcal{F}(q^{(i + 1)},\\theta)$$收敛性 $$\\ell(\\theta^{(i + 1)})\\underset{\\text{ELBO}}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i + 1)})\\underset{\\arg\\max}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i)})\\underset{\\text{满足取等条件}}{=}\\ell(\\theta^{(i)})$$因此对数似然单调不减.\n例子：高斯混合模型 GMM 假设观测数据 $x$ 来自 $K$ 个高斯分布的混合：\n$$p_{\\theta}(x) = \\sum_{k = 1}^{K}\\pi_{k}\\mathcal{N}(x|\\mu_{k},\\Sigma_{k})$$其中 $\\theta = \\left\\{ \\pi_{k},\\mu_{k},\\Sigma_{k} \\right\\}_{k=1}^K$ 是模型参数，$\\pi_{k}$ 是混合系数，满足 $\\sum_{k = 1}^{K}\\pi_{k} = 1$. 数据样本为 $\\left\\{ x^{i} \\right\\}_{i = 1}^{N}$，引入隐变量 $z$ 表示样本属于哪个高斯分布, $z^{i} = k$ 表示样本 $x^{i}$ 来自第 $k$ 个高斯分布.\nE 步 计算后验概率（责任度）：\n$$ \\begin{aligned} \\gamma_{z^{i} = k} \u0026 \\leftarrow p_{\\theta}\\left( z^{i} = k|x^{i} \\right) \\\\ \u0026 = \\frac{\\pi_{k}\\mathcal{N}(x^{i}|\\mu_{k},\\Sigma_{k})}{\\sum_{j = 1}^{K}\\pi_{j}\\mathcal{N}(x^{i}|\\mu_{j},\\Sigma_{j})} \\end{aligned} $$M 步 更新参数：\n$$\\theta = \\arg\\max\\limits_{\\theta}\\mathcal{F}(\\gamma,\\theta)$$即在已知责任度 $\\gamma_{z^{i} = k}$ 下，最大化似然的参数. 定义 $\\begin{aligned} N_{k} \u0026 = \\sum_{i = 1}^{N}\\gamma_{z^{i} = k} \\end{aligned}$,\n则更新步骤为\n$$ \\begin{aligned} \\pi_{k} \u0026 \\leftarrow \\frac{N_{k}}{N} \\\\ \\mu_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}x^{i} \\\\ \\Sigma_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}\\left( x^{i} - \\mu_{k} \\right)\\left( x^{i} - \\mu_{k} \\right)^{\\top} \\end{aligned} $$VAE 普通的自编码器（Autoencoder）就是编码\u0026ndash;解码：\n编码器把输入数据 $x$ 映射到一个隐空间向量 $z$；\n解码器把 $z$ 还原回数据空间，得到重构 $\\hat{x}$.\n但是，普通自编码器学习到的 $z$ 没有概率解释，不能直接采样用于生成.\nVAE 的关键思想是：\n给隐变量 $z$ 加一个概率分布的解释，并用变分推断来学习这个分布.\n编码器不再输出一个确定向量，而是输出一个 分布参数（均值 $\\mu(x)$、方差 $\\sigma^{2}(x)$）\n从这个分布中采样 $z \\sim q_{\\varphi(z|x)}$，再送给解码器生成 $\\hat{x}$.\n这样隐空间就被正则化成一个连续、平滑的概率空间，可以用来插值、采样、生成新样本.\n先验分布 $p(z)$ 隐变量 $z$ 的先验分布 $p(z)$ 通常取标准正态分布 $\\mathcal{N}(0,I)$.\n解码器（生成分布） $p_{\\theta}\\left( x|z \\right)$ 网络参数 $\\theta$ 输入隐变量 $z$，输出数据 $x$ 的分布参数，即高斯分布的均值 $\\mu(z)$ 和方差 $\\Sigma(z)$.\n编码器（近似后验分布）$q_{\\varphi}\\left( z|x \\right)$ 使用 $q_{\\varphi}\\left( z|x \\right)$ 拟合\u0026quot;真实\u0026quot;后验分布 $p_{\\theta}\\left( z|x \\right)$.同样使用神经网络参数 $\\varphi$，输入数据 $x$，输出隐变量 $z$ 的分布参数.\n\u0026ldquo;近似\u0026quot;后验 和 \u0026ldquo;真实\u0026quot;后验 \u0026ldquo;真实\u0026quot;的后验分布由贝叶斯公式得出\n$$ \\begin{aligned} p_{\\theta}\\left( x|z \\right) \u0026= \\frac{p_{\\theta}\\left( x|z \\right)p(z)}{p_{\\theta}(x)} \\\\ p_{\\theta}(x) \u0026= \\int p_{\\theta}\\left( x|z \\right)p(z)dz \\end{aligned} $$因此真实的后验不可解，使用近似后验 $q_{\\varphi}\\left( z|x \\right)$ 来代替.\nELBO 和损失函数 使用 ELBO 替代对数似然：\n$$\\log p_{\\theta}(x) \\geq {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$其中\n${\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack$ 是重构误差，衡量解码器重构 $\\hat{x}$ 与输入 $x$ 的差异；\n$\\text{KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$ 是正则化项，使近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 尽量接近先验分布 $p(z)$（标准正态分布）.\n训练和重参数化 目前我们有\n编码器 $q_{\\varphi}\\left( z|x \\right)$，输入 $x$，输出隐变量 $z$ 的高斯分布参数 $\\mu(x),\\sigma^{2}(x)$；\n解码器 $p_{\\theta}\\left( x|z \\right)$，输入隐变量 $z$，输出重构 $\\hat{x}$ 的分布；\n先验分布 $p(z)$，通常取标准正态分布 $\\mathcal{N}(0,I)$.\n损失函数 ELBO $$\\mathcal{L} = - {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack + \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$ 训练时，期望项（重构误差）没有解析解，使用 $z$ 的采样来近似. 为了保证采样 $z \\sim \\mathcal{N}(\\mu(x),\\sigma^{2}(x))$ 可导，使用重参数化技巧：\n$$ \\begin{array}{r} z = \\mu(x) + \\sigma(x) \\odot \\varepsilon, \\\\ \\end{array} $$其中 $\\varepsilon \\sim \\mathcal{N}(0,I)$ 是独立噪声.\n展开 KL 散度 记 $q_{\\text{agg }}(z) = {\\mathbb{E}}_{x \\sim P(x)}q\\left( z|x \\right)$,\n$$ \\begin{aligned} \\text{ELBO} \u0026= \\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right] - \\mathrm{KL}\\!\\left(q_{\\text{agg}}(z)\\|p(z)\\right) \\\\ \u0026= \\underbrace{\\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right]}_{\\text{重构项}} - \\underbrace{H\\!\\left(q_{\\text{agg}}(z),p(z)\\right)}_{\\text{交叉熵}} + \\underbrace{H\\!\\left(p(z)\\right)}_{\\text{熵}}. \\end{aligned} $$ 重构项：鼓励隐变量分布远离先验分布 $p(z)$，提高重构质量 交叉熵：把隐变量分布拉向先验分布 $p(z)$ 中心，会同时减小均值和方差 熵：鼓励隐变量分布增大方差，分布更扁平 VAE 的问题 Prior Hole VAE 的隐空间分布 $q_{\\text{agg }}(z)$ 往往只占据先验分布 $p(z)$ 的一小部分，导致从先验分布采样的 $z$ 很可能落在\u0026quot;空洞\u0026quot;区域，解码器无法生成有效样本.\nPosterior Collapse 如果解码器足够强大，例如 autoregressive 模型，可以不依赖 $z$, 或者仅从 $z$ 的一部分维度中重构输入 $x$. 即 $z$ 的某些维度对重构没有贡献，导致这些维度的近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 退化为先验分布 $p(z)$，从而无法学习到有效的隐表示.\n$$\\exists i\\ s.t.\\ \\forall x,q_{\\varphi}\\left( z_{i}|x \\right) = p\\left( z_{i} \\right)$$Vector Quantized VAE(VQ VAE) 让隐变量 $z$ 取离散值，而不是连续值. 定义一个有限的码本（codebook），编码器输出一个向量 $e_{i}$，然后将 $e_{i}$ 映射到码本中距离最近的离散向量 $e_{k}$.\n解决了 Prior Hole 和 Posterior Collapse 问题，但训练时需要使用特殊的技巧（如直通估计器）来处理离散变量的不可导问题.\n","permalink":"http://localhost:1313/posts/elbo-em-vae/","summary":"\u003ch1 id=\"证据下界-elbo\"\u003e证据下界 ELBO\u003c/h1\u003e\n\u003cp\u003e在最大似然估计（Maximum Likelihood Estimation,\nMLE）中，目标是最大化观测数据 $x$ 的对数似然.\u003c/p\u003e\n\u003cp\u003e参数 $\\theta$ 的对数似然（log likelihood）的定义为\u003c/p\u003e\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$\u003cp\u003e其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布\n$q(z)$，有\u003c/p\u003e\n$$\n\\begin{aligned}\n\\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\\n \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack\n\\end{aligned}\n$$\u003cp\u003e由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\u003c/p\u003e\n$$\n\\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack.\n$$\u003ch2 id=\"取等条件\"\u003e取等条件\u003c/h2\u003e\n\u003cp\u003eJensen 不等式能够取等，当且仅当对于所有 $z$,\n$\\frac{p_{\\theta}(x,z)}{q(z)}$\n为常数 $c$.\n因此\u003c/p\u003e","title":"ELBO，EM和VAE"},{"content":"Diffusion Model 加噪过程 定义一个马尔可夫链，从数据 $x_{0} \\sim q(x)$ 开始，每一步加一点噪声：\n$$q\\left( x_{t}~|~x_{t - 1} \\right) = \\mathcal{N}(x_{t};\\sqrt{1 - \\beta_{t}}x_{t - 1},\\beta_{t}I)$$使用重参数化，等价于\n$$x_{t} = \\sqrt{1 - \\beta_{t}}x_{t - 1} + \\sqrt{\\beta_{t}}\\varepsilon_{t},\\quad\\varepsilon_{t} \\sim N(0,I),$$其中 $\\beta$ 是一系列预定义的参数.\n对于两个高斯分布 $x_{1} \\sim \\mathcal{N}(\\mu_{1},\\sigma_{1}^{2})$ 和 $x_{2} \\sim \\mathcal{N}(\\mu_{2},\\sigma_{2}^{2})$，我们有：\n$$x_{1} + x_{2} \\sim \\mathcal{N}(\\mu_{1} + \\mu_{2},\\sigma_{1}^{2} + \\sigma_{2}^{2})$$于是定义 $\\alpha_{t} = 1 - \\beta_{t}$，则\n$$\\begin{aligned} x_{t} \u0026 = \\sqrt{\\alpha_{t}}x_{t - 1} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{\\alpha_{t}\\left( 1 - \\alpha_{t - 1} \\right)}\\varepsilon_{t} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}}\\varepsilon \\\\ \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}x_{t - 3} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}\\varepsilon \\\\ \u0026 = \\ldots \\end{aligned}$$定义 ${\\overline{\\alpha}}_{t} = \\prod_{s = 1}^{t}\\alpha_{s}$, 得到 $x_{t}$ 的封闭形式\n$$x_{t} = \\sqrt{{\\overline{\\alpha}}_{t}}x_{0} + \\sqrt{1 - {\\overline{\\alpha}}_{t}}\\varepsilon,\\quad\\varepsilon \\sim N(0,I).$$即\n$$q\\left( x_{t}~|~x_{0} \\right) = \\mathcal{N}(x_{t};\\sqrt{{\\overline{\\alpha}}_{t}}x_{0},\\left( 1 - {\\overline{\\alpha}}_{t} \\right)I)$$因为 $\\alpha_{t} \u003c 1$, 因此 ${\\overline{\\alpha}}_{\\infty} \\rightarrow 0$，此时 $q\\left( x_{t}~|~x_{0} \\right) \\rightarrow \\mathcal{N}(0,I)$. 即随着 $t$ 增大，$x_{t}$ 趋近于纯噪声.\n去噪过程 我们的目标是找到加噪过程 $q\\left( x_{t}~|~x_{t - 1} \\right)$ 的逆过程，即逐步去噪的条件高斯分布\n$$q\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{t}\\left( x_{t} \\right),\\Sigma_{t}\\left( x_{t} \\right))$$$q\\left( x_{t - 1}~|~x_{t} \\right)$不可解，因此使用一个模型 $\\theta$ 近似，以 $x_{t}$ 和 $t$ 作为输入，输出分布参数\n$$p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) = \\mathcal{N}(x_{t - 1};\\mu_{\\theta}\\left( x_{t},t \\right),\\Sigma_{\\theta}\\left( x_{t},t \\right))$$最大似然估计 MLE 目标是最小化去噪模型 $p_{\\theta}$ 对初始数据 $x_{0}$ 的负对数似然：\n$$\\mathcal{L}(\\theta) = - \\log p_{\\theta}\\left( x_{0} \\right)$$同样地，使用变分下界 ELBO 优化，其中 $x_{0}$ 是已知变量，$x_{1:T}$ 是隐变量：\n$$\\begin{array}{r} \\mathcal{F}(q,\\theta) = {\\mathbb{E}}_{q\\left( x_{1:T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0:T} \\right) - \\log q\\left( x_{1:T}|x_{0} \\right) \\right\\rbrack \\\\ \\mathcal{L}(\\theta) \\leq - \\mathcal{F}(q,\\theta) \\end{array}$$根据马尔可夫性质，\n$$\\begin{array}{r} q\\left( x_{1:T}|x_{0} \\right) = q\\left( x_{T}~|~x_{0} \\right)\\prod_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\\\ p_{\\theta}\\left( x_{0:T} \\right) = p_{\\theta}\\left( x_{T} \\right)\\prod_{t = 1}^{T}p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\end{array}$$代入得到 $\\mathcal{F}(q,\\theta)$\n$$\\begin{aligned} = \u0026 {\\mathbb{E}}_{q\\left( x_{1}:x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) + \\sum_{t = 1}^{T}\\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) - \\sum_{t = 2}^{T}q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t},x_{t - 1}|x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}{\\mathbb{E}}_{q\\left( x_{t - 1}|x_{t},x_{0} \\right)}\\left\\lbrack \\log q\\left( x_{t - 1}~|~x_{t},x_{0} \\right) - \\log p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right\\rbrack \\\\ \u0026 + {\\mathbb{E}}_{q\\left( x_{T}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{T} \\right) - \\log q\\left( x_{T}~|~x_{0} \\right) \\right\\rbrack \\\\ = \u0026 {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack - \\sum_{t = 2}^{T}{\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right) \\\\ \u0026 - \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right) \\end{aligned}$$分别记作\n$$\\mathcal{L} ≔ - \\mathcal{F}(q,\\theta) = \\mathcal{L}_{0} + \\sum_{t = 2}^{T}\\mathcal{L}_{t - 1} + \\mathcal{L}_{T}.$$其中\n初始项 $\\mathcal{L}_{0} = - {\\mathbb{E}}_{q\\left( x_{1}|x_{0} \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x_{0}|x_{1} \\right) \\right\\rbrack$\n最小化最后一步 $x_{1}$ 到 $x_{0}$ 的重建误差\n当 $p_{\\theta}$ 取高斯分布时，相当于最小化均方误差 MSE: ${\\mathbb{E}}\\left\\lbrack \\left\\| {x_{1} - x_{0}} \\right\\|^{2} \\right\\rbrack$\n中间项 $\\mathcal{L}_{t - 1} = {\\mathbb{E}}_{q\\left( x_{t}|x_{0} \\right)}\\text{ KL}\\left( q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)\\| p_{\\theta}\\left( x_{t - 1}~|~x_{t} \\right) \\right)$\n让模型 $p_{\\theta}$ 学习去噪过程，缩小和真实后验 $q\\left( x_{t - 1}~|~x_{t},x_{0} \\right)$ 的差距。\n$$q\\left( x_{t - 1}|x_{t},x_{0} \\right) = \\frac{q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)}{q\\left( x_{t}|x_{0} \\right)} \\propto q\\left( x_{t - 1}|x_{0} \\right)q\\left( x_{t}|x_{t - 1} \\right)$$ 终端项 $\\mathcal{L}_{T} = \\text{ KL}\\left( \\log q\\left( x_{T}~|~x_{0} \\right)\\|\\log p_{\\theta}\\left( x_{T} \\right) \\right)$\n让模型 $p_{\\theta}$ 的先验分布接近 $q\\left( x_{T}~|~x_{0} \\right)$\n对于足够大的 $T$，$q\\left( x_{T}~|~x_{0} \\right) \\approx \\mathcal{N}(0,I)$，而先验 $p_{\\theta}\\left( x_{T} \\right)$ 被定义为 $\\mathcal{N}(0,I)$\n因此该项可以忽略不计.\nScore-based Diffusion Model \u0026amp; Langevin dynamics Langevin dynamics Boltzmann distribution 统计力学的玻尔兹曼分布（Boltzmann distribution）指出一个系统的状态分布为\n$$p_{i} \\propto \\exp( - \\frac{\\varepsilon_{i}}{kT})$$ []{#eq:boltzmann}\n其中 $\\varepsilon_{i}$ 是状态 $i$ 的能量，$k$ 是玻尔兹曼常数，$T$ 是温度.\nLangevin equation 而 Langevin equation 描述的是粒子在（一维）势能场中的布朗运动，\n$$dx_{t} = - \\frac{1}{\\gamma}\\nabla_{x}U\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t}$$ []{#eq:langevin}\n其中\n$x$ 是粒子位置\n$U(x)$ 是势能函数\n$\\gamma$ 是阻尼系数\n$W_{t}$ 是标准 Wiener 过程：$W_{t + \\Delta} = W_{t} + \\mathcal{N}(0,\\Delta)$\n根据 Boltzmann distribution\n$$U(x) = - kT\\log p(x) + \\text{ constant},$$代入得\n$$\\begin{aligned} dx_{t} \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\\\ \u0026 = \\frac{kT}{\\gamma}\\nabla_{x}\\log p\\left( x_{t} \\right)dt + \\sqrt{\\frac{2kT}{\\gamma}}dW_{t} \\end{aligned}$$方程在离散时间 $x_{k} ≔ x(k\\tau)$ 下的形式为\n$$\\begin{array}{rlr} x_{k + 1} - x_{k} \u0026 = - \\frac{kT}{\\gamma}\\tau\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{\\frac{2kT}{\\gamma}\\tau}\\xi\\quad \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\\\ \u0026 = - \\eta\\nabla_{x}\\log p\\left( x_{t} \\right) + \\sqrt{2\\eta}\\xi \u0026 ,\\xi \\sim \\mathcal{N}(0,I) \\end{array}$$其中 $\\eta = \\frac{kT}{\\gamma}\\tau$ 是步长. 回忆 $x_{t}$ 描述的是粒子的随机位置，因此\n$$x_{k} \\sim p(x)$$即已知对数梯度 $\\nabla\\log p(x)$ 时，Langevin dynamics 迭代的过程可以对分布 $p(x)$ 采样，而不需要显式地知道 $p(x)$ 的形式。\n观察迭代形式，这实际上是一个带随机扰动的对数梯度上升过程，梯度项使得粒子趋向于高概率区域，而随机扰动则保证了采样的多样性.\nSimulated Annealing 实际上，如果令玻尔兹曼分布 ([@eq]:boltzmann) 中势能不变，$T$ 逐渐收敛至 $0$, 则分布收敛到单点分布 $p(x) = \\delta(x - x^{\\ast})$，其中 $x^{\\ast} = \\arg\\min\\limits_{x}U(x)$ 是势能的最小值点, 此时 Langevin equation ([@eq]:langevin) 中的随机扰动项收敛至 $0$，Langevin dynamics 退化为势能的对数梯度下降. 而温度 $T$ 的收敛速度控制了采样过程的随机性，快速的降温会导致探索不足，陷入局部势能极小值，反之则有更大概率达到势能全局最小值。这种模拟降温过程的方法即为模拟退火 Simulated Annealing.\nScore-based Diffusion Model 定义 score 函数，即数据分布的对数梯度：\n$$\\text{ score}(x) = \\nabla_{x}\\log p(x)$$根据 Langevin dynamics ([@eq]:langevin)，只要能估计出数据分布的 score 函数，即可通过迭代采样得到数据分布的样本.\n学习 score 在 Score-based Diffusion Model 中，唯一需要学习的就是一个 noise-conditioned score network:\n$$s_{\\theta}\\left( x_{t},t \\right) \\approx \\nabla_{x_{t}}\\log p\\left( x_{t} \\right)$$采取 DSM（Denoising Score Matching）损失：\n$$\\mathcal{L} = {\\mathbb{E}}_{x,z,t}\\left\\lbrack \\lambda(t)\\left\\| {s_{\\theta}\\left( x + \\sigma_{t}z,t \\right) + \\frac{z}{\\sigma_{t}}} \\right\\|^{2} \\right\\rbrack$$即 $s_{\\theta}\\left( x + \\sigma_{t}z,t \\right)$ 的真实值为\n$$\\nabla\\log\\mathcal{N}(u;x,\\sigma_{t}^{2}) = \\nabla\\frac{{- (u - x)}^{2}}{2\\sigma_{t}^{2}} = - \\frac{u - x}{\\sigma_{t}^{2}} = - \\frac{z}{\\sigma_{t}}$$而 $\\lambda(t)$ 是一个权重函数，用于平衡不同噪声水平下的损失贡献. 常见的选择是\n$$\\lambda(t) = \\sigma_{t}^{2}$$采样/去噪 条件 Diffusion Model 给定条件 $c$, 需要\n$$\\nabla_{x}\\log p\\left( x|c \\right)$$Bayes 公式：\n$$\\nabla_{x}\\log p\\left( x|c \\right) = \\nabla_{x}\\log p(x) + \\nabla_{x}\\log p\\left( c|x \\right)$$如何得到 $\\nabla_{x}\\log p\\left( c|x \\right)$:\nclassifier guidance：基于 $x_{t}$ 的分类器，通过反向传播获取梯度。 通过给 $\\nabla_{x}\\log p\\left( c|x \\right)$ 乘以一个系数 $s \u003e 1$，可以增强条件信息的影响，得到更符合条件的样本生成结果.\nClassifier-Free Diffusion Guidance (CFG) 不使用分类器，而是定义两种去噪模型的score：\n条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma,c \\right) - x_{0} \\right)$\n无条件模型 $\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) = \\frac{1}{\\sigma^{2}}\\left( D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right)$\n其中 $D_{\\theta}$ 是去噪器, 使用一个 null 条件（如全零向量）来表示无条件模型. 则上式的等价形式\n$$\\begin{aligned} \\nabla_{x}\\log p\\left( x|c \\right) \u0026 = \\nabla_{x}\\log p(x) + S\\nabla_{x}\\log p\\left( c|x \\right) \\\\ \u0026 = \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) + S\\left( \\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) - \\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\right) \\\\ \u0026 = S\\nabla_{x}\\log p_{\\theta}\\left( x_{t},c \\right) + (1 - S)\\nabla_{x}\\log p_{\\theta}\\left( x_{t} \\right) \\\\ \u0026 = \\frac{1}{\\sigma^{2}}\\left( SD_{\\theta}\\left( x_{t},\\sigma,c \\right) + (1 - S)D_{\\theta}\\left( x_{t},\\sigma \\right) - x_{0} \\right) \\end{aligned}$$即用二者的凸组合来进行去噪采样.\n","permalink":"http://localhost:1313/posts/2025-12-26-diffusion/","summary":"\u003ch1 id=\"diffusion-model\"\u003eDiffusion Model\u003c/h1\u003e\n\u003ch2 id=\"加噪过程\"\u003e加噪过程\u003c/h2\u003e\n\u003cp\u003e定义一个\u003cstrong\u003e马尔可夫链\u003c/strong\u003e，从数据 $x_{0} \\sim q(x)$\n开始，每一步加一点噪声：\u003c/p\u003e\n$$q\\left( x_{t}~|~x_{t - 1} \\right) = \\mathcal{N}(x_{t};\\sqrt{1 - \\beta_{t}}x_{t - 1},\\beta_{t}I)$$\u003cp\u003e使用重参数化，等价于\u003c/p\u003e\n$$x_{t} = \\sqrt{1 - \\beta_{t}}x_{t - 1} + \\sqrt{\\beta_{t}}\\varepsilon_{t},\\quad\\varepsilon_{t} \\sim N(0,I),$$\u003cp\u003e其中 $\\beta$ 是一系列预定义的参数.\u003c/p\u003e\n\u003cp\u003e对于两个高斯分布 $x_{1} \\sim \\mathcal{N}(\\mu_{1},\\sigma_{1}^{2})$ 和\n$x_{2} \\sim \\mathcal{N}(\\mu_{2},\\sigma_{2}^{2})$，我们有：\u003c/p\u003e\n$$x_{1} + x_{2} \\sim \\mathcal{N}(\\mu_{1} + \\mu_{2},\\sigma_{1}^{2} + \\sigma_{2}^{2})$$\u003cp\u003e于是定义 $\\alpha_{t} = 1 - \\beta_{t}$，则\u003c/p\u003e\n$$\\begin{aligned}\nx_{t} \u0026 = \\sqrt{\\alpha_{t}}x_{t - 1} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\\n \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{\\alpha_{t}\\left( 1 - \\alpha_{t - 1} \\right)}\\varepsilon_{t} + \\sqrt{1 - \\alpha_{t}}\\varepsilon_{t} \\\\\n \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}}x_{t - 2} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}}\\varepsilon \\\\\n \u0026 = \\sqrt{\\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}x_{t - 3} + \\sqrt{1 - \\alpha_{t}\\alpha_{t - 1}\\alpha_{t - 2}}\\varepsilon \\\\\n \u0026 = \\ldots\n\\end{aligned}$$\u003cp\u003e定义 ${\\overline{\\alpha}}_{t} = \\prod_{s = 1}^{t}\\alpha_{s}$, 得到\n$x_{t}$ 的封闭形式\u003c/p\u003e","title":"Diffusion Model"},{"content":"证据下界 ELBO 在最大似然估计（Maximum Likelihood Estimation, MLE）中，目标是最大化观测数据 $x$ 的对数似然.\n参数 $\\theta$ 的对数似然（log likelihood）的定义为\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布 $q(z)$，有\n$$ \\begin{aligned} \\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\ \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\end{aligned} $$由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\n$$ \\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack. $$取等条件 Jensen 不等式能够取等，当且仅当对于所有 $z$, $\\frac{p_{\\theta}(x,z)}{q(z)}$ 为常数 $c$. 因此\n$$ \\begin{aligned} p_{\\theta}(x) \u0026= \\sum_{z}p_{\\theta}(x,z) = c\\sum_{z}q(z) = c \\\\ q(z) \u0026= \\frac{p_{\\theta}(x,z)}{p_{\\theta}(x)} = p_{\\theta}\\left( z|x \\right). \\end{aligned} $$这里的 $q(z)$ 可以是任意分布，但使用中常用 $q(z) = q_{\\varphi}\\left( z|x \\right)$，即 $z$ 的近似后验分布，而近似后验分布越接近真实后验分布 $p_{\\theta}\\left( z|x \\right)$，ELBO 越接近对数似然.\nKL散度 任意分布 $p(x)$ 的信息熵定义为\n$$H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log p(x) \\right\\rbrack$$即对随机事件编码长度的期望值. 如果认为 $x$ 服从另一分布 $q(x)$，在\u0026quot;真实\u0026quot;分布 $p(x)$ 下的编码长度期望值定义为交叉熵：\n$$H(p,q) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack - \\log q(x) \\right\\rbrack.$$KL散度即定义为“额外的”编码长度\n$$\\text{ KL}\\left( p\\|q \\right) = H(p,q) - H(p) = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack.$$ KL散度描述了两个分布的差异程度，但是不是距离度量，因为不满足对称性和三角不等式.\nKL 散度的非负性 对于任意分布 $p(x)$ 和 $q(x)$，有 $\\text{KL}(p \\|q) \\ge 0$，因为\n$$ \\begin{aligned} \\text{ KL}\\left( p\\|q \\right) \u0026 = {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log p(x) - \\log q(x) \\right\\rbrack \\\\ \u0026 = - {\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\log\\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \\left( \\text{Jensen} \\right) \u0026 \\geq - \\log{\\mathbb{E}}_{x \\sim p}\\left\\lbrack \\frac{q(x)}{p(x)} \\right\\rbrack \\\\ \u0026 = - \\log\\int_{x}p(x)\\left( \\frac{q(x)}{p(x)} \\right)dx \\\\ \u0026 = - \\log\\int_{x}q(x)dx \\\\ \u0026 = - \\log 1 \\\\ \u0026 = 0. \\end{aligned} $$易知当且仅当 $p = q$ 时，$\\text{KL}\\left( p\\|q \\right) = 0$.\nELBO 等价形式 回到 ELBO，ELBO 和真实对数似然的差距为\n$$ \\begin{aligned} \\ell(\\theta) - \\mathcal{F}(q,\\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x) - \\log p_{\\theta}(x,z) + \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack - \\log p_{\\theta}\\left( z|x \\right) + \\log q(z) \\right\\rbrack \\\\ \u0026= \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right) \\geq 0. \\end{aligned} $$因此，ELBO 等价于\n$$\\mathcal{F}(q,\\theta) = \\ell(\\theta) - \\text{ KL}\\left( q(z)\\|p_{\\theta}\\left( z|x \\right) \\right)$$显然，取等条件同样为 $q(z) = p_{\\theta}\\left( z|x \\right)$. 而一般的问题中，通常采用以下形式：\n$$ \\begin{aligned} \\mathcal{F}(q, \\theta) \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{p_{\\theta}(z)} \\right\\rbrack - \\left( {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(z) \\right\\rbrack \\right) \\\\ \u0026= {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q(z)\\|p_{\\theta}(z) \\right) \\end{aligned} $$EM EM 算法的目标是最大化参数 $\\theta$ 对数似然：\n$$\\ell(\\theta) = \\log p\\left( x|\\theta \\right)$$第 $i$ 步的参数和隐变量分布分别记为 $\\theta^{(i)}$ 和 $q^{(i)}(z)$.\nE 步 最大化 $\\ell(\\theta^{(i)})$ 的 ELBO，即取等条件\n$$q^{(i + 1)}(z) = p_{\\theta^{(i)}}\\left( z|x \\right)$$M 步 更新参数 $\\theta^{(i)}$ 以最大化 ELBO， $$\\theta^{(i + 1)} = \\arg\\max\\limits_{\\theta}\\mathcal{F}(q^{(i + 1)},\\theta)$$收敛性 $$\\ell(\\theta^{(i + 1)})\\underset{\\text{ELBO}}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i + 1)})\\underset{\\arg\\max}{\\geq}\\mathcal{F}(q^{(i + 1)},\\theta^{(i)})\\underset{\\text{满足取等条件}}{=}\\ell(\\theta^{(i)})$$因此对数似然单调不减.\n例子：高斯混合模型 GMM 假设观测数据 $x$ 来自 $K$ 个高斯分布的混合：\n$$p_{\\theta}(x) = \\sum_{k = 1}^{K}\\pi_{k}\\mathcal{N}(x|\\mu_{k},\\Sigma_{k})$$其中 $\\theta = \\left\\{ \\pi_{k},\\mu_{k},\\Sigma_{k} \\right\\}_{k=1}^K$ 是模型参数，$\\pi_{k}$ 是混合系数，满足 $\\sum_{k = 1}^{K}\\pi_{k} = 1$. 数据样本为 $\\left\\{ x^{i} \\right\\}_{i = 1}^{N}$，引入隐变量 $z$ 表示样本属于哪个高斯分布, $z^{i} = k$ 表示样本 $x^{i}$ 来自第 $k$ 个高斯分布.\nE 步 计算后验概率（责任度）：\n$$ \\begin{aligned} \\gamma_{z^{i} = k} \u0026 \\leftarrow p_{\\theta}\\left( z^{i} = k|x^{i} \\right) \\\\ \u0026 = \\frac{\\pi_{k}\\mathcal{N}(x^{i}|\\mu_{k},\\Sigma_{k})}{\\sum_{j = 1}^{K}\\pi_{j}\\mathcal{N}(x^{i}|\\mu_{j},\\Sigma_{j})} \\end{aligned} $$M 步 更新参数：\n$$\\theta = \\arg\\max\\limits_{\\theta}\\mathcal{F}(\\gamma,\\theta)$$即在已知责任度 $\\gamma_{z^{i} = k}$ 下，最大化似然的参数. 定义 $\\begin{aligned} N_{k} \u0026 = \\sum_{i = 1}^{N}\\gamma_{z^{i} = k} \\end{aligned}$,\n则更新步骤为\n$$ \\begin{aligned} \\pi_{k} \u0026 \\leftarrow \\frac{N_{k}}{N} \\\\ \\mu_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}x^{i} \\\\ \\Sigma_{k} \u0026 \\leftarrow \\left( \\frac{1}{N_{k}} \\right)\\sum_{i = 1}^{N}\\gamma_{z^{i} = k}\\left( x^{i} - \\mu_{k} \\right)\\left( x^{i} - \\mu_{k} \\right)^{\\top} \\end{aligned} $$VAE 普通的自编码器（Autoencoder）就是编码\u0026ndash;解码：\n编码器把输入数据 $x$ 映射到一个隐空间向量 $z$；\n解码器把 $z$ 还原回数据空间，得到重构 $\\hat{x}$.\n但是，普通自编码器学习到的 $z$ 没有概率解释，不能直接采样用于生成.\nVAE 的关键思想是：\n给隐变量 $z$ 加一个概率分布的解释，并用变分推断来学习这个分布.\n编码器不再输出一个确定向量，而是输出一个 分布参数（均值 $\\mu(x)$、方差 $\\sigma^{2}(x)$）\n从这个分布中采样 $z \\sim q_{\\varphi(z|x)}$，再送给解码器生成 $\\hat{x}$.\n这样隐空间就被正则化成一个连续、平滑的概率空间，可以用来插值、采样、生成新样本.\n先验分布 $p(z)$ 隐变量 $z$ 的先验分布 $p(z)$ 通常取标准正态分布 $\\mathcal{N}(0,I)$.\n解码器（生成分布） $p_{\\theta}\\left( x|z \\right)$ 网络参数 $\\theta$ 输入隐变量 $z$，输出数据 $x$ 的分布参数，即高斯分布的均值 $\\mu(z)$ 和方差 $\\Sigma(z)$.\n编码器（近似后验分布）$q_{\\varphi}\\left( z|x \\right)$ 使用 $q_{\\varphi}\\left( z|x \\right)$ 拟合\u0026quot;真实\u0026quot;后验分布 $p_{\\theta}\\left( z|x \\right)$.同样使用神经网络参数 $\\varphi$，输入数据 $x$，输出隐变量 $z$ 的分布参数.\n\u0026ldquo;近似\u0026quot;后验 和 \u0026ldquo;真实\u0026quot;后验 \u0026ldquo;真实\u0026quot;的后验分布由贝叶斯公式得出\n$$ \\begin{aligned} p_{\\theta}\\left( x|z \\right) \u0026= \\frac{p_{\\theta}\\left( x|z \\right)p(z)}{p_{\\theta}(x)} \\\\ p_{\\theta}(x) \u0026= \\int p_{\\theta}\\left( x|z \\right)p(z)dz \\end{aligned} $$因此真实的后验不可解，使用近似后验 $q_{\\varphi}\\left( z|x \\right)$ 来代替.\nELBO 和损失函数 使用 ELBO 替代对数似然：\n$$\\log p_{\\theta}(x) \\geq {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack - \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$其中\n${\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack$ 是重构误差，衡量解码器重构 $\\hat{x}$ 与输入 $x$ 的差异；\n$\\text{KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$ 是正则化项，使近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 尽量接近先验分布 $p(z)$（标准正态分布）.\n训练和重参数化 目前我们有\n编码器 $q_{\\varphi}\\left( z|x \\right)$，输入 $x$，输出隐变量 $z$ 的高斯分布参数 $\\mu(x),\\sigma^{2}(x)$；\n解码器 $p_{\\theta}\\left( x|z \\right)$，输入隐变量 $z$，输出重构 $\\hat{x}$ 的分布；\n先验分布 $p(z)$，通常取标准正态分布 $\\mathcal{N}(0,I)$.\n损失函数 ELBO $$\\mathcal{L} = - {\\mathbb{E}}_{q_{\\varphi}\\left( z|x \\right)}\\left\\lbrack \\log p_{\\theta}\\left( x|z \\right) \\right\\rbrack + \\text{ KL}\\left( q_{\\varphi}\\left( z|x \\right)\\|p(z) \\right)$$ 训练时，期望项（重构误差）没有解析解，使用 $z$ 的采样来近似. 为了保证采样 $z \\sim \\mathcal{N}(\\mu(x),\\sigma^{2}(x))$ 可导，使用重参数化技巧：\n$$ \\begin{array}{r} z = \\mu(x) + \\sigma(x) \\odot \\varepsilon, \\\\ \\end{array} $$其中 $\\varepsilon \\sim \\mathcal{N}(0,I)$ 是独立噪声.\n展开 KL 散度 记 $q_{\\text{agg }}(z) = {\\mathbb{E}}_{x \\sim P(x)}q\\left( z|x \\right)$,\n$$ \\begin{aligned} \\text{ELBO} \u0026= \\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right] - \\mathrm{KL}\\!\\left(q_{\\text{agg}}(z)\\|p(z)\\right) \\\\ \u0026= \\underbrace{\\mathbb{E}_{q_{\\varphi}(z|x)}\\!\\left[\\log p_{\\theta}(x|z)\\right]}_{\\text{重构项}} - \\underbrace{H\\!\\left(q_{\\text{agg}}(z),p(z)\\right)}_{\\text{交叉熵}} + \\underbrace{H\\!\\left(p(z)\\right)}_{\\text{熵}}. \\end{aligned} $$ 重构项：鼓励隐变量分布远离先验分布 $p(z)$，提高重构质量 交叉熵：把隐变量分布拉向先验分布 $p(z)$ 中心，会同时减小均值和方差 熵：鼓励隐变量分布增大方差，分布更扁平 VAE 的问题 Prior Hole VAE 的隐空间分布 $q_{\\text{agg }}(z)$ 往往只占据先验分布 $p(z)$ 的一小部分，导致从先验分布采样的 $z$ 很可能落在\u0026quot;空洞\u0026quot;区域，解码器无法生成有效样本.\nPosterior Collapse 如果解码器足够强大，例如 autoregressive 模型，可以不依赖 $z$, 或者仅从 $z$ 的一部分维度中重构输入 $x$. 即 $z$ 的某些维度对重构没有贡献，导致这些维度的近似后验分布 $q_{\\varphi}\\left( z|x \\right)$ 退化为先验分布 $p(z)$，从而无法学习到有效的隐表示.\n$$\\exists i\\ s.t.\\ \\forall x,q_{\\varphi}\\left( z_{i}|x \\right) = p\\left( z_{i} \\right)$$Vector Quantized VAE(VQ VAE) 让隐变量 $z$ 取离散值，而不是连续值. 定义一个有限的码本（codebook），编码器输出一个向量 $e_{i}$，然后将 $e_{i}$ 映射到码本中距离最近的离散向量 $e_{k}$.\n解决了 Prior Hole 和 Posterior Collapse 问题，但训练时需要使用特殊的技巧（如直通估计器）来处理离散变量的不可导问题.\n","permalink":"http://localhost:1313/posts/elbo-em-vae/","summary":"\u003ch1 id=\"证据下界-elbo\"\u003e证据下界 ELBO\u003c/h1\u003e\n\u003cp\u003e在最大似然估计（Maximum Likelihood Estimation,\nMLE）中，目标是最大化观测数据 $x$ 的对数似然.\u003c/p\u003e\n\u003cp\u003e参数 $\\theta$ 的对数似然（log likelihood）的定义为\u003c/p\u003e\n$$\\ell(\\theta) = \\log p_{\\theta}(x) = \\log\\sum_{z}p_{\\theta}(x,z),$$\u003cp\u003e其中 $x$ 是观测变量，$z$ 是潜在变量. 根据 Jensen 不等式，对于任意分布\n$q(z)$，有\u003c/p\u003e\n$$\n\\begin{aligned}\n\\ell(\\theta) \u0026= \\log\\sum_{z}p_{\\theta}(x,z) = \\log\\sum_{z}q(z)\\frac{p_{\\theta}(x,z)}{q(z)} = \\log{\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack \\\\\n \u0026\\geq {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log\\frac{p_{\\theta}(x,z)}{q(z)} \\right\\rbrack = {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack\n\\end{aligned}\n$$\u003cp\u003e由此定义 $\\ell(\\theta)$ 的证据下界（Evidence Lower BOund, ELBO）$\\mathcal{F}$:\u003c/p\u003e\n$$\n\\ell(\\theta) \\geq \\mathcal{F}(q,\\theta) \\equiv {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log p_{\\theta}(x,z) \\right\\rbrack - {\\mathbb{E}}_{z \\sim q}\\left\\lbrack \\log q(z) \\right\\rbrack.\n$$\u003ch2 id=\"取等条件\"\u003e取等条件\u003c/h2\u003e\n\u003cp\u003eJensen 不等式能够取等，当且仅当对于所有 $z$,\n$\\frac{p_{\\theta}(x,z)}{q(z)}$\n为常数 $c$.\n因此\u003c/p\u003e","title":"ELBO，EM和VAE"}]